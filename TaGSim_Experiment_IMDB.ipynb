{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tfp3rOdf-K2G",
        "outputId": "3a2660bb-754e-4f10-e568-f124d612e8ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import ast\n",
        "print(sys.executable)\n",
        "import os\n",
        "import random\n",
        "import networkx as nx\n",
        "from matplotlib import pyplot as plt\n",
        "import pylab\n",
        "import re\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# 1.nr 2.nid 3.er 4.eid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/519045752/TagSim/raw/master/IMDB.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MitQRFN_CBC",
        "outputId": "8956583e-efb5-425f-aff1-0ff84a46338f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-31 03:07:16--  https://github.com/519045752/TagSim/raw/master/IMDB.zip\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/519045752/TagSim/master/IMDB.zip [following]\n",
            "--2022-10-31 03:07:16--  https://raw.githubusercontent.com/519045752/TagSim/master/IMDB.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2579001 (2.5M) [application/zip]\n",
            "Saving to: ‘IMDB.zip’\n",
            "\n",
            "IMDB.zip            100%[===================>]   2.46M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2022-10-31 03:07:17 (30.9 MB/s) - ‘IMDB.zip’ saved [2579001/2579001]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/IMDB.zip"
      ],
      "metadata": {
        "id": "BTY9KBvW_G1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET = \"IMDB\"\n",
        "ORI_DIR = \"/content/original\"\n",
        "GEN_DIR =\"/content/generated\"\n",
        "TEST_DIR = \"/content/test\"\n",
        "TEST_GEN_DIR = \"/content/test_gen\"\n",
        "DATASET_FOLDER = \"/content\""
      ],
      "metadata": {
        "id": "7YW9POyVAmNv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_csv = pd.DataFrame(test_data, columns=['G1', 'G2', 'gt_ged']).to_csv(DATASET_FOLDER + \"/testing_pairs.csv\",\n",
        "#                                                                           index=False)\n",
        "def load_pairs():\n",
        "    train_pairs = []\n",
        "    train_csv = pd.read_csv(DATASET_FOLDER+\"/training_pairs.csv\")\n",
        "    for index, row in train_csv.iterrows():\n",
        "        file1 = row['G1']\n",
        "        file2 = row['G2']\n",
        "        ged =ast.literal_eval(row['GED'])\n",
        "        new_ged = [ged[1],ged[3]]\n",
        "        gt_ged = row['gt_ged']\n",
        "        graph1 = nx.read_gexf(path=ORI_DIR + '/' + file1)\n",
        "        graph2 = nx.read_gexf(path=GEN_DIR + '/' + file2)\n",
        "        train_pairs.append({\"graph_pair\": [graph1, graph2], \"ged\": new_ged, \"gt_ged\":gt_ged})\n",
        "\n",
        "\n",
        "    test_pairs = []\n",
        "    test_csv = pd.read_csv(DATASET_FOLDER+\"/testing_pairs.csv\")\n",
        "    for index, row in test_csv.iterrows():\n",
        "        file1 = row['G1']\n",
        "        file2 = row['G2']\n",
        "        gt_ged = row['gt_ged']\n",
        "        graph1 = nx.read_gexf(path=TEST_DIR + '/' + file1)\n",
        "        graph2 = nx.read_gexf(path=TEST_DIR + '/' + file2)\n",
        "        test_pairs.append({\"graph_pair\": [graph1, graph2], \"gt_ged\": gt_ged})\n",
        "    return train_pairs, test_pairs\n",
        "train_pairs, test_pairs = load_pairs()\n",
        "print(len(train_pairs))\n",
        "print(train_pairs[0])\n",
        "print(len(test_pairs))\n",
        "print(test_pairs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w8TVFStA5p0",
        "outputId": "44a47a4f-1c5e-4c83-b22d-cb0edf94d568"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1200\n",
            "{'graph_pair': [<networkx.classes.graph.Graph object at 0x7f4ce33e7450>, <networkx.classes.graph.Graph object at 0x7f4ce33e7550>], 'ged': [5, 3], 'gt_ged': 8}\n",
            "75\n",
            "{'graph_pair': [<networkx.classes.graph.Graph object at 0x7f4cdeb70a90>, <networkx.classes.graph.Graph object at 0x7f4cdeaba5d0>], 'gt_ged': 17.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getFileInfo(filename):\n",
        "    # if test is False:\n",
        "    #     g = nx.read_gexf(path=\"./dataset/\"+datasetName+ + filename)\n",
        "    # else:\n",
        "    # draw(g)\n",
        "    reg = re.sub(\".*NR_(?P<nr>\\d+)_NID_(?P<nid>\\d+)_ER_(?P<er>\\d+)_EID_(?P<eid>\\d+).gexf\", \"\\g<eid>\", filename)\n",
        "    ori = re.sub(\"(?P<t>.+?)_.*\", \"\\g<t>\", filename)\n",
        "    nr = int(re.sub(\".*NR_(?P<t>.+?)_.*\", \"\\g<t>\", filename))\n",
        "    nid = int(re.sub(\".*NID_(?P<t>.+?)_.*\", \"\\g<t>\", filename))\n",
        "    er = int(re.sub(\".*ER_(?P<t>.+?)_.*\", \"\\g<t>\", filename))\n",
        "    eid = int(re.sub(\".*EID_(?P<t>.+?).gexf\", \"\\g<t>\", filename))\n",
        "    gev = nr + nid + er + eid\n",
        "    # return [ori+'.gexf',str(nr)+str(nid)+str(er)+str(eid)]\n",
        "    return [ori + '.gexf', [nr, nid, er, eid]]\n",
        "    # print('ori',ori, 'nr',nr, 'nid',nid, 'er',er, 'eid',eid,'gev',gev)\n",
        "\n",
        "\n",
        "ori, ged = getFileInfo(\"4_NR_0_NID_4_ER_2_EID_5.gexf\")\n",
        "print(ori, ged)\n",
        "print(sum(ged))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVCp6S65A-7u",
        "outputId": "69d71574-a16c-401b-b81f-6fab230d62a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.gexf [0, 4, 2, 5]\n",
            "11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Baseline Model"
      ],
      "metadata": {
        "id": "ppBMYQ7QBEFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class TensorNetworkModule(torch.nn.Module):\n",
        "    def __init__(self, tensor_neurons, input_dim):\n",
        "        super(TensorNetworkModule, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.setup_weights()\n",
        "        self.init_parameters()\n",
        "\n",
        "    def setup_weights(self):\n",
        "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.input_dim, self.input_dim, self.tensor_neurons))\n",
        "        self.weight_matrix_block = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 2 * self.input_dim))\n",
        "        self.bias = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 1))\n",
        "\n",
        "    def init_parameters(self):\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix_block)\n",
        "        torch.nn.init.xavier_uniform_(self.bias)\n",
        "\n",
        "    def forward(self, embedding_1, embedding_2):\n",
        "        scoring = torch.mm(torch.t(embedding_1), self.weight_matrix.view(self.input_dim, -1))\n",
        "        scoring = scoring.view(self.input_dim, self.tensor_neurons)\n",
        "        scoring = torch.mm(torch.t(scoring), embedding_2)\n",
        "        combined_representation = torch.cat((embedding_1, embedding_2))\n",
        "        block_scoring = torch.mm(self.weight_matrix_block, combined_representation)\n",
        "        scores = torch.nn.functional.relu(scoring + block_scoring + self.bias)\n",
        "        return scores\n",
        "\n",
        "\n",
        "def graph_aggregation_layer(input, adj):\n",
        "    result = torch.mm(adj, input)\n",
        "    return result\n",
        "\n",
        "\n",
        "class TaGSim(torch.nn.Module):\n",
        "    def __init__(self, number_of_node_labels, number_of_edge_labels, tensor_neurons, bottle_neck_neurons):\n",
        "        super(TaGSim, self).__init__()\n",
        "        self.number_of_node_labels = len(number_of_node_labels)\n",
        "        self.number_of_edge_labels = len(number_of_edge_labels)\n",
        "        self.node_type = number_of_node_labels\n",
        "        self.edge_type = number_of_edge_labels\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.bottle_neck_neurons = bottle_neck_neurons\n",
        "        self.setup_layers()\n",
        "\n",
        "    def setup_layers(self):\n",
        "        self.feature_count = self.tensor_neurons\n",
        "\n",
        "        # self.tensor_network_nc = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        # self.tensor_network_in = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        # self.tensor_network_ie = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_ec = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_edge_labels)\n",
        "\n",
        "        # self.fully_connected_first_nc = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_nc = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_nc = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_nc = torch.nn.Linear(4, 1)\n",
        "\n",
        "        # self.fully_connected_first_in = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_in = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_in = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_in = torch.nn.Linear(4, 1)\n",
        "\n",
        "        # self.fully_connected_first_ie = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_ie = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_ie = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_ie = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_ec = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_ec = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_ec = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_ec = torch.nn.Linear(4, 1)\n",
        "\n",
        "    def gal_pass(self, edge_index, features):\n",
        "        hidden1 = graph_aggregation_layer(features, edge_index)\n",
        "        hidden2 = graph_aggregation_layer(hidden1, edge_index)\n",
        "\n",
        "        return hidden1, hidden2\n",
        "\n",
        "    def forward(self, label_multiset):\n",
        "        adj_1, adj_2 = torch.FloatTensor(np.array(label_multiset[\"node_index_1\"].todense())), torch.FloatTensor(\n",
        "            np.array(label_multiset[\"node_index_2\"].todense()))\n",
        "        edge_adj_1, edge_adj_2 = label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"]\n",
        "        node_features_1, node_features_2 = label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"]\n",
        "        edge_features_1, edge_features_2 = label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"]\n",
        "\n",
        "        #gal\n",
        "        graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, node_features_1)  #original graph node\n",
        "        graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, node_features_2)  #generated graph node\n",
        "        edge1_hidden1, edge1_hidden2 = self.gal_pass(edge_adj_1, edge_features_1)  #original edge node\n",
        "        edge2_hidden1, edge2_hidden2 = self.gal_pass(edge_adj_2, edge_features_2)  #generated graph edge\n",
        "        #node level embedding Concatenation\n",
        "        graph1_01concat = torch.cat([node_features_1, graph1_hidden1], dim=1)\n",
        "        graph2_01concat = torch.cat([node_features_2, graph2_hidden1], dim=1)\n",
        "        graph1_12concat = torch.cat([graph1_hidden1, graph1_hidden2], dim=1)\n",
        "        graph2_12concat = torch.cat([graph2_hidden1, graph2_hidden2], dim=1)\n",
        "        #graph pooling: node Sum\n",
        "        graph1_01pooled = torch.sum(graph1_01concat, dim=0).unsqueeze(1)\n",
        "        graph2_01pooled = torch.sum(graph2_01concat, dim=0).unsqueeze(1)\n",
        "        graph1_12pooled = torch.sum(graph1_12concat, dim=0).unsqueeze(1)\n",
        "        graph2_12pooled = torch.sum(graph2_12concat, dim=0).unsqueeze(1)\n",
        "        #edge level embedding Concatenation\n",
        "        edge1_01concat = torch.cat([edge_features_1, edge1_hidden1], dim=1)\n",
        "        edge2_01concat = torch.cat([edge_features_2, edge2_hidden1], dim=1)\n",
        "        #graph pooling: edge Sum\n",
        "        edge1_01pooled = torch.sum(edge1_01concat, dim=0).unsqueeze(1)\n",
        "        edge2_01pooled = torch.sum(edge2_01concat, dim=0).unsqueeze(1)\n",
        "\n",
        "        # scores_nc = self.tensor_network_nc(graph1_01pooled, graph2_01pooled)\n",
        "        # scores_nc = torch.t(scores_nc)\n",
        "        #\n",
        "        # scores_nc = torch.nn.functional.relu(self.fully_connected_first_nc(scores_nc))\n",
        "        # scores_nc = torch.nn.functional.relu(self.fully_connected_second_nc(scores_nc))\n",
        "        # scores_nc = torch.nn.functional.relu(self.fully_connected_third_nc(scores_nc))\n",
        "        # score_nc = torch.sigmoid(self.scoring_layer_nc(scores_nc))\n",
        "\n",
        "        # scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
        "        # scores_in = torch.t(scores_in)\n",
        "        #\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
        "        # scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
        "        # score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
        "\n",
        "        # scores_ie = self.tensor_network_ie(graph1_12pooled, graph2_12pooled)\n",
        "        # scores_ie = torch.t(scores_ie)\n",
        "        #\n",
        "        # scores_ie = torch.nn.functional.relu(self.fully_connected_first_ie(scores_ie))\n",
        "        # scores_ie = torch.nn.functional.relu(self.fully_connected_second_ie(scores_ie))\n",
        "        # scores_ie = torch.nn.functional.relu(self.fully_connected_third_ie(scores_ie))\n",
        "        # score_ie = torch.sigmoid(self.scoring_layer_ie(scores_ie))\n",
        "\n",
        "        scores_ec = self.tensor_network_ec(edge1_01pooled, edge2_01pooled)\n",
        "        scores_ec = torch.t(scores_ec)\n",
        "\n",
        "        scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
        "        scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
        "        scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
        "        score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
        "\n",
        "        return torch.cat([score_ec], dim=1)\n",
        "\n",
        "    def transform_label_multiset(self, graph_pair, type_specified=True):\n",
        "        graph1 = graph_pair['graph_pair'][0]\n",
        "        graph2 = graph_pair['graph_pair'][1]\n",
        "        ged = graph_pair['ged']\n",
        "        #node and edge info of pair graph\n",
        "        node_info1 = nx.get_node_attributes(graph1, 'label')\n",
        "        node_info2 = nx.get_node_attributes(graph2, 'label')\n",
        "        edge_info1 = nx.get_edge_attributes(graph1, 'id')\n",
        "        edge_info2 = nx.get_edge_attributes(graph2, 'id')\n",
        "        nodes1 = list(graph1.nodes())\n",
        "        nodes2 = list(graph2.nodes())\n",
        "        edges1 = list(graph1.edges())\n",
        "        edges2 = list(graph2.edges())\n",
        "\n",
        "        label_multiset = dict()\n",
        "        node_features_1, node_features_2, edge_features_1, edge_features_2, edge_adj_1, edge_adj_2 = [], [], [], [], [], []\n",
        "\n",
        "        for i in graph1.nodes():\n",
        "            node_features_1.append([1.0 if node_info1[i] == node else 0.0 for node in self.node_type])\n",
        "        for i in graph2.nodes():\n",
        "            node_features_2.append([1.0 if node_info2[i] == node else 0.0 for node in self.node_type])\n",
        "        node_features_1, node_features_2 = torch.FloatTensor(np.array(node_features_1)), torch.FloatTensor(\n",
        "            np.array(node_features_2))\n",
        "\n",
        "        for i in edges1:\n",
        "            edge_features_1.append([1.0 if edge_info1[i] == edge else 0.0 for edge in self.edge_type])\n",
        "            adj_row = []\n",
        "            for d in edges1:\n",
        "                if (i == d):\n",
        "                    adj_row.append(0.0)\n",
        "                    continue\n",
        "                if ((i[0] in d) | (i[1] in d)):\n",
        "                    adj_row.append(1.0)\n",
        "                else:\n",
        "                    adj_row.append(0.0)\n",
        "            edge_adj_1.append(adj_row)\n",
        "        for i in edges2:\n",
        "            edge_features_2.append([1.0 if edge_info2[i] == edge else 0.0 for edge in self.edge_type])\n",
        "            adj_row = []\n",
        "            for d in edges2:\n",
        "                if (i == d):\n",
        "                    adj_row.append(0.0)\n",
        "                    continue\n",
        "                if ((i[0] in d) | (i[1] in d)):\n",
        "                    adj_row.append(1.0)\n",
        "                else:\n",
        "                    adj_row.append(0.0)\n",
        "            edge_adj_2.append(adj_row)\n",
        "        edge_features_1, edge_features_2 = torch.FloatTensor(np.array(edge_features_1)), torch.FloatTensor(\n",
        "            np.array(edge_features_2))\n",
        "        edge_adj_1, edge_adj_2 = torch.FloatTensor(np.array(edge_adj_1)), torch.FloatTensor(np.array(edge_adj_2))\n",
        "\n",
        "        label_multiset[\"node_index_1\"], label_multiset[\"node_index_2\"] = nx.adjacency_matrix(\n",
        "            graph1), nx.adjacency_matrix(graph2)\n",
        "        label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"] = node_features_1, node_features_2\n",
        "        label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"] = edge_features_1, edge_features_2\n",
        "        label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"] = edge_adj_1, edge_adj_2\n",
        "\n",
        "        #ged normalisation\n",
        "        if (type_specified):  # for training\n",
        "            avg_node_number = 0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes())\n",
        "            norm_ged = [n / avg_node_number for n in ged]\n",
        "            norm_ged = np.array(norm_ged)\n",
        "            label_multiset[\"target\"] = torch.from_numpy(np.exp(-norm_ged)).view(1, -1).float()\n",
        "\n",
        "            norm_gt_ged = (len(ged)) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "        else:  # for testing\n",
        "            norm_gt_ged = (ged) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "\n",
        "        return label_multiset\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = 20\n",
        "tensor_neurons = 16\n",
        "bottle_neck_neurons = 16\n",
        "batch_size = 128\n",
        "dropout = 0.0\n",
        "lr = 0.001\n",
        "weight_decay = 0.0\n",
        "\n",
        "Node_Types = ['1']\n",
        "Edge_Types = ['1']\n",
        "#collection global node label and edge label info\n",
        "\n",
        "print(\"\\n-------Model training---------.\\n\")\n",
        "\n",
        "model = TaGSim(Node_Types, Edge_Types, tensor_neurons, bottle_neck_neurons)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "iteration = 0\n",
        "\n",
        "visual_loss_train = []\n",
        "test_scores = []\n",
        "visual_loss_test = []\n",
        "train_pair = []\n",
        "test_pair = []\n",
        "epo = []\n",
        "\n",
        "#model training\n",
        "for epoch in range(epochs):\n",
        "    random.shuffle(train_pairs)\n",
        "    batches = []\n",
        "    for graph in range(0, len(train_pairs), batch_size):\n",
        "        batches.append(train_pairs[graph:graph + batch_size])\n",
        "\n",
        "    for batch in batches:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        losses = 0\n",
        "        for graph_pair in batch:\n",
        "            data = model.transform_label_multiset(graph_pair)\n",
        "            prediction = model(data)\n",
        "            losses += torch.nn.functional.mse_loss(data[\"target\"], prediction)\n",
        "\n",
        "        losses.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        loss = losses.item()\n",
        "        print('Iteration', iteration, 'loss: ', loss / len(batch))\n",
        "        iteration += 1\n",
        "\n",
        "    visual_loss_train.append(loss / len(batch))\n",
        "    # testing\n",
        "    model.eval()\n",
        "    for n in test_pairs:\n",
        "        graph1 = n['graph_pair'][0]  #updated_test\n",
        "        graph2 = n['graph_pair'][1]  #updated_test\n",
        "        ged = int(n['gt_ged'])\n",
        "        tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "        data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "        prediction = model(data)\n",
        "        prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "        current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "        test_scores.append(current_error.data.item())\n",
        "    visual_loss_test.append(sum(test_scores) / len(test_scores))\n",
        "    epo.append(epoch + 1)\n",
        "\n",
        "#visualization of traning and testing loss\n",
        "plt.plot(epo, visual_loss_train, 'g', label='Training Loss')\n",
        "plt.plot(epo, visual_loss_test, 'b', label='Validation Loss')\n",
        "plt.title('Evaluation of TaGSim Model without NID process (' + DATASET + ')')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n-------Model testing---------.\\n\")\n",
        "\n",
        "model.eval()\n",
        "test_scores = []\n",
        "for n in test_pairs:\n",
        "    graph1 = n['graph_pair'][0]  #updated_test\n",
        "    graph2 = n['graph_pair'][1]  #updated_test\n",
        "    ged = int(n['gt_ged'])\n",
        "    tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "    data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "    prediction = model(data)\n",
        "    prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "    current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "    test_scores.append(current_error.data.item())\n",
        "\n",
        "model_error = sum(test_scores) / len(test_scores)\n",
        "print(\"\\nModel test error: \" + str(model_error))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-i6Lre4sBIMt",
        "outputId": "622b26cd-db94-4882-e38f-f2cfefa65cc4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model training---------.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:261: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0 loss:  0.22370262444019318\n",
            "Iteration 1 loss:  0.20708738267421722\n",
            "Iteration 2 loss:  0.2147359699010849\n",
            "Iteration 3 loss:  0.19310010969638824\n",
            "Iteration 4 loss:  0.19087570905685425\n",
            "Iteration 5 loss:  0.17598330974578857\n",
            "Iteration 6 loss:  0.14626234769821167\n",
            "Iteration 7 loss:  0.11811263114213943\n",
            "Iteration 8 loss:  0.09917200356721878\n",
            "Iteration 9 loss:  0.08099988102912903\n",
            "Iteration 10 loss:  0.05367020145058632\n",
            "Iteration 11 loss:  0.0592331625521183\n",
            "Iteration 12 loss:  0.0583929605782032\n",
            "Iteration 13 loss:  0.04095064103603363\n",
            "Iteration 14 loss:  0.042949266731739044\n",
            "Iteration 15 loss:  0.046263281255960464\n",
            "Iteration 16 loss:  0.04114723950624466\n",
            "Iteration 17 loss:  0.0464201383292675\n",
            "Iteration 18 loss:  0.041775256395339966\n",
            "Iteration 19 loss:  0.04549392561117808\n",
            "Iteration 20 loss:  0.039666350930929184\n",
            "Iteration 21 loss:  0.038455501198768616\n",
            "Iteration 22 loss:  0.039704665541648865\n",
            "Iteration 23 loss:  0.03895789757370949\n",
            "Iteration 24 loss:  0.03614316135644913\n",
            "Iteration 25 loss:  0.03857390955090523\n",
            "Iteration 26 loss:  0.03622332215309143\n",
            "Iteration 27 loss:  0.037984102964401245\n",
            "Iteration 28 loss:  0.0376097597181797\n",
            "Iteration 29 loss:  0.03489214678605398\n",
            "Iteration 30 loss:  0.032957494258880615\n",
            "Iteration 31 loss:  0.038620736449956894\n",
            "Iteration 32 loss:  0.03674769029021263\n",
            "Iteration 33 loss:  0.03646163269877434\n",
            "Iteration 34 loss:  0.03800434619188309\n",
            "Iteration 35 loss:  0.03224477916955948\n",
            "Iteration 36 loss:  0.03554627299308777\n",
            "Iteration 37 loss:  0.036155253648757935\n",
            "Iteration 38 loss:  0.03778805956244469\n",
            "Iteration 39 loss:  0.03596350053946177\n",
            "Iteration 40 loss:  0.03552873432636261\n",
            "Iteration 41 loss:  0.03979092091321945\n",
            "Iteration 42 loss:  0.03267233073711395\n",
            "Iteration 43 loss:  0.036841217428445816\n",
            "Iteration 44 loss:  0.03191305324435234\n",
            "Iteration 45 loss:  0.03283288702368736\n",
            "Iteration 46 loss:  0.03540932759642601\n",
            "Iteration 47 loss:  0.03286748379468918\n",
            "Iteration 48 loss:  0.03393717482686043\n",
            "Iteration 49 loss:  0.03584838410218557\n",
            "Iteration 50 loss:  0.03039795719087124\n",
            "Iteration 51 loss:  0.037238236516714096\n",
            "Iteration 52 loss:  0.032227981835603714\n",
            "Iteration 53 loss:  0.034437645226716995\n",
            "Iteration 54 loss:  0.031409505754709244\n",
            "Iteration 55 loss:  0.03224073350429535\n",
            "Iteration 56 loss:  0.036017559468746185\n",
            "Iteration 57 loss:  0.03391453996300697\n",
            "Iteration 58 loss:  0.029578575864434242\n",
            "Iteration 59 loss:  0.03043515235185623\n",
            "Iteration 60 loss:  0.03421759232878685\n",
            "Iteration 61 loss:  0.03455854207277298\n",
            "Iteration 62 loss:  0.0282937902957201\n",
            "Iteration 63 loss:  0.02928934246301651\n",
            "Iteration 64 loss:  0.030151765793561935\n",
            "Iteration 65 loss:  0.030820276588201523\n",
            "Iteration 66 loss:  0.03254253789782524\n",
            "Iteration 67 loss:  0.030366363003849983\n",
            "Iteration 68 loss:  0.03382467105984688\n",
            "Iteration 69 loss:  0.02729835609594981\n",
            "Iteration 70 loss:  0.028774837031960487\n",
            "Iteration 71 loss:  0.03216823935508728\n",
            "Iteration 72 loss:  0.03635415434837341\n",
            "Iteration 73 loss:  0.03089108131825924\n",
            "Iteration 74 loss:  0.027993468567728996\n",
            "Iteration 75 loss:  0.027818353846669197\n",
            "Iteration 76 loss:  0.030850885435938835\n",
            "Iteration 77 loss:  0.0289973933249712\n",
            "Iteration 78 loss:  0.028219232335686684\n",
            "Iteration 79 loss:  0.02571020523707072\n",
            "Iteration 80 loss:  0.028072670102119446\n",
            "Iteration 81 loss:  0.029010986909270287\n",
            "Iteration 82 loss:  0.030972039327025414\n",
            "Iteration 83 loss:  0.029755370691418648\n",
            "Iteration 84 loss:  0.02872634306550026\n",
            "Iteration 85 loss:  0.03125644847750664\n",
            "Iteration 86 loss:  0.029746193438768387\n",
            "Iteration 87 loss:  0.024982327595353127\n",
            "Iteration 88 loss:  0.02952682226896286\n",
            "Iteration 89 loss:  0.025705789526303608\n",
            "Iteration 90 loss:  0.02904936857521534\n",
            "Iteration 91 loss:  0.02530135028064251\n",
            "Iteration 92 loss:  0.031208660453557968\n",
            "Iteration 93 loss:  0.029774097725749016\n",
            "Iteration 94 loss:  0.02822706289589405\n",
            "Iteration 95 loss:  0.02636587619781494\n",
            "Iteration 96 loss:  0.030066771432757378\n",
            "Iteration 97 loss:  0.025214310735464096\n",
            "Iteration 98 loss:  0.03174544870853424\n",
            "Iteration 99 loss:  0.02271715799967448\n",
            "Iteration 100 loss:  0.02982497215270996\n",
            "Iteration 101 loss:  0.02913098968565464\n",
            "Iteration 102 loss:  0.02706035040318966\n",
            "Iteration 103 loss:  0.027554048225283623\n",
            "Iteration 104 loss:  0.026689473539590836\n",
            "Iteration 105 loss:  0.024615760892629623\n",
            "Iteration 106 loss:  0.03047405369579792\n",
            "Iteration 107 loss:  0.030219413340091705\n",
            "Iteration 108 loss:  0.026570413261651993\n",
            "Iteration 109 loss:  0.02430810034275055\n",
            "Iteration 110 loss:  0.023805996403098106\n",
            "Iteration 111 loss:  0.030276639387011528\n",
            "Iteration 112 loss:  0.025932850316166878\n",
            "Iteration 113 loss:  0.027003029361367226\n",
            "Iteration 114 loss:  0.029671361669898033\n",
            "Iteration 115 loss:  0.028115173801779747\n",
            "Iteration 116 loss:  0.026293504983186722\n",
            "Iteration 117 loss:  0.026767080649733543\n",
            "Iteration 118 loss:  0.029864031821489334\n",
            "Iteration 119 loss:  0.02734713504711787\n",
            "Iteration 120 loss:  0.026835719123482704\n",
            "Iteration 121 loss:  0.0255923792719841\n",
            "Iteration 122 loss:  0.02580893039703369\n",
            "Iteration 123 loss:  0.028993770480155945\n",
            "Iteration 124 loss:  0.029799191281199455\n",
            "Iteration 125 loss:  0.024891262874007225\n",
            "Iteration 126 loss:  0.027467528358101845\n",
            "Iteration 127 loss:  0.02696109563112259\n",
            "Iteration 128 loss:  0.02918017841875553\n",
            "Iteration 129 loss:  0.0286570539077123\n",
            "Iteration 130 loss:  0.026292428374290466\n",
            "Iteration 131 loss:  0.03004818968474865\n",
            "Iteration 132 loss:  0.026906413957476616\n",
            "Iteration 133 loss:  0.02943405695259571\n",
            "Iteration 134 loss:  0.02542838454246521\n",
            "Iteration 135 loss:  0.023818109184503555\n",
            "Iteration 136 loss:  0.02619706094264984\n",
            "Iteration 137 loss:  0.027400517836213112\n",
            "Iteration 138 loss:  0.029956435784697533\n",
            "Iteration 139 loss:  0.025135045250256855\n",
            "Iteration 140 loss:  0.027138320729136467\n",
            "Iteration 141 loss:  0.03120693378150463\n",
            "Iteration 142 loss:  0.02980802394449711\n",
            "Iteration 143 loss:  0.026190264150500298\n",
            "Iteration 144 loss:  0.025106754153966904\n",
            "Iteration 145 loss:  0.02578509785234928\n",
            "Iteration 146 loss:  0.028362981975078583\n",
            "Iteration 147 loss:  0.02522379159927368\n",
            "Iteration 148 loss:  0.023685459047555923\n",
            "Iteration 149 loss:  0.029060567418734234\n",
            "Iteration 150 loss:  0.02465398609638214\n",
            "Iteration 151 loss:  0.028758782893419266\n",
            "Iteration 152 loss:  0.026592064648866653\n",
            "Iteration 153 loss:  0.02653282880783081\n",
            "Iteration 154 loss:  0.026712574064731598\n",
            "Iteration 155 loss:  0.024341575801372528\n",
            "Iteration 156 loss:  0.03027857467532158\n",
            "Iteration 157 loss:  0.02488071657717228\n",
            "Iteration 158 loss:  0.030085735023021698\n",
            "Iteration 159 loss:  0.026254331072171528\n",
            "Iteration 160 loss:  0.02567995898425579\n",
            "Iteration 161 loss:  0.025899019092321396\n",
            "Iteration 162 loss:  0.02435302734375\n",
            "Iteration 163 loss:  0.028002595528960228\n",
            "Iteration 164 loss:  0.024548713117837906\n",
            "Iteration 165 loss:  0.025622393935918808\n",
            "Iteration 166 loss:  0.028239423409104347\n",
            "Iteration 167 loss:  0.028427865356206894\n",
            "Iteration 168 loss:  0.031214118003845215\n",
            "Iteration 169 loss:  0.025478877127170563\n",
            "Iteration 170 loss:  0.02668086439371109\n",
            "Iteration 171 loss:  0.026948925107717514\n",
            "Iteration 172 loss:  0.028401842340826988\n",
            "Iteration 173 loss:  0.024712631478905678\n",
            "Iteration 174 loss:  0.02619185484945774\n",
            "Iteration 175 loss:  0.0246996209025383\n",
            "Iteration 176 loss:  0.028354492038488388\n",
            "Iteration 177 loss:  0.02927548810839653\n",
            "Iteration 178 loss:  0.026544492691755295\n",
            "Iteration 179 loss:  0.02337261289358139\n",
            "Iteration 180 loss:  0.02663560025393963\n",
            "Iteration 181 loss:  0.028834659606218338\n",
            "Iteration 182 loss:  0.028920819982886314\n",
            "Iteration 183 loss:  0.024245833978056908\n",
            "Iteration 184 loss:  0.027648990973830223\n",
            "Iteration 185 loss:  0.02324211597442627\n",
            "Iteration 186 loss:  0.02504449337720871\n",
            "Iteration 187 loss:  0.025623831897974014\n",
            "Iteration 188 loss:  0.028439639136195183\n",
            "Iteration 189 loss:  0.02906692773103714\n",
            "Iteration 190 loss:  0.026533421128988266\n",
            "Iteration 191 loss:  0.026218874379992485\n",
            "Iteration 192 loss:  0.02726258710026741\n",
            "Iteration 193 loss:  0.02228432334959507\n",
            "Iteration 194 loss:  0.029768601059913635\n",
            "Iteration 195 loss:  0.028448820114135742\n",
            "Iteration 196 loss:  0.02750704251229763\n",
            "Iteration 197 loss:  0.026406962424516678\n",
            "Iteration 198 loss:  0.02565794810652733\n",
            "Iteration 199 loss:  0.023649193346500397\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEWCAYAAACe8xtsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hUZfbA8e8hQEKHhB5AooCCdEIsFEFdRFFQbCCsYGPVBVdd97eua8G6uuuuir2BIiBiY7GiCwoKFgKEJoIhIITeiwmQcn5/vHfCJEwaycyknM/z3Gdmbptz79y5577ve4uoKsYYY0xxVAl3AMYYY8ofSx7GGGOKzZKHMcaYYrPkYYwxptgseRhjjCk2Sx7GGGOKzZJHCYjI1yJyY5DmfY+IvBaMeRfyvZeJyCYROSQi3UL9/YGIyAgR+SLccRRERN4QkUeKOO4GETm/hN/3mYiMKo14TPiJyD9E5PYyEEekiPwsIo0KG7dSJA/vz5ru7RB93XPhjstHRPqJSKp/P1V9TFWDkpgK8SQwVlVrq+pSX08RaZVn/amI/Ob3uU9+MxSR6iJyv4is8abZ7O38BviN01tEForIfhHZIyILRKQngKpOVdUB+c2/OERktBf7U3n6D/H6v1Ea3xNsqnqhqr4JOcv0bSi+V0Rae+upagHjjPfGucqvX1WvX2vvc05y85unb1vaLiIfi8jvgr08ZYG3o74WeNn7nGt/4B2kqoh0yTPdh17/ft7n8SKSISIHvW6tiDwnIs38puknItl+63qziDzoG66qR4CJwN2FxV0pkofnEm+H6OvGhjugMuokYFXenqq60X/9eb27+PX7poB5vgcMwf1BGgBxwDPAIAARqQt8DDwLRAOxwIPAkVJaprzWAVfl2QGOAtYG6fsqoz3AgyISUYxp6nvbVhfgS+BDERldGsEUlOzKgNHAp6qaXsA4a3H/HwBEJAY4C9iZZ7x3VLUO7n90GdAUWOyfQIAtfv/j3sANInKp3/BpwCgRiSwo6MqUPI7jFdH2iUhHv36NvFJKYxFp4B0B7RSRvd77FvnMa7yITPH7nOsITUSuE5HV3hFBioj8wetfC/gMaO53NNA8wPwGi8gqL96vRaS937ANInKXiCz3jtzfEZGofOKsIiL3isivIrJDRCaLSD1vXRwCIoBlIrKuGOtxkIgsFZED4qq8xvsNOx/4HTBEVX9Q1aNe97mq/skbrR2Aqr6tqlmqmq6qX6jqcm8euY6svfV6q4j84q3Ph0XkFK/kckBEZohI9QJC3gasAC7w5hcNnA3MyrNcBa3zbiKyxPv+d4CoPNNeLCJJ3rQLRaRzEdZjnDd+Fe/zqyKyw2/4W+JVbXjx3OjF9BJwlrft7PObZQMR+cSL8QcROcVvXmeLyCJve1kkImf7DctVrZZnW5zvve7zvu+sfBbnc+AoMLKw5c5LVbep6jPAeOAJ3/rIy9sObvP+T7tE5F9+6260uNLrUyKyGxjvbeeTvf/zr97/oIrf/G7y+4/+JCLdvf7NReR9b7r1InKb3zQJIpLobXfbReQ/Xv8oEZkiIru933SRiDTJZ5EvBOYVslqmAlfLsWQ8HPgQt44DrcMMVV0FXI1LMH/OZ7z1wEKgg1+/VGAvcGZBAVXq5OEV0T7A/RA+VwHzVHUHbv1Mwh2NtwLSgROt7toBXAzUBa4DnhKR7qr6G27j2eJ3FL/Ff0IRaQe8DdwONAI+BT7Ks4O8ChiIO6rvjDuaCWS01/UHTgZqA8+p6pE8JYpTAk8e0G+4o6L6uNLELXLsSOZ84Advg8zPWiBLRN4UkQtFpEERvvMCoAduA/8/4BXcjqol0JHcv2kgkzl2JDcM+C9+JZ2C1rm33mcCb+GO8N4FLvebthuu6P8HIAZXHTFLCjmS8/7IBwBfW1Nf4JBf0jqHPDsZVV0N3Ax852079f0GD8OV4BoAycCjXnzRwCfABC++/wCfiDuaLUxf77W+933f5bc4wH3AAyJSrQjzDeQDoDFwagHjXAbEA91xpdvr/YadAaQATXDL/ixQD7fdn4P7/a8DEJErccnqWtx/dDCw20suHwHLcCXi84DbReQC7zueAZ5R1brAKcAMr/8o77ta4tbxzbj9RyCdgDUFrQhgC/AT4Ku+vRa3DRdIVbNw23bAamURaQv0Ar7PM2g1rgSYr8qUPGZ6RwC+7iav/zTcn8znGq8fqrpbVd9X1TRVPYjbAM85kS9X1U9UdZ0684AvyOcHDeBq4BNV/VJVM3DtEjVwR8s+E1R1i6ruwW3sXfOZ1wjgP6qaoqqHgL8Bw6QExXpV/VpVV6hqtldaeJtj66kh7kgfcDsub/3vF5HD3vQHcMVnBV4FdorIrAKO1AD+qaoHvKOrlcAX3jLtx5XkCmvs/xDoJyL1CPxHLGidnwlUA572jvDeAxb5TTsGeNkraWV5bRNHKORIzjMPOEdEmnqf3/M+x+F2asuKMI+cZVTVH1U1E3fk6tsmBgG/qOpbqpqpqm8DPwOXFGPehVLVWbij3hNtu/MdREUXMM4TqrpHVTcCT5P7oGGLqj7rLf9R3P/8b6p6UFU3AP8Gfu+NeyNum1rk/UeTVfVXoCfQSFUf8krMKbht1LfPyADaiEhDVT2kqt/79Y8B2njbwGJvOw+kPnCwCOtjMnCtiJyGS975Je68tpB7HTb3/oMHcAduPwB528wOenHlqzIlj0tVtb5f96rX/yugpoicIa4xrytux4KI1BSRl70i7gFckb2+FK8eF29eF4rI9+Iag/cBF+F2rEXRHPjV90FVs4FNuCMhn21+79NwJYpC5+W9r4o7Ojsh3rr7yivW78cdZfmWbTeQU9/q/dHr40oNkX79V6vqaFVtgSs5NMftDPKz3e99eoDP+S2/7/vScUff9wIxqrogzygFrfPmwGbVXHcV9V+nJwF/9j9YwR2BNi8oJs88oB/uCH8+8DUuEZ8DfOPFUVT5bRN5twFf/LGUvnuBv5OnWq+IfPHsKWCcTX7vfyX3OvYf1hCX8PNu+77vaIlrC8vrJI7tbH2/5T0c+7/cgKt2/dmrmrrY6/8WMBuYLiJbROSfBZTA9gJ1ClhGnw+Ac4Gx3vyLKpbc63CLtw+si0sQ6cCbeaapA+yjAJUpeQTkFetm4I5YhgMfe6UMcPWEpwJneCvaV2SXALP6Dajp99l35IhXXfE+7ui1ibfz/NRvPoXd2ngLbiP2zU9wG/vmwpavsHnhquMyyb3zLa5puPaClqpaD1cH71u2OUBPyaetKBBV/Rl4A5dEgmky7jeeEmBYQet8KxDr9fNp5fd+E/BonoOVmt4RfmHm4Uqk/bz33+KqFY6rsvJT3Ftj590GwMXv257y3ZaL+12q+iWuyuzWYsYIrkpqBwVX6bT0e9+KY6UVyB3rLlxpIO+271vmTbhqp7w2Aevz/JZ1VPUiAFX9RVWH46rXngDeE5FaXon0QVXtgCutXoxfg3cey/Ha/Qqiqmm4UvUtFDF5eNVulwABT2jxSurTOL7U2Z5CSrmVPnl4puGqKUZ4733q4LLyPq+e+IEC5pEE9BV3Sms9XHWQT3XcUfZOIFNELuRY3SW4HXeMN10gM4BBInKed/TyZ1w1yMKiLqCft4E7xDXO1gYew52hkXkC8/KpA+xR1cMikoCr+gNAVb/Ale5meiWU6t4y5FThiMhpIvJnX4IRkZa4RJ63Hra0zcM15j8bYFhB6/w7XMK9TUSqichQIMFv2leBm73lFRGpJe6kgkKPLlX1F9w2NxLX9nYAt31cTv7JYzvQQgo+ScDfp0A7EblG3Cm0V+MaTD/2hifhqjKriUg8cIXftDuBbFy7QVH9HdcuVSQi0kRExuL+b38rpLT1F3EntrQE/gS8E2gkv4PER0WkjoicBNzJsQOH14C7RKSH95u18cb5ETgoIn8VkRoiEiEiHcU7jVxERopIIy9G35F6toj0F5FOXi3FAVziym85PqXo1eH3AOd41W758n7X9rj/e1Ncu1ag8WrjquBW+fWLxVVzFfj/q0zJ4yPJfZ3Ch74BqvoD7mirOS6z+zyNq+fehVuRn+c3c+8I6x3cUcRijv0R8Uoyt+E23r24nessv+E/437kFK9onKt6Q1XX4HYmz3qxXII79TjgmRaFmIg7apkPrAcOA+NOYD7+bgUeEpGDwP0cazT0uQy3Pqbg/mDrcYna1+h4ENe4+YOI/IZb1yvJ5wyR0uLVbc/x2onyDst3nXvrfSjuxIM9uAOPD/ymTQRuwp1csRd35D26GKHNA3ar6ia/zwIsyWf8ubg//zYR2VXYzFV1N+5I+M+4asX/Ay5WVd+09+GOwvfiGtyn+U2bhmv7W+Btq4W243hVgj8WNh7uIO033JlwFwFXqurEQqb5L+7/loSrhny9gHHH4f7nKbgS3TTc/wFVfRe3XNNw2+NMINpLOhfjqrPX47aF13CN4eBOUlkl7kzFZ4BhXpVoU1x71QFc4/M88i8tTAYuEpEahSwrXrtmQdf0XO3Fsh+3j9kN9NDcJ+HknNmJq7qLxv0ffa4B3lR3QlG+RO1hUMaYckhEFGirqsnhjqWkROQxYIeqFtTOF4o4InHVVX3VnXGa/7iWPIwx5VFFSh7lUWWqtjLGGFNKrORhjDGm2KzkYYwxptjK8s3CSk3Dhg21devW4Q7DGGPKlcWLF+9S1YC3Z68UyaN169YkJiaGOwxjjClXRCTvnQhyWLWVMcaYYrPkYYwxptgseRhjjCm2StHmEUhGRgapqakcPnw43KGYIoqKiqJFixZUq3aij4cwxpSWSps8UlNTqVOnDq1btyb3zVFNWaSq7N69m9TUVOLi4sIdjjGVXqWttjp8+DAxMTGWOMoJESEmJsZKisaUEZU2eQCWOMoZ+72MKTsqbbWVMcZUBNnZsH8/7N4Nu3a5V//uz3+GBg1K/3steYTJ7t27Oe+88wDYtm0bERERNGrkLuT88ccfqV49/+f6JCYmMnnyZCZMmFDgd5x99tksXHgiz4vK7euvv+bJJ5/k448/LnxkY8wJO3oU9uw5PgEESgq+fnv2uAQSSEQEXHONJY8KJSYmhqSkJADGjx9P7dq1ueuuu3KGZ2ZmUrVq4J8nPj6e+Pj4Qr+jNBKHMab4VOG339wOPtCOP7/u4MH85xkVBTEx0LChe+3cOfdnX+f/uV49CFZtryWPMmT06NFERUWxdOlSevXqxbBhw/jTn/7E4cOHqVGjBpMmTeLUU0/NVRIYP348GzduJCUlhY0bN3L77bdz2223AVC7dm0OHTrE119/zfjx42nYsCErV66kR48eTJkyBRHh008/5c4776RWrVr06tWLlJSUIpcw3n77bR577DFUlUGDBvHEE0+QlZXFDTfcQGJiIiLC9ddfzx133MGECRN46aWXqFq1Kh06dGD69OnBXJXGlCpfMti503U7dhT+Pj09//nVr39sB9+4MbRvnzsB5O0aNoSaNfOfXzhY8gBu//x2krYlleo8uzbtytMDi/9QsNTUVBYuXEhERAQHDhzgm2++oWrVqvzvf//jnnvu4f333z9ump9//pmvvvqKgwcPcuqpp3LLLbccdy3E0qVLWbVqFc2bN6dXr14sWLCA+Ph4/vCHPzB//nzi4uIYPnx4kePcsmULf/3rX1m8eDENGjRgwIABzJw5k5YtW7J582ZWrlwJwL597rHOjz/+OOvXrycyMjKnnzHhlp3tdvRbt8KWLcd3W7ceSwj5JYOoKJcAGjVyr6ef7t77urylgQYNIJ9KhXKlAixCxXLllVcSEREBwP79+xk1ahS//PILIkJGRkbAaQYNGkRkZCSRkZE0btyY7du306JFi1zjJCQk5PTr2rUrGzZsoHbt2px88sk5100MHz6cV155pUhxLlq0iH79+uW004wYMYL58+dz3333kZKSwrhx4xg0aBADBgwAoHPnzowYMYJLL72USy+9tPgrxphiUHVtAYESgn+3bRtkZh4/fePG0Lw5NG0KHTocSw6+zv9zrVrBqxoqyyx5wAmVEIKlVq1aOe/vu+8++vfvz4cffsiGDRvo169fwGkiIyNz3kdERJAZ4N9QlHFKQ4MGDVi2bBmzZ8/mpZdeYsaMGUycOJFPPvmE+fPn89FHH/Hoo4+yYsWKfNt0jCnI0aOuRLB5c8FdoEuCoqNdUmje3CUF33v/rkkTKOB8FeOxf28Ztn//fmJjYwF44403Sn3+p556KikpKWzYsIHWrVvzzjvvFHnahIQEbrvtNnbt2kWDBg14++23GTduHLt27aJ69epcfvnlnHrqqYwcOZLs7Gw2bdpE//796d27N9OnT+fQoUPUr1+/1JfJlG/Z2S4xrF/vul9/hdTU3Elhx47jp4uMhNhY1/XsCZdeCi1auGQQG+temzVzVUymdAQ1eYjIQOAZIAJ4TVUfzzP8TuBGIBPYCVyvqr96w0YB93qjPqKqb3r9ewBvADWAT4E/aQV9lu7//d//MWrUKB555BEGDRpU6vOvUaMGL7zwAgMHDqRWrVr07Nkz33HnzJmTqyrs3Xff5fHHH6d///45DeZDhgxh2bJlXHfddWR75w7+4x//ICsri5EjR7J//35Uldtuu80SRyWlCnv3usSQknIsSfgniyNHck/TsOGxxBAff+y9fxcdXTmrjsIpaM8wF5EIYC3wOyAVWAQMV9Wf/MbpD/ygqmkicgvQT1WvFpFoIBGIBxRYDPRQ1b0i8iNwG/ADLnlMUNXPCoolPj5e8z4MavXq1bRv376Ulrb8OnToELVr10ZV+eMf/0jbtm254447wh1Wvux3K/sOH4YNG2DdusAJ4sCB3ONHR0NcXODupJOstBBOIrJYVQNeFxDMkkcCkKyqKV4Q04EhQE7yUNWv/Mb/Hhjpvb8A+FJV93jTfgkMFJGvgbqq+r3XfzJwKVBg8jD5e/XVV3nzzTc5evQo3bp14w9/+EO4QzJlnKq7dsGXHFJSjr1ft85VLfmrWfNYMujb9/gEUbdueJbDlEwwk0cssMnvcypwRgHj38CxJBBo2livSw3Q/zgiMgYYA9CqVavixF2p3HHHHWW6pGHC4+hRV4WUNzn43h86lHv85s3hlFPg/PPd68knu9e4OHdmklUpVTxlosFcREbiqqjOKa15quorwCvgqq1Ka77GVASq7jRVX7VS3tfUVDeOT2TksYRwzjnH3p98sksQNWqEb1lMeAQzeWwGWvp9buH1y0VEzgf+Dpyjqkf8pu2XZ9qvvf4t8vQ/bp7GGFc68JUWfInBvw0i76mszZu7RNCv37GkEBfnkkSzZlClUt+D2+QVzOSxCGgrInG4Hfww4Br/EUSkG/AyMFBV/U/Amw08JiK+23kNAP6mqntE5ICInIlrML8WeDaIy2BMmZaW5qqRfvnl+G7r1tzj1qnjksJpp8GFFx5LECef7BqmrfRgiiNoyUNVM0VkLC4RRAATVXWViDwEJKrqLOBfQG3gXe9ZDRtVdbCXJB7GJSCAh3yN58CtHDtV9zOssdxUcIcP558g8jZON24MbdvCBRe411NOOdb2YKezmtIU1DYPVf0Udzqtf7/7/d6fX8C0E4GJAfonAh1LMcyw6N+/P3fffTcXXHBBTr+nn36aNWvW8OKLLwacpl+/fjz55JPEx8dz0UUXMW3atOOulwh0h968Zs6cSbt27ejQoQMA999/P3379uX88/P9OYrEbt1eMtnZrlopKQmWLnWvK1fCpk252x8aNnSJ4bzzoE0b975tW/e+Xr3wxW8qlzLRYF4ZDR8+nOnTp+dKHtOnT+ef//xnkab/9NNPCx8pHzNnzuTiiy/OSR4PPfTQCc/LnJgjR2DVqmNJIikJli07dkvuiAh3+4zevaFdu2MJom1bd0dWY8LNmsDC5IorruCTTz7h6NGjAGzYsIEtW7bQp08fbrnlFuLj4zn99NN54IEHAk7funVrdu3aBcCjjz5Ku3bt6N27N2vWrMkZ59VXX6Vnz5506dKFyy+/nLS0NBYuXMisWbP4y1/+QteuXVm3bh2jR4/mvffeA9yV5N26daNTp05cf/31HPEu923dujUPPPAA3bt3p1OnTvz8889FXta3336bTp060bFjR/76178CkJWVxejRo+nYsSOdOnXiqaeeAmDChAl06NCBzp07M2zYsGKu1bJp71746it46ikYNco9h6F2bejRA268Ed54w5UsRo2C116DxETX2L18OUydCg884B7o07OnJQ5TdljJA7j9dnfkV5q6doWnC7jfYnR0NAkJCXz22WcMGTKE6dOnc9VVVyEiPProo0RHR5OVlcV5553H8uXL6dy5c8D5LF68mOnTp5OUlERmZibdu3enR48eAAwdOpSbbroJgHvvvZfXX3+dcePGMXjwYC6++GKuuOKKXPM6fPgwo0ePZs6cObRr145rr72WF198kdtvvx2Ahg0bsmTJEl544QWefPJJXnvttULXQ2W7dfuRI7BkCXz3nesWLXLXS/g0awbdusEll7htpFs312BtZzKZ8sY22TDyVV2Bq7LyPU9jxowZdO/enW7durFq1Sp++umnfOfxzTffcNlll1GzZk3q1q3L4MGDc4atXLmSPn360KlTJ6ZOncqqVasKjGfNmjXExcXRrl07AEaNGsX8+fNzhg8dOhSAHj16sGHDhiIto/+t26tWrZpz6/aTTz4559btn3/+OXW9y4x9t26fMmVKubjrbmoqvPsu3HknnHWWu1r67LPdc6MTE+HMM+Hxx+Hzz911FVu2wCefwKOPwpVXunYKSxymPCr7/84QKKiEEExDhgzhjjvuYMmSJaSlpdGjRw/Wr1/Pk08+yaJFi2jQoAGjR4/mcKB7SxfB6NGjmTlzJl26dOGNN97g66+/LlG8vtu6l8Yt3cvjrduPHnVtFL5SxXffucZscBfRxcfDbbe5JHLWWa6UYUxFZcc8YVS7dm369+/P9ddfn1PqOHDgALVq1aJevXps376dzz4r+Ezkvn37MnPmTNLT0zl48CAfffRRzrCDBw/SrFkzMjIymDp1ak7/OnXqcDDAw5JPPfVUNmzYQHJyMgBvvfUW55xTsov+ExISmDdvHrt27SIrK4u3336bc845h127dpGdnc3ll1/OI488wpIlS3Lduv2JJ55g//79HMp7H4wQ2rYN3n8f7roLevVypYozz4Q77oDvv3cljKefhh9+cDf7+/Zb+Ne/YOhQSxym4isbh3SV2PDhw7nssstyqq+6dOlCt27dOO2002jZsiW9evUqcPru3btz9dVX06VLFxo3bpzrtuoPP/wwZ5xxBo0aNeKMM87ISRjDhg3jpptuYsKECTkN5QBRUVFMmjSJK6+8kszMTHr27MnNN99crOUpr7duV4W1a10C+OYb97punRsWGekat8eOPVaqaN48JGEZU2YF7ZbsZYndkr3iKK3fLSPDVUH5EsW337o7xYK7jqJ3b+jTx5UuunVzCcSYyiZct2Q3psw4eNC1UfgSxfffQ3q6G9amDVx8sUsYvusq7EpsYwpmycNUOKquIfu772DhQpcskpLcFdxVqriSxJgxLlH06mXtE8aciEqdPFQVsUPMciO/KtbDh2HxYlea8J0FtWWLG1azpmvkvvdeVw11xhnuBoHGmJKptMkjKiqK3bt3ExMTYwmkHFBVdu/eTVRUFBs35j5ddulS14YBx24p7mvY7twZqlULa+jGVEiVNnm0aNGC1NRUdu7cGe5QTAFU3fUVhw/Dpk1R3H9/C3x3RqlRw92yw3eB3plnQpMm4Y3XmMqi0iaPatWqERcXF+4wTB5798KCBe4sqPnzXXWUf6nirLPgj3+0UoUx4VZpk4cpG7ZtO5YovvnG3QxQ1SWFnj3dBXlnn22lCmPKGkseJmRUYcOGY4li/nz3QCOAWrVcaeLBB481bNuT7Ywpuyx5mKBRhZ9+yp0sfE++a9DAJYkxY6BvX3f6rFVBGVN+BDV5iMhA4BncY2hfU9XH8wzvCzwNdAaGqep7Xv/+wFN+o57mDZ8pIm8A5wD7vWGjVbWUb6huTtTBg/C//7k7x37yiauWAnc7jz59XKLo29c96MjuJmtM+RW05CEiEcDzwO+AVGCRiMxSVf/7i28ERgO5npmqql8BXb35RAPJwBd+o/zFl2hM+CUnu0Tx8ccwb55r4K5bFwYOdF3fvu6ZFXZGtDEVRzBLHglAsqqmAIjIdGAIkJM8VHWDNyy7gPlcAXymqmnBC9UUx9GjrhrKV7pYu9b1b98e/vQnGDTIXblt1VDGVFzBTB6xwCa/z6nAGScwn2HAf/L0e1RE7gfmAHer6pG8E4nIGGAMQKtWrU7ga42/7dvh009dsvjiC1c9FRnpLsgbO9YljJNPDneUxphQKdMN5iLSDOgEzPbr/TdgG1AdeAX4K/BQ3mlV9RVvOPHx8RX/1sFBsHo1zJjhqqN8NyWOjYXhw12yOO88d5aUMabyCWby2Ay09PvcwutXHFcBH6pqhq+Hqm713h4RkUnkaS8xJZOV5UoYEya4hm8Rd43FI4+4hNGli7VdGGOCmzwWAW1FJA6XNIYB1xRzHsNxJY0cItJMVbeKuyHVpcDK0gi2stu3DyZOhOeeg/XrXQnjkUfgxhvt4jxjzPGCljxUNVNExuKqnCKAiaq6SkQeAhJVdZaI9AQ+BBoAl4jIg6p6OoCItMaVXOblmfVUEWkECJAEFO9RdyaXVavg2WfhrbcgLc3dpvyJJ+DSS63B2xiTv0r7JMHKLCvLtWNMmABz57qG72uugXHj3MV6xhgD9iRB49m7F15/HZ5/3t0mpEULeOwxuOkm9+hVY4wpKkselcDKlceqptLT3UV7//qXq5qqaluAMeYE2K6jAvvuO/j73+GrryAqCkaMcFVTXbqEOzJjTHlnyaOC+vJLGDwYYmLg8cfdWVMxMeGOyhhTUVjyqIA+/9xVSZ16qrtWo1GjcEdkjKlo7L6mFczHH8OQIe4+U3PnWuIwxgSHJY8K5L//haFDoVMnmDPHqqmMMcFjyaOCeP99uOIK6N7dVVVFR4c7ImNMRWbJowJ45x24+mpISHB3vK1fP9wRGWMqOkse5dy0ae7q8LPPdg3ldeuGOyJjTGVgyaMcmzwZfv97dzaLaikAACAASURBVNHfZ59BnTrhjsgYU1lY8iinJk6E0aPh3HPdA5rsuRrGmFCy5FEOvfIK3HADDBgAs2ZBzZrhjsgYU9lY8ihnnn8e/vAH92CmmTOhRo1wR2SMqYwseZQjzzzjnhc+ZIg7NTcqKtwRGWMqK0se5cS//w233+4uApwxwz2DwxhjwsWSRznw+ONw111w5ZUwfTpUrx7uiIwxlZ0ljzLukUfgb39z13JMm2aPhjXGlA1BTR4iMlBE1ohIsojcHWB4XxFZIiKZInJFnmFZIpLkdbP8+seJyA/ePN8RkQp7HP7443Dffe5ajsmT7cFNxpiyI2jJQ0QigOeBC4EOwHAR6ZBntI3AaGBagFmkq2pXrxvs1/8J4ClVbQPsBW4o9eDLgM8+g3vugeHDYdIkiIgId0TGGHNMMEseCUCyqqao6lFgOjDEfwRV3aCqy4HsosxQRAQ4F3jP6/UmcGnphVw2rF/vnvrXuTO89polDmNM2RPM5BELbPL7nOr1K6ooEUkUke9FxJcgYoB9qppZ2DxFZIw3feLOnTuLG3vYpKfD5ZdDdrY7HdcuADTGlEVluRb9JFXdLCInA3NFZAWwv6gTq+orwCsA8fHxGqQYS5Uq/PGPsHQpfPQRnHJKuCMyxpjAglny2Ay09PvcwutXJKq62XtNAb4GugG7gfoi4kt6xZpnWffaa65949574eKLwx2NMcbkL5jJYxHQ1js7qjowDJhVyDQAiEgDEYn03jcEegE/qaoCXwG+M7NGAf8t9cjDYNEid/X4gAEwfny4ozHGmIIFLXl47RJjgdnAamCGqq4SkYdEZDCAiPQUkVTgSuBlEVnlTd4eSBSRZbhk8biq/uQN+ytwp4gk49pAXg/WMoTKrl3uKYDNmrlrOayB3BhT1ok7mK/Y4uPjNTExMdxhBJSVBRdeCPPmwYIFEB8f7oiMMcYRkcWqGnCvVJYbzCuF8ePhyy/h1VctcRhjyg+7PUkYffSRu/3I9dfDjTeGOxpjjCk6Sx5hkpzsbjvSvTs891y4ozHGmOKx5BEGaWnuQsAqVeC99+yBTsaY8sfaPEJMFW6+GVascM8ej4sLd0TGGFN8VvIIsZdegrfeggcecGdZGWNMeWTJI4R++AH+9Ce46CJ3q3VjjCmvLHmEyI4d7kLA2FhX8qhia94YU45Zm0cIZGa653Ls2gULF0J0dLgjMsaYkrHkEQL33Qdz58LEidCtW7ijMcaYkrPKkyCbOdM9TnbMGLjuunBHY4wxpcOSRxCtXQujRrnbjjzzTLijMcaY0mPJI0gyMmDYMKhWzV0IGBUV7oiMMab0WJtHkPzjH+6JgB98ACedFO5ojDGmdFnJIwiSkuDhh+Gaa+Cyy8IdjTHGlD5LHqXs6FHXztGwIUyYEO5ojDEmOKzaqpQ98ggsXw7//S/ExIQ7GmOMCY6gljxEZKCIrBGRZBG5O8DwviKyREQyReQKv/5dReQ7EVklIstF5Gq/YW+IyHoRSfK6rsFchuJYvBgeewyuvRYGDw53NMYYEzxBK3mISATwPPA7IBVYJCKz/J5FDrARGA3clWfyNOBaVf1FRJoDi0Vktqru84b/RVXfC1bsJ+LIEVdd1aQJPP10uKMxxpjgCma1VQKQrKopACIyHRgC5CQPVd3gDcv2n1BV1/q93yIiO4BGwD7KqAcfhFWr3G3WGzQIdzTGGBNcway2igU2+X1O9foVi4gkANWBdX69H/Wqs54Skch8phsjIokikrhz587ifm2xLFoETzzhHid70UVB/SpjjCkTyvTZViLSDHgLuE5VfaWTvwGnAT2BaOCvgaZV1VdUNV5V4xs1ahS0GA8fdtVVzZvDf/4TtK8xxpgypUjJQ0RqiUgV7307ERksItUKmWwz0NLvcwuvX5GISF3gE+Dvqvq9r7+qblXnCDAJVz0WNg88AKtXw+uvQ7164YzEGGNCp6glj/lAlIjEAl8AvwfeKGSaRUBbEYkTkerAMGBWUb7MG/9DYHLehnGvNIKICHApsLKIy1DqvvsOnnwSbroJBgwIVxTGGBN6RU0eoqppwFDgBVW9Eji9oAlUNRMYC8wGVgMzVHWViDwkIoMBRKSniKQCVwIvi8gqb/KrgL7A6ACn5E4VkRXACqAh8EiRl7YUpafD6NHQooVLIMYYU5kU9WwrEZGzgBHADV6/iMImUtVPgU/z9Lvf7/0iXHVW3ummAFPymee5RYw5qO69190198svoW7dcEdjjDGhVdSSx+24huoPvdLDycBXwQurbPv2W3jqKbjlFjj//HBHY4wxoSeqWrwJXMN5bVU9EJyQSl98fLwmJiaWyrzS0qBLF/do2RUroHbtUpmtMcaUOSKyWFXjAw0r6tlW00SkrojUwjVQ/yQifynNIMuLe+6B5GSYNMkShzGm8ipqtVUHr6RxKfAZEIc746pSmTfPPRFw3Djo1y/c0RhjTPgUNXlU867ruBSYpaoZQPHqu8q5Q4fcFeSnnOIe9GSMMZVZUc+2ehnYACwD5ovISUC5afMoDXffDevXu9JHrVrhjsYYY8KrSCUPVZ2gqrGqepF3dfevQP8gx1ZmzJ0Lzz8Pt98OffqEOxpjjAm/ojaY1xOR//huNCgi/wYqxfH3wYOuuqpdO/egJ2OMMUVv85gIHMRd+X0VrspqUrCCKkv+8hfYtAneeANq1gx3NMYYUzYUtc3jFFW93O/zgyKSFIyAypIvv4SXX3YJ5Kyzwh2NMcaUHUUteaSLSG/fBxHpBaQHJ6Sy4+GH4bTT4KGHwh2JMcaULUUtedwMTBYR303H9wKjghNS2fHxx7BtG0RFhTsSY4wpW4qUPFR1GdDFe8YGqnpARG4HlgczuHCrW9duemiMMYEU60mCqnrA755WdwYhHmOMMeVASR5DK6UWhTHGmHKlJMmjUt2exBhjzDEFtnmIyEECJwkBagQlImOMMWVegclDVeuEKhBjjDHlR0mqrQolIgNFZI2IJIvI3QGG9xWRJSKSKSJX5Bk2SkR+8bpRfv17iMgKb54TRMTaXowxJsSCljxEJAJ4HrgQ6AAMF5EOeUbbCIwGpuWZNhp4ADgDSAAeEJEG3uAXgZuAtl43MEiLYIwxJh/BLHkkAMmqmqKqR4HpwBD/EVR1g6ouB7LzTHsB8KWq7lHVvcCXwEARaQbUVdXv1T0/dzLuGSPGGGNCKJjJIxbY5Pc51etXkmljvfeFzlNExvjuArxz584iB22MMaZwQW3zCCdVfUVV41U1vlGjRuEOxxhjKpRgJo/NQEu/zy28fiWZdrP3/kTmaYwxppQEM3ksAtqKSJyIVAeGAbOKOO1sYICINPAaygcAs1V1K3BARM70zrK6FvhvMII3xhiTv6AlD1XNBMbiEsFqYIaqrhKRh0RkMICI9BSRVOBK4GURWeVNuwd4GJeAFgEPef0AbgVeA5KBdcBnwVoGY4wxgYk7aalii4+P18TExHCHYYwx5YqILFbV+EDDKmyDuTHGmOCx5GGMMabYLHkYY4wpNksexhhjis2ShzHGmGKz5GGMMabYLHkYY4wpNksexhhjis2ShzHGmGKz5GGMMabYLHkYY4wpNksexhhjis2ShzHGmGKz5FGAh+c9zJ9n/zncYRhjTJljyaMAWw5u4flFz7PzN3sGujHG+LPkUYCxCWM5knWE15a8Fu5QjDGmTLHkUYDTG5/OuXHn8mLii2RmZ4Y7HGOMKTOCmjxEZKCIrBGRZBG5O8DwSBF5xxv+g4i09vqPEJEkvy5bRLp6w7725ukb1jiYyzAuYRybDmxi1pqiPn7dGGMqvqAlDxGJAJ4HLgQ6AMNFpEOe0W4A9qpqG+Ap4AkAVZ2qql1VtSvwe2C9qib5TTfCN1xVdwRrGQAuaXcJJ9U7iWd/fDaYX2OMMeVKMEseCUCyqqao6lFgOjAkzzhDgDe99+8B54mI5BlnuDdtWERUieDWnrfy9YavWbF9RbjCMMaYMiWYySMW2OT3OdXrF3AcVc0E9gMxeca5Gng7T79JXpXVfQGSDQAiMkZEEkUkcefOkp0tdUO3G4iqGsVzPz5XovkYY0xFUaYbzEXkDCBNVVf69R6hqp2APl73+0DTquorqhqvqvGNGjUqURwxNWO4puM1TFkxhb3pe0s0L2OMqQiCmTw2Ay39Prfw+gUcR0SqAvWA3X7Dh5Gn1KGqm73Xg8A0XPVY0I07YxxpGWlMXDoxFF9njDFlWjCTxyKgrYjEiUh1XCLIe8rSLGCU9/4KYK6qKoCIVAGuwq+9Q0SqikhD73014GJgJSHQtWlXerfqzQuJL5CVnRWKrzTGmDIraMnDa8MYC8wGVgMzVHWViDwkIoO90V4HYkQkGbgT8D+dty+wSVVT/PpFArNFZDmQhCu5vBqsZchrXMI4Uvam8FnyZ6H6SmOMKZPEO9Cv0OLj4zUxMbHE88nIyqD1M63p2Lgjs0fOLoXIjDGm7BKRxaoaH2hYmW4wL2uqRVTj5h4388W6L1iza024wzHGmLCx5FFMY3qMoXpEdTtt1xhTqVnyKKYmtZtw1elX8cayNzhw5EC4wzHGmLCw5HECxiWM49DRQ0xeNjncoRhjTFhY8jgBCbEJJMQm8NyPz5Gt2eEOxxhjQs6Sxwka23Msa3av4X8p/wt3KMYYE3KWPE7QVadfReNaje1uu8aYSsmSxwmKrBrJmO5j+GTtJ6TsTSl8AmOMqUAseZTAzfE3E1ElghcWvRDuUIwxJqQseZRAbN1YhrYfyutLX+e3o7+FOxxjjAkZSx4lNC5hHPsO72PqiqnhDsUYY0LGkkcJ9WrZiy5NuvDsj89SGe4TZowxYMmjxESEcQnjWLljJfN+nRfucIwxJiQseZSCazpdQ3SNaLvflTGm0rDkUQpqVKvBjd1uZObPM9m0f1PhExhjTDlnyaOU3NLzFhTlxcQXwx2KMcYEnSWPUtK6fmsuaXcJry55lcOZh8MdjjHGBJUlj1I0LmEcu9J2MX3l9MJHNsaYciyoyUNEBorIGhFJFpG7AwyPFJF3vOE/iEhrr39rEUkXkSSve8lvmh4issKbZoKISDCXoTjOjTuXDo062Gm7xpgKL2jJQ0QigOeBC4EOwHAR6ZBntBuAvaraBngKeMJv2DpV7ep1N/v1fxG4CWjrdQODtQzFJSKM7TmWJVuX8H3q9+EOxxhjgiaYJY8EIFlVU1T1KDAdGJJnnCHAm97794DzCipJiEgzoK6qfq/u0H4ycGnph37ift/l99SLrGd32zXGVGjBTB6xgP95q6lev4DjqGomsB+I8YbFichSEZknIn38xk8tZJ4AiMgYEUkUkcSdO3eWbEmKoXb12lzX9Tre/eldth7cGrLvNcaYUCqrDeZbgVaq2g24E5gmInWLMwNVfUVV41U1vlGjRkEJMj+39ryVzOxMXl78cki/1xhjQiWYyWMz0NLvcwuvX8BxRKQqUA/YrapHVHU3gKouBtYB7bzxWxQyz7BrG9OWC9tcyMuLX+Zo1tFwh2OMMaUumMljEdBWROJEpDowDJiVZ5xZwCjv/RXAXFVVEWnkNbgjIifjGsZTVHUrcEBEzvTaRq4F/hvEZThh4xLGse3QNt7/6f1wh2KMMaUuaMnDa8MYC8wGVgMzVHWViDwkIoO90V4HYkQkGVc95Tudty+wXESScA3pN6vqHm/YrcBrQDKuRPJZsJahJC5ocwFto9vy97l/Z+nWpeEOxxhjSpVUhusR4uPjNTExMeTfu2DjAq567yp2/raTh/s/zF1n30VElYiQx2GMMSdCRBaranygYWW1wbxC6NWqF8tvXs6Q04Zw95y7OXfyufy679dwh2WMMSVmySPIYmrGMOOKGbx56Zss3bqUzi91ZuryqXYFujGmXLPkEQIiwrVdrmXZzcvo1LgTIz8cyTUfXMPe9L3hDs0YY06IJY8QimsQx7zR83j03Ed576f36PxSZ+aunxvusIwxptgseYRYRJUI7ulzD9/d8B01q9XkvMnncdcXd3Ek80i4QzPGmCKz5BEm8c3jWTJmCbfE38K/v/s3Ca8lsGL7inCHZYwxRWLJI4xqVa/FC4Ne4OPhH7Pt0DZ6vtqTp79/mmzNDndoxhhTIEseZcCgdoNYccsKBpwygDtm38GAtwaQeiC18AmNMSZM7CLBMkRVeXXJq9wx+w4iIyJ5+eKXufL0K3OGZ2Vnse/wPvak72FP+h52p+/OeZ9fv7SMNKpIlRPuWtRtwbDThzGo3SCiqkaFce0YY0KtoIsELXmUQWt3r2XkByNZtGURHRt3JC0jjT3pe9h3eF+B09WPqk90jWhiasQQXSOa6BrR1KxWE1Ulm2yytXhdVnYWK3asYNuhbdSLrMeVHa5kZOeR9DmpD1XECq3GVHSWPMpZ8gDIyMrgnwv+ybebvnWJICqamJrHkoKv8yWK+lH1g3Lrk6zsLL7a8BVTlk/h/dXvc+joIVrWbck1na5hZOeRdGzcsdS/0xhTNljyKIfJoyxKy0hj1ppZTFk+hc+TPydLs+jSpAsjO49keMfhxNYN+FwuY0w5ZcnDkkep2/nbTt5Z9Q5TV0zl+9TvEYT+cf0Z2WkkQ9sPpV5UvXCHaIwpIUseljyCKnlPMlOXT2XKiikk70kmqmoUl7S7hJGdRzKwzUCqR1QPd4jGmBNgycOSR0ioKj9u/pEpy6fwzqp32Jm2k5rVatK9WXd6Nu/putienNLgFNyzvIwxZZklD0seIZeRlcEX677gy5Qv+XHzjyzdtpTDmYcBiK4RTXzz+JyEkhCbQLM6zcIcsfGXrdnsSd9DtmbTuFbjkH//hn0bmLt+Lsl7kmnfsD1dm3bltIanUS2iWshjCYfM7ExmJ8/mx80/MrDNQM5scWZYDrgseVjyCLuMrAxW7VzFos2L+HHzjyzasoiVO1aSpVkAxNaJpWfssWQS3zye+lH1wxx1xZKekc7237az47cdubrth7azIy33511pu3J+m9b1W9OrZS96t+pN71a96dCoQ6mfqr390Ha+2vAVc1LmMHfDXFL2pgAgCIrbR1WPqM7pjU6na9OudGnSxb027VKhtpPVO1czKWkSby1/i22HtuX0P6XBKYzoNIIRnUfQLqZdyOIJW/IQkYHAM0AE8JqqPp5neCQwGegB7AauVtUNIvI74HGgOnAU+IuqzvWm+RpoBqR7sxmgqjsKisOSR9mUlpFG0raknGSyaPMiftnzS87wttFt6dykMy3qtiC2TiyxdWNzvdaoViOM0ZdNhzMPs3z7chK3JJK4JZHVu1bnJIVDRw8FnKZWtVo0rtWYJrWb0LhWYxrXbOxeazUmS7P4LvU7vt34bc7OrH5Ufc5ueTa9W7pk0jO2Z7EvIN1/eD/zfp3H3PVzmbN+Dit3rASgXmQ9+rXux7lx53Je3Hm0i2nH2t1rSdqWxLLty0jalkTStiR2pu3MmddJ9U7KlVC6Nu1K6/qty03V6L7D+5i+cjqTkibx4+YfiZAIBrUbxHVdr6NPqz58vPZjpqyYwpyUOShKQmwCIzuN5OqOVwe9VBiW5CEiEcBa4HdAKrAIGK6qP/mNcyvQWVVvFpFhwGWqerWIdAO2q+oWEekIzFbVWG+ar4G7VLXI2cCSR/mxN30viVsSXTLZsojVO1ez+eDmgDu+BlENaF6n+bGkEiDBxNSMQSh4J1LQTkaQMrsTOpJ5hOXbl7N462IStySyeOtiVu5YSWZ2JgANazakU+NONKvTLFdC8E8UjWo2olb1WoV+l6qSsjeFbzd+y4JNC/h247es3rUagGpVqhHfPD6nZHJ2y7NpWLNhrunTM9JZuGkhc9bPYc76OSRuSSRbs4mqGkXvVr05L+48zo07l+7NulO1StVCY9l2aFtOMvG9rt29Nue+cHUj69KlSRfaN2xP/aj61I2sS53IOtSpXifXa93Iurn6hapaLCs7iznr5zApaRIfrv6QI1lH6Ni4I9d1vY4RnUbQpHaT46bZfGAz01dOZ8qKKSRtSyJCIrigzQWM7DSSIacNoWa1mqUeZ7iSx1nAeFW9wPv8NwBV/YffOLO9cb4TkarANqCR+gUl7p+7G2imqkcseVROB44cYPOBzWw+uPm41y0Ht7D54Ga2HdpW6jeVrFWtFl2bdqVHsx50b9adHs17cFrD0wrdwZW2o1lHWbF9RU6SSNySyModK8nIzgCOtSP1aNYj57VVvVZBTXy70naxcNNCFmxcwLebvmXR5kU58ZzW8DR6t+xNbN1Y5v86n4WbFnIk6whVq1QlITYhJ1mc1eIsIqtGlko8aRlprNyx0iWUbctI2u4SyoEjBziadbRI84iMiMyVaBrUaMDJ9U+mTXQbTok+hTbRbWgT3Ya6kXVPKMa1u9fyZtKbTF4+mdQDqTSIasCITiMY3XU03Zt1L/LvtXLHSqYun8q0ldPYuH8jtavXZmj7oYzsNJJz484ttQuGw5U8rgAGquqN3uffA2eo6li/cVZ646R6n9d54+zKM5+bVfV87/PXQAyQBbwPPKIBFkJExgBjAFq1atXj11/t2eEVXWZ2JtsPbc+VWAp7WqOvPj0/O3/byZJtS0jalkRaRhoANarWoGvTri6ZNOtBj+Y9aN+wfYmPWtMz0nMSoS/+X3b/wuKti1mxY0XODrB+VP1ciSK+eTwn1Tsp7CWk9Ix0Erck5pRMFmxawL7D++jatGtOsujTqg91IuuEPLajWUc5eOQgB48e5MCRAznvC+u3O303KXtTcrU/ADSq2ehYMmnQJldyiakRk+u3OHDkAO+uepdJSZNYsGkBVaQKA9sMZHSX0Qw+dXCJkme2ZvPtxm+ZsnwKM1bNYP+R/TSt3ZThHYczsvNIujXtVqLtotwmDxE5HZiFa9dY5/WLVdXNIlIHlzymqOrkgmKxkocpqazsLNbsXsPiLYtZsnUJi7cuZum2pTnVaVFVo+jcpLNLJl4p5fTGp1M9ojqqyq60XQFLTf7v96TvOe5760XWo0fzHrkSRVz9uLAniqLI1mzSMtKoXb12uEMpsUNHD7FuzzqS9ySzbq979b3ftH9TroOQepH1cpJJFanCrDWzSMtI47SGp3Fd1+sY2Xkkzes0L/UYD2ce5tNfPmXK8il8vPZjMrIzaN+wPe9e+S6nNz79hOZZLqutRKQFMBe4TlUX5PMdo4F4/4QUiCUPEwzZmp1TMli8ZTFLti1hydYlHDhyAHBnBzWt3ZRth7YdV20iCE1qN8ndThOgzaZuZN1ykSgqs8OZh1m/d32upOJLLPsP72do+6Fc1/U6EmITQvZb7knfw3s/vcd7P73HB1d/cMIJPFzJoyquwfw8YDOuwfwaVV3lN84fgU5+DeZDVfUqEakPzAMeVNUP8syzvqruEpFqwNvA/1T1pYJiseRhQiVbs1m3Z11O6WTroa00r938uKTQtHbTSnPNgim/wnmq7kXA07hTdSeq6qMi8hCQqKqzRCQKeAvoBuwBhqlqiojcC/wN+MVvdgOA34D5QDVvnv8D7lT1TkjPhyUPY4wpPrtI0JKHMcYUW0HJw57oY4wxptgseRhjjCk2Sx7GGGOKzZKHMcaYYrPkYYwxptgseRhjjCk2Sx7GGGOKrVJc5yEiO4GyemfEhsCuQscKH4uvZCy+krH4Sqak8Z2kqo0CDagUyaMsE5HE/C7CKQssvpKx+ErG4iuZYMZn1VbGGGOKzZKHMcaYYrPkEX6vhDuAQlh8JWPxlYzFVzJBi8/aPIwxxhSblTyMMcYUmyUPY4wxxWbJIwREpKWIfCUiP4nIKhH5U4Bx+onIfhFJ8rr7QxzjBhFZ4X33cQ8/EWeCiCSLyHIR6R7C2E71Wy9JInJARG7PM05I15+ITBSRHSKy0q9ftIh8KSK/eK8N8pl2lDfOLyIyKoTx/UtEfvZ+vw+9J3YGmrbAbSGI8Y0Xkc1+v+FF+Uw7UETWeNvi3SGM7x2/2DaISFI+04Zi/QXcp4R0G1RV64LcAc2A7t77OrjH83bIM04/4OMwxrgBaFjA8IuAzwABzgR+CFOcEbhn3Z8UzvUH9AW6Ayv9+v0TuNt7fzfwRIDpooEU77WB975BiOIbAFT13j8RKL6ibAtBjG88cFcRfv91wMlAdWBZ3v9SsOLLM/zfwP1hXH8B9ymh3Aat5BECqrpVVZd47w8Cq4HY8EZVbEOAyep8D9QXkWZhiOM8YJ2qhvWOAao6H/foZH9DgDe9928ClwaY9ALgS1Xdo6p7gS+BgaGIT1W/UNVM7+P3QIvS/t6iymf9FUUCkKyqKap6FJiOW++lqqD4RESAq4C3S/t7i6qAfUrItkFLHiEmIq1xz2z/IcDgs0RkmYh8JiKnhzQwUOALEVksImMCDI8FNvl9TiU8CXAY+f9pw7n+AJqo6lbv/TagSYBxysp6vB5XkgyksG0hmMZ61WoT86lyKQvrrw+wXVV/yWd4SNdfnn1KyLZBSx4hJCK1gfeB21X1QJ7BS3BVMV2AZ4GZIQ6vt6p2By4E/igifUP8/YUSkerAYODdAIPDvf5yUVc/UCbPgxeRvwOZwNR8RgnXtvAicArQFdiKqxoqi4ZTcKkjZOuvoH1KsLdBSx4hIiLVcD/yVFX9IO9wVT2gqoe8958C1USkYajiU9XN3usO4ENc9YC/zUBLv88tvH6hdCGwRFW35x0Q7vXn2e6ryvNedwQYJ6zrUURGAxcDI7ydy3GKsC0EhapuV9UsVc0GXs3ne8O9/qoCQ4F38hsnVOsvn31KyLZBSx4h4NWRvg6sVtX/5DNOU288RCQB99vsDlF8tUSkju89rmF1ZZ7RZgHXemddnQns9yseh0q+R3zhXH9+ZgG+M1dGAf8NMM5sYICINPCqZQZ4/YJORAYC/wcMVtW0fMYpyrYQrPj829Auy+d7FwFtRSTOK4kOw633UDkf+FlVUwMNDNX6K2CfErptMJhnBFiXc3ZDb1zxcTmQ5HUXATcDN3vjpB0avAAAAmtJREFUjAVW4c4e+R44O4Txnex97zIvhr97/f3jE+B53JkuK4D4EK/DWrhkUM+vX9jWHy6JbQUycHXGNwAxwBzgF+B/QLQ3bjzwmt+01wPJXnddCONLxtV1+7bBl7xxmwOfFrQthCi+t7xtazluJ9gsb3ze54twZxetC2V8Xv83fNuc37jhWH/57VNCtg3a7UmMMcYUm1VbGWOMKTZLHsYYY4rNkocxxphis+RhjDGm2Cx5GGOMKTZLHsaUAhHJktx3/i21u72KSGv/u7saUxZUDXcAxlQQ6araNdxBGBMqVvIwJoi8Zzv803u+w48i0sbr31pE5no3AZwjIq28/k3EPWtjmded7c0qQkRe9Z7d8IWI1AjbQhmDJQ9jSkuNPNVWV/sN26+qnYDngKe9fs8Cb6pqZ9wNCid4/ScA89Td4LE77iplgLbA86p6OrAPuDzIy2NMgewKc2NKgYgcUtXaAfpvgP9v745RIgiCKAy/hxgYiWhoYOINPIGXENlIjDYQI/ECnsLEa5gYCZqKB9hUYfcCi8gz6BYm0KBgxzX4v2SqOxh6opqaHqp1nGTWG9m9J9m1vVBrv/HR59+S7NmeS9pPshzc40Dt/IXDPr6WtJnkZvwnA35G5QGML7/EFctB/Cn2K7FmJA9gfCeD63OPn9Q6wkrSRNJjjx8kTSXJ9obt7b9aJFDB2wuwGlu2Xwbj+yTfv+vu2H5Vqx5O+9yFpDvbV5Lmks76/KWkW9vnahXGVK27K/CvsOcBjKjveRwlWax7LcAq8dkKAFBG5QEAKKPyAACUkTwAAGUkDwBAGckDAFBG8gAAlH0Bok9jSZKhY0QAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model testing---------.\n",
            "\n",
            "\n",
            "Model test error: 0.2305271233121554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model without NID"
      ],
      "metadata": {
        "id": "68OZ3pnbCY7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class TensorNetworkModule(torch.nn.Module):\n",
        "    def __init__(self, tensor_neurons, input_dim):\n",
        "        super(TensorNetworkModule, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.setup_weights()\n",
        "        self.init_parameters()\n",
        "\n",
        "    def setup_weights(self):\n",
        "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.input_dim, self.input_dim, self.tensor_neurons))\n",
        "        self.weight_matrix_block = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 2 * self.input_dim))\n",
        "        self.bias = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 1))\n",
        "\n",
        "    def init_parameters(self):\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix_block)\n",
        "        torch.nn.init.xavier_uniform_(self.bias)\n",
        "\n",
        "    def forward(self, embedding_1, embedding_2):\n",
        "        scoring = torch.mm(torch.t(embedding_1), self.weight_matrix.view(self.input_dim, -1))\n",
        "        scoring = scoring.view(self.input_dim, self.tensor_neurons)\n",
        "        scoring = torch.mm(torch.t(scoring), embedding_2)\n",
        "        combined_representation = torch.cat((embedding_1, embedding_2))\n",
        "        block_scoring = torch.mm(self.weight_matrix_block, combined_representation)\n",
        "        scores = torch.nn.functional.relu(scoring + block_scoring + self.bias)\n",
        "        return scores\n",
        "\n",
        "\n",
        "def graph_aggregation_layer(input, adj):\n",
        "    result = torch.mm(adj, input)\n",
        "    return result\n",
        "\n",
        "\n",
        "class TaGSim(torch.nn.Module):\n",
        "    def __init__(self, number_of_node_labels, number_of_edge_labels, tensor_neurons, bottle_neck_neurons):\n",
        "        super(TaGSim, self).__init__()\n",
        "        self.number_of_node_labels = len(number_of_node_labels)\n",
        "        self.number_of_edge_labels = len(number_of_edge_labels)\n",
        "        self.node_type = number_of_node_labels\n",
        "        self.edge_type = number_of_edge_labels\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.bottle_neck_neurons = bottle_neck_neurons\n",
        "        self.setup_layers()\n",
        "\n",
        "    def setup_layers(self):\n",
        "        self.feature_count = self.tensor_neurons\n",
        "\n",
        "        # self.tensor_network_nc = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_in = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        # self.tensor_network_ie = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_ec = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_edge_labels)\n",
        "\n",
        "        # self.fully_connected_first_nc = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_nc = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_nc = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_nc = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_in = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_in = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_in = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_in = torch.nn.Linear(4, 1)\n",
        "\n",
        "        # self.fully_connected_first_ie = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_ie = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_ie = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_ie = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_ec = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_ec = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_ec = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_ec = torch.nn.Linear(4, 1)\n",
        "\n",
        "    def gal_pass(self, edge_index, features):\n",
        "        hidden1 = graph_aggregation_layer(features, edge_index)\n",
        "        hidden2 = graph_aggregation_layer(hidden1, edge_index)\n",
        "\n",
        "        return hidden1, hidden2\n",
        "\n",
        "    def forward(self, label_multiset):\n",
        "        adj_1, adj_2 = torch.FloatTensor(np.array(label_multiset[\"node_index_1\"].todense())), torch.FloatTensor(\n",
        "            np.array(label_multiset[\"node_index_2\"].todense()))\n",
        "        edge_adj_1, edge_adj_2 = label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"]\n",
        "        node_features_1, node_features_2 = label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"]\n",
        "        edge_features_1, edge_features_2 = label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"]\n",
        "\n",
        "        #gal\n",
        "        graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, node_features_1)  #original graph node\n",
        "        graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, node_features_2)  #generated graph node\n",
        "        edge1_hidden1, edge1_hidden2 = self.gal_pass(edge_adj_1, edge_features_1)  #original edge node\n",
        "        edge2_hidden1, edge2_hidden2 = self.gal_pass(edge_adj_2, edge_features_2)  #generated graph edge\n",
        "        #node level embedding Concatenation\n",
        "        graph1_01concat = torch.cat([node_features_1, graph1_hidden1], dim=1)\n",
        "        graph2_01concat = torch.cat([node_features_2, graph2_hidden1], dim=1)\n",
        "        graph1_12concat = torch.cat([graph1_hidden1, graph1_hidden2], dim=1)\n",
        "        graph2_12concat = torch.cat([graph2_hidden1, graph2_hidden2], dim=1)\n",
        "        #graph pooling: node Sum\n",
        "        graph1_01pooled = torch.sum(graph1_01concat, dim=0).unsqueeze(1)\n",
        "        graph2_01pooled = torch.sum(graph2_01concat, dim=0).unsqueeze(1)\n",
        "        graph1_12pooled = torch.sum(graph1_12concat, dim=0).unsqueeze(1)\n",
        "        graph2_12pooled = torch.sum(graph2_12concat, dim=0).unsqueeze(1)\n",
        "        #edge level embedding Concatenation\n",
        "        edge1_01concat = torch.cat([edge_features_1, edge1_hidden1], dim=1)\n",
        "        edge2_01concat = torch.cat([edge_features_2, edge2_hidden1], dim=1)\n",
        "        #graph pooling: edge Sum\n",
        "        edge1_01pooled = torch.sum(edge1_01concat, dim=0).unsqueeze(1)\n",
        "        edge2_01pooled = torch.sum(edge2_01concat, dim=0).unsqueeze(1)\n",
        "\n",
        "        # scores_nc = self.tensor_network_nc(graph1_01pooled, graph2_01pooled)\n",
        "        # scores_nc = torch.t(scores_nc)\n",
        "        #\n",
        "        # scores_nc = torch.nn.functional.relu(self.fully_connected_first_nc(scores_nc))\n",
        "        # scores_nc = torch.nn.functional.relu(self.fully_connected_second_nc(scores_nc))\n",
        "        # scores_nc = torch.nn.functional.relu(self.fully_connected_third_nc(scores_nc))\n",
        "        # score_nc = torch.sigmoid(self.scoring_layer_nc(scores_nc))\n",
        "\n",
        "        scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
        "        scores_in = torch.t(scores_in)\n",
        "\n",
        "        scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
        "        scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
        "        scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
        "        score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
        "\n",
        "        # scores_ie = self.tensor_network_ie(graph1_12pooled, graph2_12pooled)\n",
        "        # scores_ie = torch.t(scores_ie)\n",
        "        #\n",
        "        # scores_ie = torch.nn.functional.relu(self.fully_connected_first_ie(scores_ie))\n",
        "        # scores_ie = torch.nn.functional.relu(self.fully_connected_second_ie(scores_ie))\n",
        "        # scores_ie = torch.nn.functional.relu(self.fully_connected_third_ie(scores_ie))\n",
        "        # score_ie = torch.sigmoid(self.scoring_layer_ie(scores_ie))\n",
        "\n",
        "        scores_ec = self.tensor_network_ec(edge1_01pooled, edge2_01pooled)\n",
        "        scores_ec = torch.t(scores_ec)\n",
        "\n",
        "        scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
        "        scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
        "        scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
        "        score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
        "\n",
        "        return torch.cat([ score_in,  score_ec], dim=1)\n",
        "\n",
        "    def transform_label_multiset(self, graph_pair, type_specified=True):\n",
        "        graph1 = graph_pair['graph_pair'][0]\n",
        "        graph2 = graph_pair['graph_pair'][1]\n",
        "        ged = graph_pair['ged']\n",
        "        #node and edge info of pair graph\n",
        "        node_info1 = nx.get_node_attributes(graph1, 'label')\n",
        "        node_info2 = nx.get_node_attributes(graph2, 'label')\n",
        "        edge_info1 = nx.get_edge_attributes(graph1, 'id')\n",
        "        edge_info2 = nx.get_edge_attributes(graph2, 'id')\n",
        "        nodes1 = list(graph1.nodes())\n",
        "        nodes2 = list(graph2.nodes())\n",
        "        edges1 = list(graph1.edges())\n",
        "        edges2 = list(graph2.edges())\n",
        "\n",
        "        label_multiset = dict()\n",
        "        node_features_1, node_features_2, edge_features_1, edge_features_2, edge_adj_1, edge_adj_2 = [], [], [], [], [], []\n",
        "\n",
        "        for i in graph1.nodes():\n",
        "            node_features_1.append([1.0 if node_info1[i] == node else 0.0 for node in self.node_type])\n",
        "        for i in graph2.nodes():\n",
        "            node_features_2.append([1.0 if node_info2[i] == node else 0.0 for node in self.node_type])\n",
        "        node_features_1, node_features_2 = torch.FloatTensor(np.array(node_features_1)), torch.FloatTensor(\n",
        "            np.array(node_features_2))\n",
        "\n",
        "        for i in edges1:\n",
        "            edge_features_1.append([1.0 if edge_info1[i] == edge else 0.0 for edge in self.edge_type])\n",
        "            adj_row = []\n",
        "            for d in edges1:\n",
        "                if (i == d):\n",
        "                    adj_row.append(0.0)\n",
        "                    continue\n",
        "                if ((i[0] in d) | (i[1] in d)):\n",
        "                    adj_row.append(1.0)\n",
        "                else:\n",
        "                    adj_row.append(0.0)\n",
        "            edge_adj_1.append(adj_row)\n",
        "        for i in edges2:\n",
        "            edge_features_2.append([1.0 if edge_info2[i] == edge else 0.0 for edge in self.edge_type])\n",
        "            adj_row = []\n",
        "            for d in edges2:\n",
        "                if (i == d):\n",
        "                    adj_row.append(0.0)\n",
        "                    continue\n",
        "                if ((i[0] in d) | (i[1] in d)):\n",
        "                    adj_row.append(1.0)\n",
        "                else:\n",
        "                    adj_row.append(0.0)\n",
        "            edge_adj_2.append(adj_row)\n",
        "        edge_features_1, edge_features_2 = torch.FloatTensor(np.array(edge_features_1)), torch.FloatTensor(\n",
        "            np.array(edge_features_2))\n",
        "        edge_adj_1, edge_adj_2 = torch.FloatTensor(np.array(edge_adj_1)), torch.FloatTensor(np.array(edge_adj_2))\n",
        "\n",
        "        label_multiset[\"node_index_1\"], label_multiset[\"node_index_2\"] = nx.adjacency_matrix(\n",
        "            graph1), nx.adjacency_matrix(graph2)\n",
        "        label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"] = node_features_1, node_features_2\n",
        "        label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"] = edge_features_1, edge_features_2\n",
        "        label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"] = edge_adj_1, edge_adj_2\n",
        "\n",
        "        #ged normalisation\n",
        "        if (type_specified):  # for training\n",
        "            avg_node_number = 0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes())\n",
        "            norm_ged = [n / avg_node_number for n in ged]\n",
        "            norm_ged = np.array(norm_ged)\n",
        "            label_multiset[\"target\"] = torch.from_numpy(np.exp(-norm_ged)).view(1, -1).float()\n",
        "\n",
        "            norm_gt_ged = (len(ged)) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "        else:  # for testing\n",
        "            norm_gt_ged = (ged) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "\n",
        "        return label_multiset\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = 20\n",
        "tensor_neurons = 16\n",
        "bottle_neck_neurons = 16\n",
        "batch_size = 128\n",
        "dropout = 0.0\n",
        "lr = 0.001\n",
        "weight_decay = 0.0\n",
        "\n",
        "Node_Types = ['1']\n",
        "Edge_Types = ['1']\n",
        "#collection global node label and edge label info\n",
        "\n",
        "print(\"\\n-------Model training---------.\\n\")\n",
        "\n",
        "model = TaGSim(Node_Types, Edge_Types, tensor_neurons, bottle_neck_neurons)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "iteration = 0\n",
        "\n",
        "visual_loss_train = []\n",
        "test_scores = []\n",
        "visual_loss_test = []\n",
        "train_pair = []\n",
        "test_pair = []\n",
        "epo = []\n",
        "\n",
        "#model training\n",
        "for epoch in range(epochs):\n",
        "    random.shuffle(train_pairs)\n",
        "    batches = []\n",
        "    for graph in range(0, len(train_pairs), batch_size):\n",
        "        batches.append(train_pairs[graph:graph + batch_size])\n",
        "\n",
        "    for batch in batches:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        losses = 0\n",
        "        for graph_pair in batch:\n",
        "            data = model.transform_label_multiset(graph_pair)\n",
        "            prediction = model(data)\n",
        "            losses += torch.nn.functional.mse_loss(data[\"target\"], prediction)\n",
        "\n",
        "        losses.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        loss = losses.item()\n",
        "        print('Iteration', iteration, 'loss: ', loss / len(batch))\n",
        "        iteration += 1\n",
        "\n",
        "    visual_loss_train.append(loss / len(batch))\n",
        "    # testing\n",
        "    model.eval()\n",
        "    for n in test_pairs:\n",
        "        graph1 = n['graph_pair'][0]  #updated_test\n",
        "        graph2 = n['graph_pair'][1]  #updated_test\n",
        "        ged = int(n['gt_ged'])\n",
        "        tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "        data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "        prediction = model(data)\n",
        "        prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "        current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "        test_scores.append(current_error.data.item())\n",
        "    visual_loss_test.append(sum(test_scores) / len(test_scores))\n",
        "    epo.append(epoch + 1)\n",
        "\n",
        "#visualization of traning and testing loss\n",
        "plt.plot(epo, visual_loss_train, 'g', label='Training Loss')\n",
        "plt.plot(epo, visual_loss_test, 'b', label='Validation Loss')\n",
        "plt.title('Evaluation of TaGSim Model with SUM Graph Pooling layer (' + DATASET + ')')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n-------Model testing---------.\\n\")\n",
        "\n",
        "model.eval()\n",
        "test_scores = []\n",
        "for n in test_pairs:\n",
        "    graph1 = n['graph_pair'][0]  #updated_test\n",
        "    graph2 = n['graph_pair'][1]  #updated_test\n",
        "    ged = int(n['gt_ged'])\n",
        "    tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "    data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "    prediction = model(data)\n",
        "    prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "    current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "    test_scores.append(current_error.data.item())\n",
        "\n",
        "model_error = sum(test_scores) / len(test_scores)\n",
        "print(\"\\nModel test error: \" + str(model_error))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Au1iomXeCQ1x",
        "outputId": "19226ebc-09a9-454d-c0cf-eab0a3ef6dbc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model training---------.\n",
            "\n",
            "Iteration 0 loss:  0.155412957072258\n",
            "Iteration 1 loss:  0.13951422274112701\n",
            "Iteration 2 loss:  0.1298229694366455\n",
            "Iteration 3 loss:  0.10504843294620514\n",
            "Iteration 4 loss:  0.0986267551779747\n",
            "Iteration 5 loss:  0.08879538625478745\n",
            "Iteration 6 loss:  0.08836612105369568\n",
            "Iteration 7 loss:  0.07076223194599152\n",
            "Iteration 8 loss:  0.06616806983947754\n",
            "Iteration 9 loss:  0.0553552508354187\n",
            "Iteration 10 loss:  0.06387066841125488\n",
            "Iteration 11 loss:  0.06420211493968964\n",
            "Iteration 12 loss:  0.058968644589185715\n",
            "Iteration 13 loss:  0.052529916167259216\n",
            "Iteration 14 loss:  0.05089225620031357\n",
            "Iteration 15 loss:  0.047879479825496674\n",
            "Iteration 16 loss:  0.04128224402666092\n",
            "Iteration 17 loss:  0.05067940801382065\n",
            "Iteration 18 loss:  0.04635543003678322\n",
            "Iteration 19 loss:  0.04657942553361257\n",
            "Iteration 20 loss:  0.04431881010532379\n",
            "Iteration 21 loss:  0.044014137238264084\n",
            "Iteration 22 loss:  0.04603849723935127\n",
            "Iteration 23 loss:  0.048517387360334396\n",
            "Iteration 24 loss:  0.04544584080576897\n",
            "Iteration 25 loss:  0.04299672320485115\n",
            "Iteration 26 loss:  0.04620996117591858\n",
            "Iteration 27 loss:  0.04658107832074165\n",
            "Iteration 28 loss:  0.04011709243059158\n",
            "Iteration 29 loss:  0.043123096227645874\n",
            "Iteration 30 loss:  0.03907205909490585\n",
            "Iteration 31 loss:  0.04376836493611336\n",
            "Iteration 32 loss:  0.04120655730366707\n",
            "Iteration 33 loss:  0.04409913346171379\n",
            "Iteration 34 loss:  0.04107581079006195\n",
            "Iteration 35 loss:  0.048933204263448715\n",
            "Iteration 36 loss:  0.04598987475037575\n",
            "Iteration 37 loss:  0.047942277044057846\n",
            "Iteration 38 loss:  0.042202167212963104\n",
            "Iteration 39 loss:  0.048387820521990456\n",
            "Iteration 40 loss:  0.04485262930393219\n",
            "Iteration 41 loss:  0.04705503582954407\n",
            "Iteration 42 loss:  0.041060905903577805\n",
            "Iteration 43 loss:  0.04002860561013222\n",
            "Iteration 44 loss:  0.03867165744304657\n",
            "Iteration 45 loss:  0.038611773401498795\n",
            "Iteration 46 loss:  0.043562617152929306\n",
            "Iteration 47 loss:  0.045191146433353424\n",
            "Iteration 48 loss:  0.04493127390742302\n",
            "Iteration 49 loss:  0.051492164532343544\n",
            "Iteration 50 loss:  0.04211418330669403\n",
            "Iteration 51 loss:  0.04302426800131798\n",
            "Iteration 52 loss:  0.04201292246580124\n",
            "Iteration 53 loss:  0.04658152908086777\n",
            "Iteration 54 loss:  0.0418536439538002\n",
            "Iteration 55 loss:  0.0402139313519001\n",
            "Iteration 56 loss:  0.041157662868499756\n",
            "Iteration 57 loss:  0.04377976432442665\n",
            "Iteration 58 loss:  0.039918508380651474\n",
            "Iteration 59 loss:  0.0352689598997434\n",
            "Iteration 60 loss:  0.04152117297053337\n",
            "Iteration 61 loss:  0.04114624485373497\n",
            "Iteration 62 loss:  0.04170841723680496\n",
            "Iteration 63 loss:  0.03800832852721214\n",
            "Iteration 64 loss:  0.03884280100464821\n",
            "Iteration 65 loss:  0.04206455126404762\n",
            "Iteration 66 loss:  0.03914620727300644\n",
            "Iteration 67 loss:  0.04004708305001259\n",
            "Iteration 68 loss:  0.04279167205095291\n",
            "Iteration 69 loss:  0.03792399416367213\n",
            "Iteration 70 loss:  0.037259023636579514\n",
            "Iteration 71 loss:  0.03637218475341797\n",
            "Iteration 72 loss:  0.03824158012866974\n",
            "Iteration 73 loss:  0.036062780767679214\n",
            "Iteration 74 loss:  0.04395855590701103\n",
            "Iteration 75 loss:  0.037680868059396744\n",
            "Iteration 76 loss:  0.039296917617321014\n",
            "Iteration 77 loss:  0.04008042812347412\n",
            "Iteration 78 loss:  0.0363706611096859\n",
            "Iteration 79 loss:  0.038360958298047386\n",
            "Iteration 80 loss:  0.040424659848213196\n",
            "Iteration 81 loss:  0.035879336297512054\n",
            "Iteration 82 loss:  0.036032576113939285\n",
            "Iteration 83 loss:  0.037463124841451645\n",
            "Iteration 84 loss:  0.031114162877202034\n",
            "Iteration 85 loss:  0.035893626511096954\n",
            "Iteration 86 loss:  0.034821443259716034\n",
            "Iteration 87 loss:  0.034669484943151474\n",
            "Iteration 88 loss:  0.03676482290029526\n",
            "Iteration 89 loss:  0.026568313439687092\n",
            "Iteration 90 loss:  0.03396257385611534\n",
            "Iteration 91 loss:  0.031938809901475906\n",
            "Iteration 92 loss:  0.0365629717707634\n",
            "Iteration 93 loss:  0.03253708779811859\n",
            "Iteration 94 loss:  0.03399287164211273\n",
            "Iteration 95 loss:  0.03292325511574745\n",
            "Iteration 96 loss:  0.029098128899931908\n",
            "Iteration 97 loss:  0.03022041916847229\n",
            "Iteration 98 loss:  0.03498651087284088\n",
            "Iteration 99 loss:  0.028930693864822388\n",
            "Iteration 100 loss:  0.03087599016726017\n",
            "Iteration 101 loss:  0.031346749514341354\n",
            "Iteration 102 loss:  0.03243343532085419\n",
            "Iteration 103 loss:  0.030214710161089897\n",
            "Iteration 104 loss:  0.03380121663212776\n",
            "Iteration 105 loss:  0.026811283081769943\n",
            "Iteration 106 loss:  0.02838829532265663\n",
            "Iteration 107 loss:  0.029834918677806854\n",
            "Iteration 108 loss:  0.029248101636767387\n",
            "Iteration 109 loss:  0.03386497994263967\n",
            "Iteration 110 loss:  0.029871469363570213\n",
            "Iteration 111 loss:  0.022992271929979324\n",
            "Iteration 112 loss:  0.027082914486527443\n",
            "Iteration 113 loss:  0.028910115361213684\n",
            "Iteration 114 loss:  0.029487809166312218\n",
            "Iteration 115 loss:  0.030713478103280067\n",
            "Iteration 116 loss:  0.03295939043164253\n",
            "Iteration 117 loss:  0.028032496571540833\n",
            "Iteration 118 loss:  0.03159082680940628\n",
            "Iteration 119 loss:  0.026981182396411896\n",
            "Iteration 120 loss:  0.02884821407496929\n",
            "Iteration 121 loss:  0.02681467868387699\n",
            "Iteration 122 loss:  0.0306767076253891\n",
            "Iteration 123 loss:  0.026916585862636566\n",
            "Iteration 124 loss:  0.02822204865515232\n",
            "Iteration 125 loss:  0.02860953100025654\n",
            "Iteration 126 loss:  0.027178550139069557\n",
            "Iteration 127 loss:  0.02704731374979019\n",
            "Iteration 128 loss:  0.029296597465872765\n",
            "Iteration 129 loss:  0.028278800348440807\n",
            "Iteration 130 loss:  0.032138925045728683\n",
            "Iteration 131 loss:  0.02643597684800625\n",
            "Iteration 132 loss:  0.027207843959331512\n",
            "Iteration 133 loss:  0.027372580021619797\n",
            "Iteration 134 loss:  0.03140885382890701\n",
            "Iteration 135 loss:  0.030282679945230484\n",
            "Iteration 136 loss:  0.027431977912783623\n",
            "Iteration 137 loss:  0.022261636331677437\n",
            "Iteration 138 loss:  0.02466721646487713\n",
            "Iteration 139 loss:  0.02840925504763921\n",
            "Iteration 140 loss:  0.025446817278862\n",
            "Iteration 141 loss:  0.02465278096497059\n",
            "Iteration 142 loss:  0.03119783103466034\n",
            "Iteration 143 loss:  0.029002314433455467\n",
            "Iteration 144 loss:  0.025734832510352135\n",
            "Iteration 145 loss:  0.028790635988116264\n",
            "Iteration 146 loss:  0.028162486851215363\n",
            "Iteration 147 loss:  0.027264304459095\n",
            "Iteration 148 loss:  0.028484439477324486\n",
            "Iteration 149 loss:  0.023722815016905468\n",
            "Iteration 150 loss:  0.02908976934850216\n",
            "Iteration 151 loss:  0.02631494775414467\n",
            "Iteration 152 loss:  0.02664566971361637\n",
            "Iteration 153 loss:  0.028169037774205208\n",
            "Iteration 154 loss:  0.02638239599764347\n",
            "Iteration 155 loss:  0.023804185912013054\n",
            "Iteration 156 loss:  0.030717860907316208\n",
            "Iteration 157 loss:  0.028835194185376167\n",
            "Iteration 158 loss:  0.026146454736590385\n",
            "Iteration 159 loss:  0.026105575263500214\n",
            "Iteration 160 loss:  0.027530482038855553\n",
            "Iteration 161 loss:  0.029243439435958862\n",
            "Iteration 162 loss:  0.025508500635623932\n",
            "Iteration 163 loss:  0.02876022644340992\n",
            "Iteration 164 loss:  0.023486966267228127\n",
            "Iteration 165 loss:  0.02811516262590885\n",
            "Iteration 166 loss:  0.026691528037190437\n",
            "Iteration 167 loss:  0.027008814737200737\n",
            "Iteration 168 loss:  0.028554297983646393\n",
            "Iteration 169 loss:  0.02567192167043686\n",
            "Iteration 170 loss:  0.023629488423466682\n",
            "Iteration 171 loss:  0.027064763009548187\n",
            "Iteration 172 loss:  0.02957945317029953\n",
            "Iteration 173 loss:  0.02551661990582943\n",
            "Iteration 174 loss:  0.025492485612630844\n",
            "Iteration 175 loss:  0.02624857984483242\n",
            "Iteration 176 loss:  0.028075851500034332\n",
            "Iteration 177 loss:  0.03053947165608406\n",
            "Iteration 178 loss:  0.025653613731265068\n",
            "Iteration 179 loss:  0.030415187279383343\n",
            "Iteration 180 loss:  0.02950112894177437\n",
            "Iteration 181 loss:  0.025426525622606277\n",
            "Iteration 182 loss:  0.02983289211988449\n",
            "Iteration 183 loss:  0.023509377613663673\n",
            "Iteration 184 loss:  0.0288598220795393\n",
            "Iteration 185 loss:  0.023895639926195145\n",
            "Iteration 186 loss:  0.02511315979063511\n",
            "Iteration 187 loss:  0.028707677498459816\n",
            "Iteration 188 loss:  0.027432743459939957\n",
            "Iteration 189 loss:  0.02658289670944214\n",
            "Iteration 190 loss:  0.02907203696668148\n",
            "Iteration 191 loss:  0.024942755699157715\n",
            "Iteration 192 loss:  0.02532440796494484\n",
            "Iteration 193 loss:  0.026507174596190453\n",
            "Iteration 194 loss:  0.028785649687051773\n",
            "Iteration 195 loss:  0.02802407182753086\n",
            "Iteration 196 loss:  0.02513948269188404\n",
            "Iteration 197 loss:  0.026210753247141838\n",
            "Iteration 198 loss:  0.02784247137606144\n",
            "Iteration 199 loss:  0.025464313725630443\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model testing---------.\n",
            "\n",
            "\n",
            "Model test error: 0.10657592008427097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MAX Pooling"
      ],
      "metadata": {
        "id": "2Lfo0x9TChNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class TensorNetworkModule(torch.nn.Module):\n",
        "    def __init__(self, tensor_neurons, input_dim):\n",
        "        super(TensorNetworkModule, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.setup_weights()\n",
        "        self.init_parameters()\n",
        "\n",
        "    def setup_weights(self):\n",
        "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.input_dim, self.input_dim, self.tensor_neurons))\n",
        "        self.weight_matrix_block = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 2 * self.input_dim))\n",
        "        self.bias = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 1))\n",
        "\n",
        "    def init_parameters(self):\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix_block)\n",
        "        torch.nn.init.xavier_uniform_(self.bias)\n",
        "\n",
        "    def forward(self, embedding_1, embedding_2):\n",
        "        scoring = torch.mm(torch.t(embedding_1), self.weight_matrix.view(self.input_dim, -1))\n",
        "        scoring = scoring.view(self.input_dim, self.tensor_neurons)\n",
        "        scoring = torch.mm(torch.t(scoring), embedding_2)\n",
        "        combined_representation = torch.cat((embedding_1, embedding_2))\n",
        "        block_scoring = torch.mm(self.weight_matrix_block, combined_representation)\n",
        "        scores = torch.nn.functional.relu(scoring + block_scoring + self.bias)\n",
        "        return scores\n",
        "\n",
        "\n",
        "def graph_aggregation_layer(input, adj):\n",
        "    result = torch.mm(adj, input)\n",
        "    return result\n",
        "\n",
        "\n",
        "class TaGSim(torch.nn.Module):\n",
        "    def __init__(self, number_of_node_labels, number_of_edge_labels, tensor_neurons, bottle_neck_neurons):\n",
        "        super(TaGSim, self).__init__()\n",
        "        self.number_of_node_labels = len(number_of_node_labels)\n",
        "        self.number_of_edge_labels = len(number_of_edge_labels)\n",
        "        self.node_type = number_of_node_labels\n",
        "        self.edge_type = number_of_edge_labels\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.bottle_neck_neurons = bottle_neck_neurons\n",
        "        self.setup_layers()\n",
        "\n",
        "    def setup_layers(self):\n",
        "        self.feature_count = self.tensor_neurons\n",
        "\n",
        "        # self.tensor_network_nc = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_in = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        # self.tensor_network_ie = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_ec = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_edge_labels)\n",
        "\n",
        "        # self.fully_connected_first_nc = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_nc = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_nc = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_nc = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_in = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_in = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_in = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_in = torch.nn.Linear(4, 1)\n",
        "\n",
        "        # self.fully_connected_first_ie = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_ie = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_ie = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_ie = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_ec = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_ec = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_ec = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_ec = torch.nn.Linear(4, 1)\n",
        "\n",
        "    def gal_pass(self, edge_index, features):\n",
        "        hidden1 = graph_aggregation_layer(features, edge_index)\n",
        "        hidden2 = graph_aggregation_layer(hidden1, edge_index)\n",
        "\n",
        "        return hidden1, hidden2\n",
        "\n",
        "    def forward(self, label_multiset):\n",
        "        adj_1, adj_2 = torch.FloatTensor(np.array(label_multiset[\"node_index_1\"].todense())), torch.FloatTensor(\n",
        "            np.array(label_multiset[\"node_index_2\"].todense()))\n",
        "        edge_adj_1, edge_adj_2 = label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"]\n",
        "        node_features_1, node_features_2 = label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"]\n",
        "        edge_features_1, edge_features_2 = label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"]\n",
        "\n",
        "        #gal\n",
        "        graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, node_features_1)  #original graph node\n",
        "        graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, node_features_2)  #generated graph node\n",
        "        edge1_hidden1, edge1_hidden2 = self.gal_pass(edge_adj_1, edge_features_1)  #original edge node\n",
        "        edge2_hidden1, edge2_hidden2 = self.gal_pass(edge_adj_2, edge_features_2)  #generated graph edge\n",
        "        #node level embedding Concatenation\n",
        "        graph1_01concat = torch.cat([node_features_1, graph1_hidden1], dim=1)\n",
        "        graph2_01concat = torch.cat([node_features_2, graph2_hidden1], dim=1)\n",
        "        graph1_12concat = torch.cat([graph1_hidden1, graph1_hidden2], dim=1)\n",
        "        graph2_12concat = torch.cat([graph2_hidden1, graph2_hidden2], dim=1)\n",
        "        #graph pooling: node Sum\n",
        "        graph1_01pooled, max_idxs = torch.max(graph1_01concat, 0)\n",
        "        graph2_01pooled, max_idxs = torch.max(graph2_01concat, 0)\n",
        "        graph1_12pooled, max_idxs = torch.max(graph1_12concat, 0)\n",
        "        graph2_12pooled, max_idxs = torch.max(graph2_12concat, 0)\n",
        "\n",
        "        graph1_01pooled = torch.unsqueeze(graph1_01pooled, 1)\n",
        "        graph2_01pooled = torch.unsqueeze(graph2_01pooled, 1)\n",
        "        graph1_12pooled = torch.unsqueeze(graph1_12pooled, 1)\n",
        "        graph2_12pooled = torch.unsqueeze(graph2_12pooled, 1)\n",
        "\n",
        "        #edge level embedding Concatenation\n",
        "        edge1_01concat = torch.cat([edge_features_1, edge1_hidden1], dim=1)\n",
        "        edge2_01concat = torch.cat([edge_features_2, edge2_hidden1], dim=1)\n",
        "        #graph pooling: edge Sum\n",
        "        edge1_01pooled, max_idxs = torch.max(edge1_01concat, 0)\n",
        "        edge2_01pooled, max_idxs = torch.max(edge2_01concat, 0)\n",
        "        edge1_01pooled = torch.unsqueeze(edge1_01pooled, 1)\n",
        "        edge2_01pooled = torch.unsqueeze(edge2_01pooled, 1)\n",
        "\n",
        "        # scores_nc = self.tensor_network_nc(graph1_01pooled, graph2_01pooled)\n",
        "        # scores_nc = torch.t(scores_nc)\n",
        "        #\n",
        "        # scores_nc = torch.nn.functional.relu(self.fully_connected_first_nc(scores_nc))\n",
        "        # scores_nc = torch.nn.functional.relu(self.fully_connected_second_nc(scores_nc))\n",
        "        # scores_nc = torch.nn.functional.relu(self.fully_connected_third_nc(scores_nc))\n",
        "        # score_nc = torch.sigmoid(self.scoring_layer_nc(scores_nc))\n",
        "\n",
        "        scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
        "        scores_in = torch.t(scores_in)\n",
        "\n",
        "        scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
        "        scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
        "        scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
        "        score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
        "\n",
        "        # scores_ie = self.tensor_network_ie(graph1_12pooled, graph2_12pooled)\n",
        "        # scores_ie = torch.t(scores_ie)\n",
        "        #\n",
        "        # scores_ie = torch.nn.functional.relu(self.fully_connected_first_ie(scores_ie))\n",
        "        # scores_ie = torch.nn.functional.relu(self.fully_connected_second_ie(scores_ie))\n",
        "        # scores_ie = torch.nn.functional.relu(self.fully_connected_third_ie(scores_ie))\n",
        "        # score_ie = torch.sigmoid(self.scoring_layer_ie(scores_ie))\n",
        "\n",
        "        scores_ec = self.tensor_network_ec(edge1_01pooled, edge2_01pooled)\n",
        "        scores_ec = torch.t(scores_ec)\n",
        "\n",
        "        scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
        "        scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
        "        scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
        "        score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
        "\n",
        "        return torch.cat([ score_in,  score_ec], dim=1)\n",
        "\n",
        "    def transform_label_multiset(self, graph_pair, type_specified=True):\n",
        "        graph1 = graph_pair['graph_pair'][0]\n",
        "        graph2 = graph_pair['graph_pair'][1]\n",
        "        ged = graph_pair['ged']\n",
        "        #node and edge info of pair graph\n",
        "        node_info1 = nx.get_node_attributes(graph1, 'label')\n",
        "        node_info2 = nx.get_node_attributes(graph2, 'label')\n",
        "        edge_info1 = nx.get_edge_attributes(graph1, 'id')\n",
        "        edge_info2 = nx.get_edge_attributes(graph2, 'id')\n",
        "        nodes1 = list(graph1.nodes())\n",
        "        nodes2 = list(graph2.nodes())\n",
        "        edges1 = list(graph1.edges())\n",
        "        edges2 = list(graph2.edges())\n",
        "\n",
        "        label_multiset = dict()\n",
        "        node_features_1, node_features_2, edge_features_1, edge_features_2, edge_adj_1, edge_adj_2 = [], [], [], [], [], []\n",
        "\n",
        "        for i in graph1.nodes():\n",
        "            node_features_1.append([1.0 if node_info1[i] == node else 0.0 for node in self.node_type])\n",
        "        for i in graph2.nodes():\n",
        "            node_features_2.append([1.0 if node_info2[i] == node else 0.0 for node in self.node_type])\n",
        "        node_features_1, node_features_2 = torch.FloatTensor(np.array(node_features_1)), torch.FloatTensor(\n",
        "            np.array(node_features_2))\n",
        "\n",
        "        for i in edges1:\n",
        "            edge_features_1.append([1.0 if edge_info1[i] == edge else 0.0 for edge in self.edge_type])\n",
        "            adj_row = []\n",
        "            for d in edges1:\n",
        "                if (i == d):\n",
        "                    adj_row.append(0.0)\n",
        "                    continue\n",
        "                if ((i[0] in d) | (i[1] in d)):\n",
        "                    adj_row.append(1.0)\n",
        "                else:\n",
        "                    adj_row.append(0.0)\n",
        "            edge_adj_1.append(adj_row)\n",
        "        for i in edges2:\n",
        "            edge_features_2.append([1.0 if edge_info2[i] == edge else 0.0 for edge in self.edge_type])\n",
        "            adj_row = []\n",
        "            for d in edges2:\n",
        "                if (i == d):\n",
        "                    adj_row.append(0.0)\n",
        "                    continue\n",
        "                if ((i[0] in d) | (i[1] in d)):\n",
        "                    adj_row.append(1.0)\n",
        "                else:\n",
        "                    adj_row.append(0.0)\n",
        "            edge_adj_2.append(adj_row)\n",
        "        edge_features_1, edge_features_2 = torch.FloatTensor(np.array(edge_features_1)), torch.FloatTensor(\n",
        "            np.array(edge_features_2))\n",
        "        edge_adj_1, edge_adj_2 = torch.FloatTensor(np.array(edge_adj_1)), torch.FloatTensor(np.array(edge_adj_2))\n",
        "\n",
        "        label_multiset[\"node_index_1\"], label_multiset[\"node_index_2\"] = nx.adjacency_matrix(\n",
        "            graph1), nx.adjacency_matrix(graph2)\n",
        "        label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"] = node_features_1, node_features_2\n",
        "        label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"] = edge_features_1, edge_features_2\n",
        "        label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"] = edge_adj_1, edge_adj_2\n",
        "\n",
        "        #ged normalisation\n",
        "        if (type_specified):  # for training\n",
        "            avg_node_number = 0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes())\n",
        "            norm_ged = [n / avg_node_number for n in ged]\n",
        "            norm_ged = np.array(norm_ged)\n",
        "            label_multiset[\"target\"] = torch.from_numpy(np.exp(-norm_ged)).view(1, -1).float()\n",
        "\n",
        "            norm_gt_ged = (len(ged)) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "        else:  # for testing\n",
        "            norm_gt_ged = (ged) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "\n",
        "        return label_multiset\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = 20\n",
        "tensor_neurons = 16\n",
        "bottle_neck_neurons = 16\n",
        "batch_size = 128\n",
        "dropout = 0.0\n",
        "lr = 0.001\n",
        "weight_decay = 0.0\n",
        "\n",
        "Node_Types = ['1']\n",
        "Edge_Types = ['1']\n",
        "#collection global node label and edge label info\n",
        "\n",
        "print(\"\\n-------Model training---------.\\n\")\n",
        "\n",
        "model = TaGSim(Node_Types, Edge_Types, tensor_neurons, bottle_neck_neurons)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "iteration = 0\n",
        "\n",
        "visual_loss_train = []\n",
        "test_scores = []\n",
        "visual_loss_test = []\n",
        "train_pair = []\n",
        "test_pair = []\n",
        "epo = []\n",
        "\n",
        "#model training\n",
        "for epoch in range(epochs):\n",
        "    random.shuffle(train_pairs)\n",
        "    batches = []\n",
        "    for graph in range(0, len(train_pairs), batch_size):\n",
        "        batches.append(train_pairs[graph:graph + batch_size])\n",
        "\n",
        "    for batch in batches:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        losses = 0\n",
        "        for graph_pair in batch:\n",
        "            data = model.transform_label_multiset(graph_pair)\n",
        "            prediction = model(data)\n",
        "            losses += torch.nn.functional.mse_loss(data[\"target\"], prediction)\n",
        "\n",
        "        losses.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        loss = losses.item()\n",
        "        print('Iteration', iteration, 'loss: ', loss / len(batch))\n",
        "        iteration += 1\n",
        "\n",
        "    visual_loss_train.append(loss / len(batch))\n",
        "    # testing\n",
        "    model.eval()\n",
        "    for n in test_pairs:\n",
        "        graph1 = n['graph_pair'][0]  #updated_test\n",
        "        graph2 = n['graph_pair'][1]  #updated_test\n",
        "        ged = int(n['gt_ged'])\n",
        "        tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "        data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "        prediction = model(data)\n",
        "        prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "        current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "        test_scores.append(current_error.data.item())\n",
        "    visual_loss_test.append(sum(test_scores) / len(test_scores))\n",
        "    epo.append(epoch + 1)\n",
        "\n",
        "#visualization of traning and testing loss\n",
        "plt.plot(epo, visual_loss_train, 'g', label='Training Loss')\n",
        "plt.plot(epo, visual_loss_test, 'b', label='Validation Loss')\n",
        "plt.title('Evaluation of TaGSim Model with MAX Graph Pooling layer (' + DATASET + ')')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n-------Model testing---------.\\n\")\n",
        "\n",
        "model.eval()\n",
        "test_scores = []\n",
        "for n in test_pairs:\n",
        "    graph1 = n['graph_pair'][0]  #updated_test\n",
        "    graph2 = n['graph_pair'][1]  #updated_test\n",
        "    ged = int(n['gt_ged'])\n",
        "    tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "    data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "    prediction = model(data)\n",
        "    prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "    current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "    test_scores.append(current_error.data.item())\n",
        "\n",
        "model_error = sum(test_scores) / len(test_scores)\n",
        "print(\"\\nModel test error: \" + str(model_error))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xsjve2chCWrc",
        "outputId": "ff38ce1e-755d-4232-ad99-eddc8b923690"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model training---------.\n",
            "\n",
            "Iteration 0 loss:  0.07919812947511673\n",
            "Iteration 1 loss:  0.07785609364509583\n",
            "Iteration 2 loss:  0.08586514741182327\n",
            "Iteration 3 loss:  0.08247215300798416\n",
            "Iteration 4 loss:  0.0831141546368599\n",
            "Iteration 5 loss:  0.08134765923023224\n",
            "Iteration 6 loss:  0.07808508723974228\n",
            "Iteration 7 loss:  0.0814896672964096\n",
            "Iteration 8 loss:  0.08008097857236862\n",
            "Iteration 9 loss:  0.08474807937939961\n",
            "Iteration 10 loss:  0.083806112408638\n",
            "Iteration 11 loss:  0.0813029482960701\n",
            "Iteration 12 loss:  0.07546649873256683\n",
            "Iteration 13 loss:  0.07536724954843521\n",
            "Iteration 14 loss:  0.0840739756822586\n",
            "Iteration 15 loss:  0.08312353491783142\n",
            "Iteration 16 loss:  0.07396095991134644\n",
            "Iteration 17 loss:  0.07698941975831985\n",
            "Iteration 18 loss:  0.07993099838495255\n",
            "Iteration 19 loss:  0.08134606977303822\n",
            "Iteration 20 loss:  0.07784949988126755\n",
            "Iteration 21 loss:  0.07736273109912872\n",
            "Iteration 22 loss:  0.07902617752552032\n",
            "Iteration 23 loss:  0.07531815767288208\n",
            "Iteration 24 loss:  0.09150376915931702\n",
            "Iteration 25 loss:  0.07828228175640106\n",
            "Iteration 26 loss:  0.07946562767028809\n",
            "Iteration 27 loss:  0.07715002447366714\n",
            "Iteration 28 loss:  0.06941738724708557\n",
            "Iteration 29 loss:  0.06132581333319346\n",
            "Iteration 30 loss:  0.07796052098274231\n",
            "Iteration 31 loss:  0.07243620604276657\n",
            "Iteration 32 loss:  0.0784975066781044\n",
            "Iteration 33 loss:  0.07869464159011841\n",
            "Iteration 34 loss:  0.07403527200222015\n",
            "Iteration 35 loss:  0.07785962522029877\n",
            "Iteration 36 loss:  0.07341838628053665\n",
            "Iteration 37 loss:  0.08009158819913864\n",
            "Iteration 38 loss:  0.0675857812166214\n",
            "Iteration 39 loss:  0.0779625376065572\n",
            "Iteration 40 loss:  0.0702764019370079\n",
            "Iteration 41 loss:  0.07222627103328705\n",
            "Iteration 42 loss:  0.0732317790389061\n",
            "Iteration 43 loss:  0.0783439353108406\n",
            "Iteration 44 loss:  0.06786923855543137\n",
            "Iteration 45 loss:  0.08003780245780945\n",
            "Iteration 46 loss:  0.07812338322401047\n",
            "Iteration 47 loss:  0.07938840985298157\n",
            "Iteration 48 loss:  0.06718429923057556\n",
            "Iteration 49 loss:  0.06220213075478872\n",
            "Iteration 50 loss:  0.07051432877779007\n",
            "Iteration 51 loss:  0.07441720366477966\n",
            "Iteration 52 loss:  0.06648565828800201\n",
            "Iteration 53 loss:  0.07308964431285858\n",
            "Iteration 54 loss:  0.07431916147470474\n",
            "Iteration 55 loss:  0.07073307037353516\n",
            "Iteration 56 loss:  0.07107950001955032\n",
            "Iteration 57 loss:  0.07006269693374634\n",
            "Iteration 58 loss:  0.07506237179040909\n",
            "Iteration 59 loss:  0.06071734925111135\n",
            "Iteration 60 loss:  0.06314659863710403\n",
            "Iteration 61 loss:  0.0683978796005249\n",
            "Iteration 62 loss:  0.06532751768827438\n",
            "Iteration 63 loss:  0.06611935049295425\n",
            "Iteration 64 loss:  0.06734821200370789\n",
            "Iteration 65 loss:  0.07959452271461487\n",
            "Iteration 66 loss:  0.06989996880292892\n",
            "Iteration 67 loss:  0.06790586560964584\n",
            "Iteration 68 loss:  0.07015559077262878\n",
            "Iteration 69 loss:  0.06890758872032166\n",
            "Iteration 70 loss:  0.0653393417596817\n",
            "Iteration 71 loss:  0.07257115095853806\n",
            "Iteration 72 loss:  0.06841359287500381\n",
            "Iteration 73 loss:  0.06568251550197601\n",
            "Iteration 74 loss:  0.06084434315562248\n",
            "Iteration 75 loss:  0.06120534613728523\n",
            "Iteration 76 loss:  0.06475729495286942\n",
            "Iteration 77 loss:  0.07075132429599762\n",
            "Iteration 78 loss:  0.06443042308092117\n",
            "Iteration 79 loss:  0.06168253223101298\n",
            "Iteration 80 loss:  0.06580101698637009\n",
            "Iteration 81 loss:  0.06651701033115387\n",
            "Iteration 82 loss:  0.061776112765073776\n",
            "Iteration 83 loss:  0.06335857510566711\n",
            "Iteration 84 loss:  0.0589122399687767\n",
            "Iteration 85 loss:  0.060674961656332016\n",
            "Iteration 86 loss:  0.06435642391443253\n",
            "Iteration 87 loss:  0.0644792914390564\n",
            "Iteration 88 loss:  0.06478025764226913\n",
            "Iteration 89 loss:  0.05625425775845846\n",
            "Iteration 90 loss:  0.06486804038286209\n",
            "Iteration 91 loss:  0.06663690507411957\n",
            "Iteration 92 loss:  0.05796245485544205\n",
            "Iteration 93 loss:  0.055442456156015396\n",
            "Iteration 94 loss:  0.06453203409910202\n",
            "Iteration 95 loss:  0.06398467719554901\n",
            "Iteration 96 loss:  0.06816055625677109\n",
            "Iteration 97 loss:  0.04983723163604736\n",
            "Iteration 98 loss:  0.05753272771835327\n",
            "Iteration 99 loss:  0.057570834954579674\n",
            "Iteration 100 loss:  0.05695664882659912\n",
            "Iteration 101 loss:  0.06754646450281143\n",
            "Iteration 102 loss:  0.05541122704744339\n",
            "Iteration 103 loss:  0.059654928743839264\n",
            "Iteration 104 loss:  0.05961719527840614\n",
            "Iteration 105 loss:  0.05647817999124527\n",
            "Iteration 106 loss:  0.061603423207998276\n",
            "Iteration 107 loss:  0.05739589035511017\n",
            "Iteration 108 loss:  0.05411791801452637\n",
            "Iteration 109 loss:  0.06259411573410034\n",
            "Iteration 110 loss:  0.05928632989525795\n",
            "Iteration 111 loss:  0.059436872601509094\n",
            "Iteration 112 loss:  0.05994105711579323\n",
            "Iteration 113 loss:  0.060955505818128586\n",
            "Iteration 114 loss:  0.0495937205851078\n",
            "Iteration 115 loss:  0.06251740455627441\n",
            "Iteration 116 loss:  0.058481425046920776\n",
            "Iteration 117 loss:  0.05882816016674042\n",
            "Iteration 118 loss:  0.047116074711084366\n",
            "Iteration 119 loss:  0.044185166557629905\n",
            "Iteration 120 loss:  0.05141820013523102\n",
            "Iteration 121 loss:  0.04910380765795708\n",
            "Iteration 122 loss:  0.06335081160068512\n",
            "Iteration 123 loss:  0.05591210722923279\n",
            "Iteration 124 loss:  0.054032351821660995\n",
            "Iteration 125 loss:  0.05931922420859337\n",
            "Iteration 126 loss:  0.05423007532954216\n",
            "Iteration 127 loss:  0.04926326870918274\n",
            "Iteration 128 loss:  0.05424218252301216\n",
            "Iteration 129 loss:  0.048736502726872764\n",
            "Iteration 130 loss:  0.0507807731628418\n",
            "Iteration 131 loss:  0.049534495919942856\n",
            "Iteration 132 loss:  0.04915430396795273\n",
            "Iteration 133 loss:  0.05442330241203308\n",
            "Iteration 134 loss:  0.058190252631902695\n",
            "Iteration 135 loss:  0.052086640149354935\n",
            "Iteration 136 loss:  0.05485386401414871\n",
            "Iteration 137 loss:  0.0498916357755661\n",
            "Iteration 138 loss:  0.04688963666558266\n",
            "Iteration 139 loss:  0.04263238608837128\n",
            "Iteration 140 loss:  0.05502926558256149\n",
            "Iteration 141 loss:  0.047783613204956055\n",
            "Iteration 142 loss:  0.04957215115427971\n",
            "Iteration 143 loss:  0.05179203301668167\n",
            "Iteration 144 loss:  0.04708350449800491\n",
            "Iteration 145 loss:  0.05085308477282524\n",
            "Iteration 146 loss:  0.040623728185892105\n",
            "Iteration 147 loss:  0.04567762464284897\n",
            "Iteration 148 loss:  0.04364001378417015\n",
            "Iteration 149 loss:  0.04739364484945933\n",
            "Iteration 150 loss:  0.04550213739275932\n",
            "Iteration 151 loss:  0.039904262870550156\n",
            "Iteration 152 loss:  0.04810085520148277\n",
            "Iteration 153 loss:  0.04231765493750572\n",
            "Iteration 154 loss:  0.040619559586048126\n",
            "Iteration 155 loss:  0.049439072608947754\n",
            "Iteration 156 loss:  0.04990994185209274\n",
            "Iteration 157 loss:  0.03894425556063652\n",
            "Iteration 158 loss:  0.04193747788667679\n",
            "Iteration 159 loss:  0.04137391845385233\n",
            "Iteration 160 loss:  0.04333443194627762\n",
            "Iteration 161 loss:  0.03979188948869705\n",
            "Iteration 162 loss:  0.04123686999082565\n",
            "Iteration 163 loss:  0.042768388986587524\n",
            "Iteration 164 loss:  0.03988170251250267\n",
            "Iteration 165 loss:  0.036876000463962555\n",
            "Iteration 166 loss:  0.038888197392225266\n",
            "Iteration 167 loss:  0.0344080850481987\n",
            "Iteration 168 loss:  0.04027004539966583\n",
            "Iteration 169 loss:  0.0326655904452006\n",
            "Iteration 170 loss:  0.03661078214645386\n",
            "Iteration 171 loss:  0.03978395089507103\n",
            "Iteration 172 loss:  0.03683193027973175\n",
            "Iteration 173 loss:  0.04106776416301727\n",
            "Iteration 174 loss:  0.032879408448934555\n",
            "Iteration 175 loss:  0.031595420092344284\n",
            "Iteration 176 loss:  0.03261903300881386\n",
            "Iteration 177 loss:  0.03596971929073334\n",
            "Iteration 178 loss:  0.02959197759628296\n",
            "Iteration 179 loss:  0.02244322995344798\n",
            "Iteration 180 loss:  0.03881913051009178\n",
            "Iteration 181 loss:  0.030302822589874268\n",
            "Iteration 182 loss:  0.028513073921203613\n",
            "Iteration 183 loss:  0.028672682121396065\n",
            "Iteration 184 loss:  0.030063094571232796\n",
            "Iteration 185 loss:  0.029392294585704803\n",
            "Iteration 186 loss:  0.030879585072398186\n",
            "Iteration 187 loss:  0.02957209013402462\n",
            "Iteration 188 loss:  0.03081083856523037\n",
            "Iteration 189 loss:  0.028482909003893535\n",
            "Iteration 190 loss:  0.027303431183099747\n",
            "Iteration 191 loss:  0.029080960899591446\n",
            "Iteration 192 loss:  0.02713366225361824\n",
            "Iteration 193 loss:  0.025761278346180916\n",
            "Iteration 194 loss:  0.03101627714931965\n",
            "Iteration 195 loss:  0.029403217136859894\n",
            "Iteration 196 loss:  0.029043445363640785\n",
            "Iteration 197 loss:  0.029110563918948174\n",
            "Iteration 198 loss:  0.029213525354862213\n",
            "Iteration 199 loss:  0.023824100693066914\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model testing---------.\n",
            "\n",
            "\n",
            "Model test error: 0.1247382732698073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MIN Pooling"
      ],
      "metadata": {
        "id": "ZuoWGguXCpef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class TensorNetworkModule(torch.nn.Module):\n",
        "    def __init__(self, tensor_neurons, input_dim):\n",
        "        super(TensorNetworkModule, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.setup_weights()\n",
        "        self.init_parameters()\n",
        "\n",
        "    def setup_weights(self):\n",
        "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.input_dim, self.input_dim, self.tensor_neurons))\n",
        "        self.weight_matrix_block = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 2 * self.input_dim))\n",
        "        self.bias = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 1))\n",
        "\n",
        "    def init_parameters(self):\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix_block)\n",
        "        torch.nn.init.xavier_uniform_(self.bias)\n",
        "\n",
        "    def forward(self, embedding_1, embedding_2):\n",
        "        scoring = torch.mm(torch.t(embedding_1), self.weight_matrix.view(self.input_dim, -1))\n",
        "        scoring = scoring.view(self.input_dim, self.tensor_neurons)\n",
        "        scoring = torch.mm(torch.t(scoring), embedding_2)\n",
        "        combined_representation = torch.cat((embedding_1, embedding_2))\n",
        "        block_scoring = torch.mm(self.weight_matrix_block, combined_representation)\n",
        "        scores = torch.nn.functional.relu(scoring + block_scoring + self.bias)\n",
        "        return scores\n",
        "\n",
        "\n",
        "def graph_aggregation_layer(input, adj):\n",
        "    result = torch.mm(adj, input)\n",
        "    return result\n",
        "\n",
        "\n",
        "class TaGSim(torch.nn.Module):\n",
        "    def __init__(self, number_of_node_labels, number_of_edge_labels, tensor_neurons, bottle_neck_neurons):\n",
        "        super(TaGSim, self).__init__()\n",
        "        self.number_of_node_labels = len(number_of_node_labels)\n",
        "        self.number_of_edge_labels = len(number_of_edge_labels)\n",
        "        self.node_type = number_of_node_labels\n",
        "        self.edge_type = number_of_edge_labels\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.bottle_neck_neurons = bottle_neck_neurons\n",
        "        self.setup_layers()\n",
        "\n",
        "    def setup_layers(self):\n",
        "        self.feature_count = self.tensor_neurons\n",
        "\n",
        "        # self.tensor_network_nc = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_in = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        # self.tensor_network_ie = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_ec = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_edge_labels)\n",
        "\n",
        "        # self.fully_connected_first_nc = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_nc = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_nc = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_nc = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_in = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_in = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_in = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_in = torch.nn.Linear(4, 1)\n",
        "\n",
        "        # self.fully_connected_first_ie = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_ie = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_ie = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_ie = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_ec = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_ec = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_ec = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_ec = torch.nn.Linear(4, 1)\n",
        "\n",
        "    def gal_pass(self, edge_index, features):\n",
        "        hidden1 = graph_aggregation_layer(features, edge_index)\n",
        "        hidden2 = graph_aggregation_layer(hidden1, edge_index)\n",
        "\n",
        "        return hidden1, hidden2\n",
        "\n",
        "    def forward(self, label_multiset):\n",
        "        adj_1, adj_2 = torch.FloatTensor(np.array(label_multiset[\"node_index_1\"].todense())), torch.FloatTensor(\n",
        "            np.array(label_multiset[\"node_index_2\"].todense()))\n",
        "        edge_adj_1, edge_adj_2 = label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"]\n",
        "        node_features_1, node_features_2 = label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"]\n",
        "        edge_features_1, edge_features_2 = label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"]\n",
        "\n",
        "        #gal\n",
        "        graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, node_features_1)  #original graph node\n",
        "        graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, node_features_2)  #generated graph node\n",
        "        edge1_hidden1, edge1_hidden2 = self.gal_pass(edge_adj_1, edge_features_1)  #original edge node\n",
        "        edge2_hidden1, edge2_hidden2 = self.gal_pass(edge_adj_2, edge_features_2)  #generated graph edge\n",
        "        #node level embedding Concatenation\n",
        "        graph1_01concat = torch.cat([node_features_1, graph1_hidden1], dim=1)\n",
        "        graph2_01concat = torch.cat([node_features_2, graph2_hidden1], dim=1)\n",
        "        graph1_12concat = torch.cat([graph1_hidden1, graph1_hidden2], dim=1)\n",
        "        graph2_12concat = torch.cat([graph2_hidden1, graph2_hidden2], dim=1)\n",
        "        #graph pooling: node Sum\n",
        "        graph1_01pooled, min_idxs = torch.min(graph1_01concat, 0)\n",
        "        graph2_01pooled, min_idxs = torch.min(graph2_01concat, 0)\n",
        "        graph1_12pooled, min_idxs = torch.min(graph1_12concat, 0)\n",
        "        graph2_12pooled, min_idxs = torch.min(graph2_12concat, 0)\n",
        "\n",
        "        graph1_01pooled = torch.unsqueeze(graph1_01pooled, 1)\n",
        "        graph2_01pooled = torch.unsqueeze(graph2_01pooled, 1)\n",
        "        graph1_12pooled = torch.unsqueeze(graph1_12pooled, 1)\n",
        "        graph2_12pooled = torch.unsqueeze(graph2_12pooled, 1)\n",
        "\n",
        "        #edge level embedding Concatenation\n",
        "        edge1_01concat = torch.cat([edge_features_1, edge1_hidden1], dim=1)\n",
        "        edge2_01concat = torch.cat([edge_features_2, edge2_hidden1], dim=1)\n",
        "        #graph pooling: edge Sum\n",
        "        edge1_01pooled, min_idxs = torch.min(edge1_01concat, 0)\n",
        "        edge2_01pooled, min_idxs = torch.min(edge2_01concat, 0)\n",
        "        edge1_01pooled = torch.unsqueeze(edge1_01pooled, 1)\n",
        "        edge2_01pooled = torch.unsqueeze(edge2_01pooled, 1)\n",
        "\n",
        "        # scores_nc = self.tensor_network_nc(graph1_01pooled, graph2_01pooled)\n",
        "        # scores_nc = torch.t(scores_nc)\n",
        "        #\n",
        "        # scores_nc = torch.nn.functional.relu(self.fully_connected_first_nc(scores_nc))\n",
        "        # scores_nc = torch.nn.functional.relu(self.fully_connected_second_nc(scores_nc))\n",
        "        # scores_nc = torch.nn.functional.relu(self.fully_connected_third_nc(scores_nc))\n",
        "        # score_nc = torch.sigmoid(self.scoring_layer_nc(scores_nc))\n",
        "\n",
        "        scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
        "        scores_in = torch.t(scores_in)\n",
        "\n",
        "        scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
        "        scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
        "        scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
        "        score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
        "\n",
        "        # scores_ie = self.tensor_network_ie(graph1_12pooled, graph2_12pooled)\n",
        "        # scores_ie = torch.t(scores_ie)\n",
        "        #\n",
        "        # scores_ie = torch.nn.functional.relu(self.fully_connected_first_ie(scores_ie))\n",
        "        # scores_ie = torch.nn.functional.relu(self.fully_connected_second_ie(scores_ie))\n",
        "        # scores_ie = torch.nn.functional.relu(self.fully_connected_third_ie(scores_ie))\n",
        "        # score_ie = torch.sigmoid(self.scoring_layer_ie(scores_ie))\n",
        "\n",
        "        scores_ec = self.tensor_network_ec(edge1_01pooled, edge2_01pooled)\n",
        "        scores_ec = torch.t(scores_ec)\n",
        "\n",
        "        scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
        "        scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
        "        scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
        "        score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
        "\n",
        "        return torch.cat([ score_in,  score_ec], dim=1)\n",
        "\n",
        "    def transform_label_multiset(self, graph_pair, type_specified=True):\n",
        "        graph1 = graph_pair['graph_pair'][0]\n",
        "        graph2 = graph_pair['graph_pair'][1]\n",
        "        ged = graph_pair['ged']\n",
        "        #node and edge info of pair graph\n",
        "        node_info1 = nx.get_node_attributes(graph1, 'label')\n",
        "        node_info2 = nx.get_node_attributes(graph2, 'label')\n",
        "        edge_info1 = nx.get_edge_attributes(graph1, 'id')\n",
        "        edge_info2 = nx.get_edge_attributes(graph2, 'id')\n",
        "        nodes1 = list(graph1.nodes())\n",
        "        nodes2 = list(graph2.nodes())\n",
        "        edges1 = list(graph1.edges())\n",
        "        edges2 = list(graph2.edges())\n",
        "\n",
        "        label_multiset = dict()\n",
        "        node_features_1, node_features_2, edge_features_1, edge_features_2, edge_adj_1, edge_adj_2 = [], [], [], [], [], []\n",
        "\n",
        "        for i in graph1.nodes():\n",
        "            node_features_1.append([1.0 if node_info1[i] == node else 0.0 for node in self.node_type])\n",
        "        for i in graph2.nodes():\n",
        "            node_features_2.append([1.0 if node_info2[i] == node else 0.0 for node in self.node_type])\n",
        "        node_features_1, node_features_2 = torch.FloatTensor(np.array(node_features_1)), torch.FloatTensor(\n",
        "            np.array(node_features_2))\n",
        "\n",
        "        for i in edges1:\n",
        "            edge_features_1.append([1.0 if edge_info1[i] == edge else 0.0 for edge in self.edge_type])\n",
        "            adj_row = []\n",
        "            for d in edges1:\n",
        "                if (i == d):\n",
        "                    adj_row.append(0.0)\n",
        "                    continue\n",
        "                if ((i[0] in d) | (i[1] in d)):\n",
        "                    adj_row.append(1.0)\n",
        "                else:\n",
        "                    adj_row.append(0.0)\n",
        "            edge_adj_1.append(adj_row)\n",
        "        for i in edges2:\n",
        "            edge_features_2.append([1.0 if edge_info2[i] == edge else 0.0 for edge in self.edge_type])\n",
        "            adj_row = []\n",
        "            for d in edges2:\n",
        "                if (i == d):\n",
        "                    adj_row.append(0.0)\n",
        "                    continue\n",
        "                if ((i[0] in d) | (i[1] in d)):\n",
        "                    adj_row.append(1.0)\n",
        "                else:\n",
        "                    adj_row.append(0.0)\n",
        "            edge_adj_2.append(adj_row)\n",
        "        edge_features_1, edge_features_2 = torch.FloatTensor(np.array(edge_features_1)), torch.FloatTensor(\n",
        "            np.array(edge_features_2))\n",
        "        edge_adj_1, edge_adj_2 = torch.FloatTensor(np.array(edge_adj_1)), torch.FloatTensor(np.array(edge_adj_2))\n",
        "\n",
        "        label_multiset[\"node_index_1\"], label_multiset[\"node_index_2\"] = nx.adjacency_matrix(\n",
        "            graph1), nx.adjacency_matrix(graph2)\n",
        "        label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"] = node_features_1, node_features_2\n",
        "        label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"] = edge_features_1, edge_features_2\n",
        "        label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"] = edge_adj_1, edge_adj_2\n",
        "\n",
        "        #ged normalisation\n",
        "        if (type_specified):  # for training\n",
        "            avg_node_number = 0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes())\n",
        "            norm_ged = [n / avg_node_number for n in ged]\n",
        "            norm_ged = np.array(norm_ged)\n",
        "            label_multiset[\"target\"] = torch.from_numpy(np.exp(-norm_ged)).view(1, -1).float()\n",
        "\n",
        "            norm_gt_ged = (len(ged)) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "        else:  # for testing\n",
        "            norm_gt_ged = (ged) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "\n",
        "        return label_multiset\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = 20\n",
        "tensor_neurons = 16\n",
        "bottle_neck_neurons = 16\n",
        "batch_size = 128\n",
        "dropout = 0.0\n",
        "lr = 0.001\n",
        "weight_decay = 0.0\n",
        "\n",
        "Node_Types = ['1']\n",
        "Edge_Types = ['1']\n",
        "#collection global node label and edge label info\n",
        "\n",
        "print(\"\\n-------Model training---------.\\n\")\n",
        "\n",
        "model = TaGSim(Node_Types, Edge_Types, tensor_neurons, bottle_neck_neurons)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "iteration = 0\n",
        "\n",
        "visual_loss_train = []\n",
        "test_scores = []\n",
        "visual_loss_test = []\n",
        "train_pair = []\n",
        "test_pair = []\n",
        "epo = []\n",
        "\n",
        "#model training\n",
        "for epoch in range(epochs):\n",
        "    random.shuffle(train_pairs)\n",
        "    batches = []\n",
        "    for graph in range(0, len(train_pairs), batch_size):\n",
        "        batches.append(train_pairs[graph:graph + batch_size])\n",
        "\n",
        "    for batch in batches:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        losses = 0\n",
        "        for graph_pair in batch:\n",
        "            data = model.transform_label_multiset(graph_pair)\n",
        "            prediction = model(data)\n",
        "            losses += torch.nn.functional.mse_loss(data[\"target\"], prediction)\n",
        "\n",
        "        losses.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        loss = losses.item()\n",
        "        print('Iteration', iteration, 'loss: ', loss / len(batch))\n",
        "        iteration += 1\n",
        "\n",
        "    visual_loss_train.append(loss / len(batch))\n",
        "    # testing\n",
        "    model.eval()\n",
        "    for n in test_pairs:\n",
        "        graph1 = n['graph_pair'][0]  #updated_test\n",
        "        graph2 = n['graph_pair'][1]  #updated_test\n",
        "        ged = int(n['gt_ged'])\n",
        "        tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "        data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "        prediction = model(data)\n",
        "        prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "        current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "        test_scores.append(current_error.data.item())\n",
        "    visual_loss_test.append(sum(test_scores) / len(test_scores))\n",
        "    epo.append(epoch + 1)\n",
        "\n",
        "#visualization of traning and testing loss\n",
        "plt.plot(epo, visual_loss_train, 'g', label='Training Loss')\n",
        "plt.plot(epo, visual_loss_test, 'b', label='Validation Loss')\n",
        "plt.title('Evaluation of TaGSim Model with MIN Graph Pooling layer (' + DATASET + ')')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n-------Model testing---------.\\n\")\n",
        "\n",
        "model.eval()\n",
        "test_scores = []\n",
        "for n in test_pairs:\n",
        "    graph1 = n['graph_pair'][0]  #updated_test\n",
        "    graph2 = n['graph_pair'][1]  #updated_test\n",
        "    ged = int(n['gt_ged'])\n",
        "    tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "    data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "    prediction = model(data)\n",
        "    prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "    current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "    test_scores.append(current_error.data.item())\n",
        "\n",
        "model_error = sum(test_scores) / len(test_scores)\n",
        "print(\"\\nModel test error: \" + str(model_error))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qxUbMh8xCWok",
        "outputId": "40fd32f6-0eec-4101-8291-f9a71c626881"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model training---------.\n",
            "\n",
            "Iteration 0 loss:  0.10433503240346909\n",
            "Iteration 1 loss:  0.10441343486309052\n",
            "Iteration 2 loss:  0.09758713096380234\n",
            "Iteration 3 loss:  0.09966062009334564\n",
            "Iteration 4 loss:  0.1008688434958458\n",
            "Iteration 5 loss:  0.10098244249820709\n",
            "Iteration 6 loss:  0.0972660556435585\n",
            "Iteration 7 loss:  0.09898737818002701\n",
            "Iteration 8 loss:  0.09373898804187775\n",
            "Iteration 9 loss:  0.10252836346626282\n",
            "Iteration 10 loss:  0.0996306985616684\n",
            "Iteration 11 loss:  0.09132909774780273\n",
            "Iteration 12 loss:  0.09535548835992813\n",
            "Iteration 13 loss:  0.09825370460748672\n",
            "Iteration 14 loss:  0.09774383157491684\n",
            "Iteration 15 loss:  0.09792430698871613\n",
            "Iteration 16 loss:  0.10129789263010025\n",
            "Iteration 17 loss:  0.10056010633707047\n",
            "Iteration 18 loss:  0.08899158984422684\n",
            "Iteration 19 loss:  0.08814532558123271\n",
            "Iteration 20 loss:  0.09357201308012009\n",
            "Iteration 21 loss:  0.09683867543935776\n",
            "Iteration 22 loss:  0.0983228012919426\n",
            "Iteration 23 loss:  0.0927148312330246\n",
            "Iteration 24 loss:  0.09015406668186188\n",
            "Iteration 25 loss:  0.08868687599897385\n",
            "Iteration 26 loss:  0.08675017207860947\n",
            "Iteration 27 loss:  0.09229826927185059\n",
            "Iteration 28 loss:  0.09778698533773422\n",
            "Iteration 29 loss:  0.09054370721181233\n",
            "Iteration 30 loss:  0.09377630054950714\n",
            "Iteration 31 loss:  0.08491317182779312\n",
            "Iteration 32 loss:  0.09003209322690964\n",
            "Iteration 33 loss:  0.08871301263570786\n",
            "Iteration 34 loss:  0.0910140872001648\n",
            "Iteration 35 loss:  0.09389142692089081\n",
            "Iteration 36 loss:  0.09181717783212662\n",
            "Iteration 37 loss:  0.08114204555749893\n",
            "Iteration 38 loss:  0.08717229962348938\n",
            "Iteration 39 loss:  0.08791143695513408\n",
            "Iteration 40 loss:  0.08963306993246078\n",
            "Iteration 41 loss:  0.09469930082559586\n",
            "Iteration 42 loss:  0.08064161986112595\n",
            "Iteration 43 loss:  0.08999387174844742\n",
            "Iteration 44 loss:  0.08759507536888123\n",
            "Iteration 45 loss:  0.08073228597640991\n",
            "Iteration 46 loss:  0.0810089111328125\n",
            "Iteration 47 loss:  0.0897044986486435\n",
            "Iteration 48 loss:  0.07310765236616135\n",
            "Iteration 49 loss:  0.07988448441028595\n",
            "Iteration 50 loss:  0.08377974480390549\n",
            "Iteration 51 loss:  0.08547567576169968\n",
            "Iteration 52 loss:  0.08160439878702164\n",
            "Iteration 53 loss:  0.07524687051773071\n",
            "Iteration 54 loss:  0.07817395776510239\n",
            "Iteration 55 loss:  0.07765696197748184\n",
            "Iteration 56 loss:  0.07904863357543945\n",
            "Iteration 57 loss:  0.07750613242387772\n",
            "Iteration 58 loss:  0.0874270647764206\n",
            "Iteration 59 loss:  0.07692631582419078\n",
            "Iteration 60 loss:  0.06969279795885086\n",
            "Iteration 61 loss:  0.07969717681407928\n",
            "Iteration 62 loss:  0.07586238533258438\n",
            "Iteration 63 loss:  0.07654711604118347\n",
            "Iteration 64 loss:  0.07501564174890518\n",
            "Iteration 65 loss:  0.07759261876344681\n",
            "Iteration 66 loss:  0.0727018192410469\n",
            "Iteration 67 loss:  0.08021019399166107\n",
            "Iteration 68 loss:  0.0701344758272171\n",
            "Iteration 69 loss:  0.08457226554552714\n",
            "Iteration 70 loss:  0.0707840621471405\n",
            "Iteration 71 loss:  0.0800391286611557\n",
            "Iteration 72 loss:  0.07132498919963837\n",
            "Iteration 73 loss:  0.0760156661272049\n",
            "Iteration 74 loss:  0.06969152390956879\n",
            "Iteration 75 loss:  0.0681927502155304\n",
            "Iteration 76 loss:  0.06661885231733322\n",
            "Iteration 77 loss:  0.06627663224935532\n",
            "Iteration 78 loss:  0.06656862050294876\n",
            "Iteration 79 loss:  0.06236064434051514\n",
            "Iteration 80 loss:  0.06252887099981308\n",
            "Iteration 81 loss:  0.07195860147476196\n",
            "Iteration 82 loss:  0.06823485344648361\n",
            "Iteration 83 loss:  0.06406902521848679\n",
            "Iteration 84 loss:  0.06221591681241989\n",
            "Iteration 85 loss:  0.06509418040513992\n",
            "Iteration 86 loss:  0.06111631542444229\n",
            "Iteration 87 loss:  0.061052482575178146\n",
            "Iteration 88 loss:  0.06071631982922554\n",
            "Iteration 89 loss:  0.07041655977567036\n",
            "Iteration 90 loss:  0.06545504182577133\n",
            "Iteration 91 loss:  0.05978574603796005\n",
            "Iteration 92 loss:  0.06160888820886612\n",
            "Iteration 93 loss:  0.061025481671094894\n",
            "Iteration 94 loss:  0.050222739577293396\n",
            "Iteration 95 loss:  0.05490124225616455\n",
            "Iteration 96 loss:  0.05942043662071228\n",
            "Iteration 97 loss:  0.05357922986149788\n",
            "Iteration 98 loss:  0.05514856427907944\n",
            "Iteration 99 loss:  0.05932691693305969\n",
            "Iteration 100 loss:  0.05395166575908661\n",
            "Iteration 101 loss:  0.04787800833582878\n",
            "Iteration 102 loss:  0.054983124136924744\n",
            "Iteration 103 loss:  0.052236102521419525\n",
            "Iteration 104 loss:  0.05051770806312561\n",
            "Iteration 105 loss:  0.04697801545262337\n",
            "Iteration 106 loss:  0.05738101154565811\n",
            "Iteration 107 loss:  0.05263933911919594\n",
            "Iteration 108 loss:  0.04861004650592804\n",
            "Iteration 109 loss:  0.0396273136138916\n",
            "Iteration 110 loss:  0.04337103292346001\n",
            "Iteration 111 loss:  0.04688676446676254\n",
            "Iteration 112 loss:  0.049679018557071686\n",
            "Iteration 113 loss:  0.04513353109359741\n",
            "Iteration 114 loss:  0.04874110594391823\n",
            "Iteration 115 loss:  0.041385188698768616\n",
            "Iteration 116 loss:  0.04359492287039757\n",
            "Iteration 117 loss:  0.04220310226082802\n",
            "Iteration 118 loss:  0.03936934098601341\n",
            "Iteration 119 loss:  0.04183422029018402\n",
            "Iteration 120 loss:  0.04126891493797302\n",
            "Iteration 121 loss:  0.03855975717306137\n",
            "Iteration 122 loss:  0.04036487638950348\n",
            "Iteration 123 loss:  0.04378167912364006\n",
            "Iteration 124 loss:  0.03768329694867134\n",
            "Iteration 125 loss:  0.03514433652162552\n",
            "Iteration 126 loss:  0.03602467104792595\n",
            "Iteration 127 loss:  0.0360739640891552\n",
            "Iteration 128 loss:  0.03652934357523918\n",
            "Iteration 129 loss:  0.034319249292214714\n",
            "Iteration 130 loss:  0.03510219603776932\n",
            "Iteration 131 loss:  0.03942183777689934\n",
            "Iteration 132 loss:  0.034145209938287735\n",
            "Iteration 133 loss:  0.03487973287701607\n",
            "Iteration 134 loss:  0.030591383576393127\n",
            "Iteration 135 loss:  0.035088058561086655\n",
            "Iteration 136 loss:  0.02999071218073368\n",
            "Iteration 137 loss:  0.03126907721161842\n",
            "Iteration 138 loss:  0.031136207282543182\n",
            "Iteration 139 loss:  0.03151494264602661\n",
            "Iteration 140 loss:  0.03032878041267395\n",
            "Iteration 141 loss:  0.030803464353084564\n",
            "Iteration 142 loss:  0.030326688662171364\n",
            "Iteration 143 loss:  0.03060554899275303\n",
            "Iteration 144 loss:  0.029891472309827805\n",
            "Iteration 145 loss:  0.030673552304506302\n",
            "Iteration 146 loss:  0.02968410588800907\n",
            "Iteration 147 loss:  0.030202537775039673\n",
            "Iteration 148 loss:  0.031767502427101135\n",
            "Iteration 149 loss:  0.03347826997439066\n",
            "Iteration 150 loss:  0.0286497063934803\n",
            "Iteration 151 loss:  0.03578811511397362\n",
            "Iteration 152 loss:  0.02880585938692093\n",
            "Iteration 153 loss:  0.025332149118185043\n",
            "Iteration 154 loss:  0.025916533544659615\n",
            "Iteration 155 loss:  0.030680451542139053\n",
            "Iteration 156 loss:  0.02773885801434517\n",
            "Iteration 157 loss:  0.032926447689533234\n",
            "Iteration 158 loss:  0.02885950729250908\n",
            "Iteration 159 loss:  0.029486854871114094\n",
            "Iteration 160 loss:  0.029710203409194946\n",
            "Iteration 161 loss:  0.027755485847592354\n",
            "Iteration 162 loss:  0.03060728870332241\n",
            "Iteration 163 loss:  0.028186025097966194\n",
            "Iteration 164 loss:  0.028248732909560204\n",
            "Iteration 165 loss:  0.029260804876685143\n",
            "Iteration 166 loss:  0.02799670584499836\n",
            "Iteration 167 loss:  0.03041129745543003\n",
            "Iteration 168 loss:  0.030869774520397186\n",
            "Iteration 169 loss:  0.027241153021653492\n",
            "Iteration 170 loss:  0.028790783137083054\n",
            "Iteration 171 loss:  0.03207295387983322\n",
            "Iteration 172 loss:  0.029357105493545532\n",
            "Iteration 173 loss:  0.028554752469062805\n",
            "Iteration 174 loss:  0.02744903787970543\n",
            "Iteration 175 loss:  0.030578866600990295\n",
            "Iteration 176 loss:  0.025551315397024155\n",
            "Iteration 177 loss:  0.028369445353746414\n",
            "Iteration 178 loss:  0.03126776963472366\n",
            "Iteration 179 loss:  0.030501315991083782\n",
            "Iteration 180 loss:  0.03102981299161911\n",
            "Iteration 181 loss:  0.029030947014689445\n",
            "Iteration 182 loss:  0.032786913216114044\n",
            "Iteration 183 loss:  0.02792268991470337\n",
            "Iteration 184 loss:  0.026643987745046616\n",
            "Iteration 185 loss:  0.02731260471045971\n",
            "Iteration 186 loss:  0.02778385952115059\n",
            "Iteration 187 loss:  0.028080344200134277\n",
            "Iteration 188 loss:  0.03254874423146248\n",
            "Iteration 189 loss:  0.02728979041179021\n",
            "Iteration 190 loss:  0.0293573047965765\n",
            "Iteration 191 loss:  0.02644696645438671\n",
            "Iteration 192 loss:  0.030210644006729126\n",
            "Iteration 193 loss:  0.028042156249284744\n",
            "Iteration 194 loss:  0.029095882549881935\n",
            "Iteration 195 loss:  0.03160734847187996\n",
            "Iteration 196 loss:  0.031695879995822906\n",
            "Iteration 197 loss:  0.027988051995635033\n",
            "Iteration 198 loss:  0.026755113154649734\n",
            "Iteration 199 loss:  0.032249584794044495\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model testing---------.\n",
            "\n",
            "\n",
            "Model test error: 0.12355815868785915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MEAN Pooling"
      ],
      "metadata": {
        "id": "PKVQveHbCp32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class TensorNetworkModule(torch.nn.Module):\n",
        "    def __init__(self, tensor_neurons, input_dim):\n",
        "        super(TensorNetworkModule, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.setup_weights()\n",
        "        self.init_parameters()\n",
        "\n",
        "    def setup_weights(self):\n",
        "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.input_dim, self.input_dim, self.tensor_neurons))\n",
        "        self.weight_matrix_block = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 2 * self.input_dim))\n",
        "        self.bias = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 1))\n",
        "\n",
        "    def init_parameters(self):\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix_block)\n",
        "        torch.nn.init.xavier_uniform_(self.bias)\n",
        "\n",
        "    def forward(self, embedding_1, embedding_2):\n",
        "        scoring = torch.mm(torch.t(embedding_1), self.weight_matrix.view(self.input_dim, -1))\n",
        "        scoring = scoring.view(self.input_dim, self.tensor_neurons)\n",
        "        scoring = torch.mm(torch.t(scoring), embedding_2)\n",
        "        combined_representation = torch.cat((embedding_1, embedding_2))\n",
        "        block_scoring = torch.mm(self.weight_matrix_block, combined_representation)\n",
        "        scores = torch.nn.functional.relu(scoring + block_scoring + self.bias)\n",
        "        return scores\n",
        "\n",
        "\n",
        "def graph_aggregation_layer(input, adj):\n",
        "    result = torch.mm(adj, input)\n",
        "    return result\n",
        "\n",
        "\n",
        "class TaGSim(torch.nn.Module):\n",
        "    def __init__(self, number_of_node_labels, number_of_edge_labels, tensor_neurons, bottle_neck_neurons):\n",
        "        super(TaGSim, self).__init__()\n",
        "        self.number_of_node_labels = len(number_of_node_labels)\n",
        "        self.number_of_edge_labels = len(number_of_edge_labels)\n",
        "        self.node_type = number_of_node_labels\n",
        "        self.edge_type = number_of_edge_labels\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.bottle_neck_neurons = bottle_neck_neurons\n",
        "        self.setup_layers()\n",
        "\n",
        "    def setup_layers(self):\n",
        "        self.feature_count = self.tensor_neurons\n",
        "\n",
        "        # self.tensor_network_nc = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_in = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        # self.tensor_network_ie = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_ec = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_edge_labels)\n",
        "\n",
        "        # self.fully_connected_first_nc = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_nc = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_nc = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_nc = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_in = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_in = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_in = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_in = torch.nn.Linear(4, 1)\n",
        "\n",
        "        # self.fully_connected_first_ie = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_ie = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_ie = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_ie = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_ec = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_ec = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_ec = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_ec = torch.nn.Linear(4, 1)\n",
        "\n",
        "    def gal_pass(self, edge_index, features):\n",
        "        hidden1 = graph_aggregation_layer(features, edge_index)\n",
        "        hidden2 = graph_aggregation_layer(hidden1, edge_index)\n",
        "\n",
        "        return hidden1, hidden2\n",
        "\n",
        "    def forward(self, label_multiset):\n",
        "        adj_1, adj_2 = torch.FloatTensor(np.array(label_multiset[\"node_index_1\"].todense())), torch.FloatTensor(\n",
        "            np.array(label_multiset[\"node_index_2\"].todense()))\n",
        "        edge_adj_1, edge_adj_2 = label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"]\n",
        "        node_features_1, node_features_2 = label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"]\n",
        "        edge_features_1, edge_features_2 = label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"]\n",
        "\n",
        "        #gal\n",
        "        graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, node_features_1)  #original graph node\n",
        "        graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, node_features_2)  #generated graph node\n",
        "        edge1_hidden1, edge1_hidden2 = self.gal_pass(edge_adj_1, edge_features_1)  #original edge node\n",
        "        edge2_hidden1, edge2_hidden2 = self.gal_pass(edge_adj_2, edge_features_2)  #generated graph edge\n",
        "        #node level embedding Concatenation\n",
        "        graph1_01concat = torch.cat([node_features_1, graph1_hidden1], dim=1)\n",
        "        graph2_01concat = torch.cat([node_features_2, graph2_hidden1], dim=1)\n",
        "        graph1_12concat = torch.cat([graph1_hidden1, graph1_hidden2], dim=1)\n",
        "        graph2_12concat = torch.cat([graph2_hidden1, graph2_hidden2], dim=1)\n",
        "        #graph pooling: node Mean\n",
        "        graph1_01pooled = torch.mean(graph1_01concat, 0)\n",
        "        graph2_01pooled = torch.mean(graph2_01concat, 0)\n",
        "        graph1_12pooled = torch.mean(graph1_12concat, 0)\n",
        "        graph2_12pooled = torch.mean(graph2_12concat, 0)\n",
        "\n",
        "        graph1_01pooled = torch.unsqueeze(graph1_01pooled, 1)\n",
        "        graph2_01pooled = torch.unsqueeze(graph2_01pooled, 1)\n",
        "        graph1_12pooled = torch.unsqueeze(graph1_12pooled, 1)\n",
        "        graph2_12pooled = torch.unsqueeze(graph2_12pooled, 1)\n",
        "\n",
        "        #edge level embedding Concatenation\n",
        "        edge1_01concat = torch.cat([edge_features_1, edge1_hidden1], dim=1)\n",
        "        edge2_01concat = torch.cat([edge_features_2, edge2_hidden1], dim=1)\n",
        "        #graph pooling: edge Mean\n",
        "        edge1_01pooled = torch.mean(edge1_01concat, 0)\n",
        "        edge2_01pooled = torch.mean(edge2_01concat, 0)\n",
        "        edge1_01pooled = torch.unsqueeze(edge1_01pooled, 1)\n",
        "        edge2_01pooled = torch.unsqueeze(edge2_01pooled, 1)\n",
        "\n",
        "        # scores_nc = self.tensor_network_nc(graph1_01pooled, graph2_01pooled)\n",
        "        # scores_nc = torch.t(scores_nc)\n",
        "        #\n",
        "        # scores_nc = torch.nn.functional.relu(self.fully_connected_first_nc(scores_nc))\n",
        "        # scores_nc = torch.nn.functional.relu(self.fully_connected_second_nc(scores_nc))\n",
        "        # scores_nc = torch.nn.functional.relu(self.fully_connected_third_nc(scores_nc))\n",
        "        # score_nc = torch.sigmoid(self.scoring_layer_nc(scores_nc))\n",
        "\n",
        "        scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
        "        scores_in = torch.t(scores_in)\n",
        "\n",
        "        scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
        "        scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
        "        scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
        "        score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
        "\n",
        "        # scores_ie = self.tensor_network_ie(graph1_12pooled, graph2_12pooled)\n",
        "        # scores_ie = torch.t(scores_ie)\n",
        "        #\n",
        "        # scores_ie = torch.nn.functional.relu(self.fully_connected_first_ie(scores_ie))\n",
        "        # scores_ie = torch.nn.functional.relu(self.fully_connected_second_ie(scores_ie))\n",
        "        # scores_ie = torch.nn.functional.relu(self.fully_connected_third_ie(scores_ie))\n",
        "        # score_ie = torch.sigmoid(self.scoring_layer_ie(scores_ie))\n",
        "\n",
        "        scores_ec = self.tensor_network_ec(edge1_01pooled, edge2_01pooled)\n",
        "        scores_ec = torch.t(scores_ec)\n",
        "\n",
        "        scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
        "        scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
        "        scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
        "        score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
        "\n",
        "        return torch.cat([ score_in,  score_ec], dim=1)\n",
        "\n",
        "    def transform_label_multiset(self, graph_pair, type_specified=True):\n",
        "        graph1 = graph_pair['graph_pair'][0]\n",
        "        graph2 = graph_pair['graph_pair'][1]\n",
        "        ged = graph_pair['ged']\n",
        "        #node and edge info of pair graph\n",
        "        node_info1 = nx.get_node_attributes(graph1, 'label')\n",
        "        node_info2 = nx.get_node_attributes(graph2, 'label')\n",
        "        edge_info1 = nx.get_edge_attributes(graph1, 'id')\n",
        "        edge_info2 = nx.get_edge_attributes(graph2, 'id')\n",
        "        nodes1 = list(graph1.nodes())\n",
        "        nodes2 = list(graph2.nodes())\n",
        "        edges1 = list(graph1.edges())\n",
        "        edges2 = list(graph2.edges())\n",
        "\n",
        "        label_multiset = dict()\n",
        "        node_features_1, node_features_2, edge_features_1, edge_features_2, edge_adj_1, edge_adj_2 = [], [], [], [], [], []\n",
        "\n",
        "        for i in graph1.nodes():\n",
        "            node_features_1.append([1.0 if node_info1[i] == node else 0.0 for node in self.node_type])\n",
        "        for i in graph2.nodes():\n",
        "            node_features_2.append([1.0 if node_info2[i] == node else 0.0 for node in self.node_type])\n",
        "        node_features_1, node_features_2 = torch.FloatTensor(np.array(node_features_1)), torch.FloatTensor(\n",
        "            np.array(node_features_2))\n",
        "\n",
        "        for i in edges1:\n",
        "            edge_features_1.append([1.0 if edge_info1[i] == edge else 0.0 for edge in self.edge_type])\n",
        "            adj_row = []\n",
        "            for d in edges1:\n",
        "                if (i == d):\n",
        "                    adj_row.append(0.0)\n",
        "                    continue\n",
        "                if ((i[0] in d) | (i[1] in d)):\n",
        "                    adj_row.append(1.0)\n",
        "                else:\n",
        "                    adj_row.append(0.0)\n",
        "            edge_adj_1.append(adj_row)\n",
        "        for i in edges2:\n",
        "            edge_features_2.append([1.0 if edge_info2[i] == edge else 0.0 for edge in self.edge_type])\n",
        "            adj_row = []\n",
        "            for d in edges2:\n",
        "                if (i == d):\n",
        "                    adj_row.append(0.0)\n",
        "                    continue\n",
        "                if ((i[0] in d) | (i[1] in d)):\n",
        "                    adj_row.append(1.0)\n",
        "                else:\n",
        "                    adj_row.append(0.0)\n",
        "            edge_adj_2.append(adj_row)\n",
        "        edge_features_1, edge_features_2 = torch.FloatTensor(np.array(edge_features_1)), torch.FloatTensor(\n",
        "            np.array(edge_features_2))\n",
        "        edge_adj_1, edge_adj_2 = torch.FloatTensor(np.array(edge_adj_1)), torch.FloatTensor(np.array(edge_adj_2))\n",
        "\n",
        "        label_multiset[\"node_index_1\"], label_multiset[\"node_index_2\"] = nx.adjacency_matrix(\n",
        "            graph1), nx.adjacency_matrix(graph2)\n",
        "        label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"] = node_features_1, node_features_2\n",
        "        label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"] = edge_features_1, edge_features_2\n",
        "        label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"] = edge_adj_1, edge_adj_2\n",
        "\n",
        "        #ged normalisation\n",
        "        if (type_specified):  # for training\n",
        "            avg_node_number = 0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes())\n",
        "            norm_ged = [n / avg_node_number for n in ged]\n",
        "            norm_ged = np.array(norm_ged)\n",
        "            label_multiset[\"target\"] = torch.from_numpy(np.exp(-norm_ged)).view(1, -1).float()\n",
        "\n",
        "            norm_gt_ged = (len(ged)) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "        else:  # for testing\n",
        "            norm_gt_ged = (ged) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "\n",
        "        return label_multiset\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = 20\n",
        "tensor_neurons = 16\n",
        "bottle_neck_neurons = 16\n",
        "batch_size = 128\n",
        "dropout = 0.0\n",
        "lr = 0.001\n",
        "weight_decay = 0.0\n",
        "\n",
        "Node_Types = ['1']\n",
        "Edge_Types = ['1']\n",
        "#collection global node label and edge label info\n",
        "\n",
        "print(\"\\n-------Model training---------.\\n\")\n",
        "\n",
        "model = TaGSim(Node_Types, Edge_Types, tensor_neurons, bottle_neck_neurons)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "iteration = 0\n",
        "\n",
        "visual_loss_train = []\n",
        "test_scores = []\n",
        "visual_loss_test = []\n",
        "train_pair = []\n",
        "test_pair = []\n",
        "epo = []\n",
        "\n",
        "#model training\n",
        "for epoch in range(epochs):\n",
        "    random.shuffle(train_pairs)\n",
        "    batches = []\n",
        "    for graph in range(0, len(train_pairs), batch_size):\n",
        "        batches.append(train_pairs[graph:graph + batch_size])\n",
        "\n",
        "    for batch in batches:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        losses = 0\n",
        "        for graph_pair in batch:\n",
        "            data = model.transform_label_multiset(graph_pair)\n",
        "            prediction = model(data)\n",
        "            losses += torch.nn.functional.mse_loss(data[\"target\"], prediction)\n",
        "\n",
        "        losses.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        loss = losses.item()\n",
        "        print('Iteration', iteration, 'loss: ', loss / len(batch))\n",
        "        iteration += 1\n",
        "\n",
        "    visual_loss_train.append(loss / len(batch))\n",
        "    # testing\n",
        "    model.eval()\n",
        "    for n in test_pairs:\n",
        "        graph1 = n['graph_pair'][0]  #updated_test\n",
        "        graph2 = n['graph_pair'][1]  #updated_test\n",
        "        ged = int(n['gt_ged'])\n",
        "        tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "        data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "        prediction = model(data)\n",
        "        prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "        current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "        test_scores.append(current_error.data.item())\n",
        "    visual_loss_test.append(sum(test_scores) / len(test_scores))\n",
        "    epo.append(epoch + 1)\n",
        "\n",
        "#visualization of traning and testing loss\n",
        "plt.plot(epo, visual_loss_train, 'g', label='Training Loss')\n",
        "plt.plot(epo, visual_loss_test, 'b', label='Validation Loss')\n",
        "plt.title('Evaluation of TaGSim Model with MEAN Graph Pooling layer (' + DATASET + ')')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n-------Model testing---------.\\n\")\n",
        "\n",
        "model.eval()\n",
        "test_scores = []\n",
        "for n in test_pairs:\n",
        "    graph1 = n['graph_pair'][0]  #updated_test\n",
        "    graph2 = n['graph_pair'][1]  #updated_test\n",
        "    ged = int(n['gt_ged'])\n",
        "    tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "    data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "    prediction = model(data)\n",
        "    prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "    current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "    test_scores.append(current_error.data.item())\n",
        "\n",
        "model_error = sum(test_scores) / len(test_scores)\n",
        "print(\"\\nModel test error: \" + str(model_error))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bS_fzz0aCWlh",
        "outputId": "f0515479-1c42-44f2-b212-1a242609edd5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model training---------.\n",
            "\n",
            "Iteration 0 loss:  0.08737308531999588\n",
            "Iteration 1 loss:  0.09081749618053436\n",
            "Iteration 2 loss:  0.09232860058546066\n",
            "Iteration 3 loss:  0.08736100792884827\n",
            "Iteration 4 loss:  0.08781496435403824\n",
            "Iteration 5 loss:  0.08036080002784729\n",
            "Iteration 6 loss:  0.07977058738470078\n",
            "Iteration 7 loss:  0.08350809663534164\n",
            "Iteration 8 loss:  0.07642660290002823\n",
            "Iteration 9 loss:  0.08531613151232402\n",
            "Iteration 10 loss:  0.08349568396806717\n",
            "Iteration 11 loss:  0.08439429104328156\n",
            "Iteration 12 loss:  0.07973678410053253\n",
            "Iteration 13 loss:  0.0807994157075882\n",
            "Iteration 14 loss:  0.08391135931015015\n",
            "Iteration 15 loss:  0.07890495657920837\n",
            "Iteration 16 loss:  0.08623793721199036\n",
            "Iteration 17 loss:  0.0723639652132988\n",
            "Iteration 18 loss:  0.08032073825597763\n",
            "Iteration 19 loss:  0.07849603394667308\n",
            "Iteration 20 loss:  0.06641340255737305\n",
            "Iteration 21 loss:  0.07298247516155243\n",
            "Iteration 22 loss:  0.07719767093658447\n",
            "Iteration 23 loss:  0.06988810002803802\n",
            "Iteration 24 loss:  0.08273816108703613\n",
            "Iteration 25 loss:  0.07559877634048462\n",
            "Iteration 26 loss:  0.08354633301496506\n",
            "Iteration 27 loss:  0.08191591501235962\n",
            "Iteration 28 loss:  0.08365015685558319\n",
            "Iteration 29 loss:  0.09068345030148824\n",
            "Iteration 30 loss:  0.07864271104335785\n",
            "Iteration 31 loss:  0.07559890300035477\n",
            "Iteration 32 loss:  0.076530322432518\n",
            "Iteration 33 loss:  0.07616264373064041\n",
            "Iteration 34 loss:  0.07378554344177246\n",
            "Iteration 35 loss:  0.0740659236907959\n",
            "Iteration 36 loss:  0.07016488164663315\n",
            "Iteration 37 loss:  0.0753876343369484\n",
            "Iteration 38 loss:  0.07296235114336014\n",
            "Iteration 39 loss:  0.06773444016774495\n",
            "Iteration 40 loss:  0.07172183692455292\n",
            "Iteration 41 loss:  0.06870075315237045\n",
            "Iteration 42 loss:  0.07425032556056976\n",
            "Iteration 43 loss:  0.06868476420640945\n",
            "Iteration 44 loss:  0.07358796894550323\n",
            "Iteration 45 loss:  0.06826584041118622\n",
            "Iteration 46 loss:  0.06944344937801361\n",
            "Iteration 47 loss:  0.07680497318506241\n",
            "Iteration 48 loss:  0.06771249324083328\n",
            "Iteration 49 loss:  0.0728386143843333\n",
            "Iteration 50 loss:  0.06640633940696716\n",
            "Iteration 51 loss:  0.06622716784477234\n",
            "Iteration 52 loss:  0.0768769308924675\n",
            "Iteration 53 loss:  0.06358228623867035\n",
            "Iteration 54 loss:  0.07397967576980591\n",
            "Iteration 55 loss:  0.06751322746276855\n",
            "Iteration 56 loss:  0.06006257236003876\n",
            "Iteration 57 loss:  0.06543422490358353\n",
            "Iteration 58 loss:  0.062155887484550476\n",
            "Iteration 59 loss:  0.06947635610898335\n",
            "Iteration 60 loss:  0.060937006026506424\n",
            "Iteration 61 loss:  0.059682440012693405\n",
            "Iteration 62 loss:  0.06958980858325958\n",
            "Iteration 63 loss:  0.06457735598087311\n",
            "Iteration 64 loss:  0.06282876431941986\n",
            "Iteration 65 loss:  0.05450814962387085\n",
            "Iteration 66 loss:  0.06672190874814987\n",
            "Iteration 67 loss:  0.059786297380924225\n",
            "Iteration 68 loss:  0.06219811737537384\n",
            "Iteration 69 loss:  0.059917330741882324\n",
            "Iteration 70 loss:  0.06175067648291588\n",
            "Iteration 71 loss:  0.06124581769108772\n",
            "Iteration 72 loss:  0.06417100131511688\n",
            "Iteration 73 loss:  0.058221179991960526\n",
            "Iteration 74 loss:  0.05954798310995102\n",
            "Iteration 75 loss:  0.049839019775390625\n",
            "Iteration 76 loss:  0.05221552774310112\n",
            "Iteration 77 loss:  0.054868295788764954\n",
            "Iteration 78 loss:  0.052537865936756134\n",
            "Iteration 79 loss:  0.04841144879659017\n",
            "Iteration 80 loss:  0.05547727644443512\n",
            "Iteration 81 loss:  0.054345618933439255\n",
            "Iteration 82 loss:  0.05183957889676094\n",
            "Iteration 83 loss:  0.051905110478401184\n",
            "Iteration 84 loss:  0.050103992223739624\n",
            "Iteration 85 loss:  0.04915843531489372\n",
            "Iteration 86 loss:  0.047573719173669815\n",
            "Iteration 87 loss:  0.055143170058727264\n",
            "Iteration 88 loss:  0.04530639573931694\n",
            "Iteration 89 loss:  0.04296480119228363\n",
            "Iteration 90 loss:  0.04712310805916786\n",
            "Iteration 91 loss:  0.04487428069114685\n",
            "Iteration 92 loss:  0.05163215100765228\n",
            "Iteration 93 loss:  0.04176962003111839\n",
            "Iteration 94 loss:  0.04363019019365311\n",
            "Iteration 95 loss:  0.046941932290792465\n",
            "Iteration 96 loss:  0.04304151237010956\n",
            "Iteration 97 loss:  0.04386778548359871\n",
            "Iteration 98 loss:  0.04292209446430206\n",
            "Iteration 99 loss:  0.03865636885166168\n",
            "Iteration 100 loss:  0.040489256381988525\n",
            "Iteration 101 loss:  0.04302910715341568\n",
            "Iteration 102 loss:  0.04293510690331459\n",
            "Iteration 103 loss:  0.0388476736843586\n",
            "Iteration 104 loss:  0.041132524609565735\n",
            "Iteration 105 loss:  0.03647218272089958\n",
            "Iteration 106 loss:  0.036395952105522156\n",
            "Iteration 107 loss:  0.039123233407735825\n",
            "Iteration 108 loss:  0.03704981505870819\n",
            "Iteration 109 loss:  0.03440871834754944\n",
            "Iteration 110 loss:  0.03521103411912918\n",
            "Iteration 111 loss:  0.03821444511413574\n",
            "Iteration 112 loss:  0.03516615182161331\n",
            "Iteration 113 loss:  0.0368940569460392\n",
            "Iteration 114 loss:  0.034069549292325974\n",
            "Iteration 115 loss:  0.03550460562109947\n",
            "Iteration 116 loss:  0.03364523872733116\n",
            "Iteration 117 loss:  0.030177000910043716\n",
            "Iteration 118 loss:  0.035343095660209656\n",
            "Iteration 119 loss:  0.03180860231320063\n",
            "Iteration 120 loss:  0.029779547825455666\n",
            "Iteration 121 loss:  0.03458387032151222\n",
            "Iteration 122 loss:  0.03466656804084778\n",
            "Iteration 123 loss:  0.03474966436624527\n",
            "Iteration 124 loss:  0.03209337592124939\n",
            "Iteration 125 loss:  0.028214601799845695\n",
            "Iteration 126 loss:  0.031007438898086548\n",
            "Iteration 127 loss:  0.030049830675125122\n",
            "Iteration 128 loss:  0.031109048053622246\n",
            "Iteration 129 loss:  0.031038085619608562\n",
            "Iteration 130 loss:  0.028801625594496727\n",
            "Iteration 131 loss:  0.029927341267466545\n",
            "Iteration 132 loss:  0.03057936765253544\n",
            "Iteration 133 loss:  0.030955955386161804\n",
            "Iteration 134 loss:  0.02875572070479393\n",
            "Iteration 135 loss:  0.029667291790246964\n",
            "Iteration 136 loss:  0.03239693492650986\n",
            "Iteration 137 loss:  0.032462380826473236\n",
            "Iteration 138 loss:  0.03025640733540058\n",
            "Iteration 139 loss:  0.02769295871257782\n",
            "Iteration 140 loss:  0.028895901516079903\n",
            "Iteration 141 loss:  0.029048895463347435\n",
            "Iteration 142 loss:  0.027510840445756912\n",
            "Iteration 143 loss:  0.028883805498480797\n",
            "Iteration 144 loss:  0.028211692348122597\n",
            "Iteration 145 loss:  0.03019600920379162\n",
            "Iteration 146 loss:  0.03209388256072998\n",
            "Iteration 147 loss:  0.0303858183324337\n",
            "Iteration 148 loss:  0.0340789332985878\n",
            "Iteration 149 loss:  0.027094513177871704\n",
            "Iteration 150 loss:  0.02847808413207531\n",
            "Iteration 151 loss:  0.029749717563390732\n",
            "Iteration 152 loss:  0.030452877283096313\n",
            "Iteration 153 loss:  0.02979358844459057\n",
            "Iteration 154 loss:  0.02948709763586521\n",
            "Iteration 155 loss:  0.02914644591510296\n",
            "Iteration 156 loss:  0.02830006554722786\n",
            "Iteration 157 loss:  0.03241962194442749\n",
            "Iteration 158 loss:  0.027701804414391518\n",
            "Iteration 159 loss:  0.03463430951038996\n",
            "Iteration 160 loss:  0.028440415859222412\n",
            "Iteration 161 loss:  0.028238696977496147\n",
            "Iteration 162 loss:  0.03430867940187454\n",
            "Iteration 163 loss:  0.032055553048849106\n",
            "Iteration 164 loss:  0.03265108913183212\n",
            "Iteration 165 loss:  0.029911775141954422\n",
            "Iteration 166 loss:  0.02642080746591091\n",
            "Iteration 167 loss:  0.027646953240036964\n",
            "Iteration 168 loss:  0.027672821655869484\n",
            "Iteration 169 loss:  0.026098497211933136\n",
            "Iteration 170 loss:  0.030472896993160248\n",
            "Iteration 171 loss:  0.02965852990746498\n",
            "Iteration 172 loss:  0.030948137864470482\n",
            "Iteration 173 loss:  0.02518504112958908\n",
            "Iteration 174 loss:  0.031444549560546875\n",
            "Iteration 175 loss:  0.028489472344517708\n",
            "Iteration 176 loss:  0.026965348049998283\n",
            "Iteration 177 loss:  0.03098372556269169\n",
            "Iteration 178 loss:  0.029903072863817215\n",
            "Iteration 179 loss:  0.031524633367856346\n",
            "Iteration 180 loss:  0.02862132340669632\n",
            "Iteration 181 loss:  0.030756160616874695\n",
            "Iteration 182 loss:  0.028354713693261147\n",
            "Iteration 183 loss:  0.030900539830327034\n",
            "Iteration 184 loss:  0.028856076300144196\n",
            "Iteration 185 loss:  0.030531123280525208\n",
            "Iteration 186 loss:  0.028302423655986786\n",
            "Iteration 187 loss:  0.029294611886143684\n",
            "Iteration 188 loss:  0.029075484722852707\n",
            "Iteration 189 loss:  0.02705397456884384\n",
            "Iteration 190 loss:  0.027334753423929214\n",
            "Iteration 191 loss:  0.027302978560328484\n",
            "Iteration 192 loss:  0.029787514358758926\n",
            "Iteration 193 loss:  0.029330942779779434\n",
            "Iteration 194 loss:  0.028313616290688515\n",
            "Iteration 195 loss:  0.030154908075928688\n",
            "Iteration 196 loss:  0.02991674467921257\n",
            "Iteration 197 loss:  0.030419671908020973\n",
            "Iteration 198 loss:  0.029871707782149315\n",
            "Iteration 199 loss:  0.029743221898873646\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model testing---------.\n",
            "\n",
            "\n",
            "Model test error: 0.12760207045517746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SUM Pooling"
      ],
      "metadata": {
        "id": "kdZAx8ruCqx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class TensorNetworkModule(torch.nn.Module):\n",
        "    def __init__(self, tensor_neurons, input_dim):\n",
        "        super(TensorNetworkModule, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.setup_weights()\n",
        "        self.init_parameters()\n",
        "\n",
        "    def setup_weights(self):\n",
        "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.input_dim, self.input_dim, self.tensor_neurons))\n",
        "        self.weight_matrix_block = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 2 * self.input_dim))\n",
        "        self.bias = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 1))\n",
        "\n",
        "    def init_parameters(self):\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix_block)\n",
        "        torch.nn.init.xavier_uniform_(self.bias)\n",
        "\n",
        "    def forward(self, embedding_1, embedding_2):\n",
        "        scoring = torch.mm(torch.t(embedding_1), self.weight_matrix.view(self.input_dim, -1))\n",
        "        scoring = scoring.view(self.input_dim, self.tensor_neurons)\n",
        "        scoring = torch.mm(torch.t(scoring), embedding_2)\n",
        "        combined_representation = torch.cat((embedding_1, embedding_2))\n",
        "        block_scoring = torch.mm(self.weight_matrix_block, combined_representation)\n",
        "        scores = torch.nn.functional.relu(scoring + block_scoring + self.bias)\n",
        "        return scores\n",
        "\n",
        "\n",
        "def graph_aggregation_layer(input, adj):\n",
        "    result = torch.mm(adj, input)\n",
        "    return result\n",
        "\n",
        "\n",
        "class TaGSim(torch.nn.Module):\n",
        "    def __init__(self, number_of_node_labels, number_of_edge_labels, tensor_neurons, bottle_neck_neurons):\n",
        "        super(TaGSim, self).__init__()\n",
        "        self.number_of_node_labels = len(number_of_node_labels)\n",
        "        self.number_of_edge_labels = len(number_of_edge_labels)\n",
        "        self.node_type = number_of_node_labels\n",
        "        self.edge_type = number_of_edge_labels\n",
        "        self.tensor_neurons = tensor_neurons\n",
        "        self.bottle_neck_neurons = bottle_neck_neurons\n",
        "        self.setup_layers()\n",
        "\n",
        "    def setup_layers(self):\n",
        "        self.feature_count = self.tensor_neurons\n",
        "\n",
        "        # self.tensor_network_nc = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_in = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        # self.tensor_network_ie = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
        "        self.tensor_network_ec = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_edge_labels)\n",
        "\n",
        "        # self.fully_connected_first_nc = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_nc = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_nc = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_nc = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_in = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_in = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_in = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_in = torch.nn.Linear(4, 1)\n",
        "\n",
        "        # self.fully_connected_first_ie = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        # self.fully_connected_second_ie = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        # self.fully_connected_third_ie = torch.nn.Linear(8, 4)\n",
        "        # self.scoring_layer_ie = torch.nn.Linear(4, 1)\n",
        "\n",
        "        self.fully_connected_first_ec = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
        "        self.fully_connected_second_ec = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
        "        self.fully_connected_third_ec = torch.nn.Linear(8, 4)\n",
        "        self.scoring_layer_ec = torch.nn.Linear(4, 1)\n",
        "\n",
        "    def gal_pass(self, edge_index, features):\n",
        "        hidden1 = graph_aggregation_layer(features, edge_index)\n",
        "        hidden2 = graph_aggregation_layer(hidden1, edge_index)\n",
        "\n",
        "        return hidden1, hidden2\n",
        "\n",
        "    def forward(self, label_multiset):\n",
        "        adj_1, adj_2 = torch.FloatTensor(np.array(label_multiset[\"node_index_1\"].todense())), torch.FloatTensor(\n",
        "            np.array(label_multiset[\"node_index_2\"].todense()))\n",
        "        edge_adj_1, edge_adj_2 = label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"]\n",
        "        node_features_1, node_features_2 = label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"]\n",
        "        edge_features_1, edge_features_2 = label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"]\n",
        "\n",
        "        #gal\n",
        "        graph1_hidden1, graph1_hidden2 = self.gal_pass(adj_1, node_features_1)  #original graph node\n",
        "        graph2_hidden1, graph2_hidden2 = self.gal_pass(adj_2, node_features_2)  #generated graph node\n",
        "        edge1_hidden1, edge1_hidden2 = self.gal_pass(edge_adj_1, edge_features_1)  #original edge node\n",
        "        edge2_hidden1, edge2_hidden2 = self.gal_pass(edge_adj_2, edge_features_2)  #generated graph edge\n",
        "        #node level embedding Concatenation\n",
        "        graph1_01concat = torch.cat([node_features_1, graph1_hidden1], dim=1)\n",
        "        graph2_01concat = torch.cat([node_features_2, graph2_hidden1], dim=1)\n",
        "        graph1_12concat = torch.cat([graph1_hidden1, graph1_hidden2], dim=1)\n",
        "        graph2_12concat = torch.cat([graph2_hidden1, graph2_hidden2], dim=1)\n",
        "        #graph pooling: node Sum\n",
        "        graph1_01pooled = torch.sum(graph1_01concat, dim=0).unsqueeze(1)\n",
        "        graph2_01pooled = torch.sum(graph2_01concat, dim=0).unsqueeze(1)\n",
        "        graph1_12pooled = torch.sum(graph1_12concat, dim=0).unsqueeze(1)\n",
        "        graph2_12pooled = torch.sum(graph2_12concat, dim=0).unsqueeze(1)\n",
        "        #edge level embedding Concatenation\n",
        "        edge1_01concat = torch.cat([edge_features_1, edge1_hidden1], dim=1)\n",
        "        edge2_01concat = torch.cat([edge_features_2, edge2_hidden1], dim=1)\n",
        "        #graph pooling: edge Sum\n",
        "        edge1_01pooled = torch.sum(edge1_01concat, dim=0).unsqueeze(1)\n",
        "        edge2_01pooled = torch.sum(edge2_01concat, dim=0).unsqueeze(1)\n",
        "\n",
        "        # scores_nc = self.tensor_network_nc(graph1_01pooled, graph2_01pooled)\n",
        "        # scores_nc = torch.t(scores_nc)\n",
        "        #\n",
        "        # scores_nc = torch.nn.functional.relu(self.fully_connected_first_nc(scores_nc))\n",
        "        # scores_nc = torch.nn.functional.relu(self.fully_connected_second_nc(scores_nc))\n",
        "        # scores_nc = torch.nn.functional.relu(self.fully_connected_third_nc(scores_nc))\n",
        "        # score_nc = torch.sigmoid(self.scoring_layer_nc(scores_nc))\n",
        "\n",
        "        scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
        "        scores_in = torch.t(scores_in)\n",
        "\n",
        "        scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
        "        scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
        "        scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
        "        score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
        "\n",
        "        # scores_ie = self.tensor_network_ie(graph1_12pooled, graph2_12pooled)\n",
        "        # scores_ie = torch.t(scores_ie)\n",
        "        #\n",
        "        # scores_ie = torch.nn.functional.relu(self.fully_connected_first_ie(scores_ie))\n",
        "        # scores_ie = torch.nn.functional.relu(self.fully_connected_second_ie(scores_ie))\n",
        "        # scores_ie = torch.nn.functional.relu(self.fully_connected_third_ie(scores_ie))\n",
        "        # score_ie = torch.sigmoid(self.scoring_layer_ie(scores_ie))\n",
        "\n",
        "        scores_ec = self.tensor_network_ec(edge1_01pooled, edge2_01pooled)\n",
        "        scores_ec = torch.t(scores_ec)\n",
        "\n",
        "        scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
        "        scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
        "        scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
        "        score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
        "\n",
        "        return torch.cat([ score_in,  score_ec], dim=1)\n",
        "\n",
        "    def transform_label_multiset(self, graph_pair, type_specified=True):\n",
        "        graph1 = graph_pair['graph_pair'][0]\n",
        "        graph2 = graph_pair['graph_pair'][1]\n",
        "        ged = graph_pair['ged']\n",
        "        #node and edge info of pair graph\n",
        "        node_info1 = nx.get_node_attributes(graph1, 'label')\n",
        "        node_info2 = nx.get_node_attributes(graph2, 'label')\n",
        "        edge_info1 = nx.get_edge_attributes(graph1, 'id')\n",
        "        edge_info2 = nx.get_edge_attributes(graph2, 'id')\n",
        "        nodes1 = list(graph1.nodes())\n",
        "        nodes2 = list(graph2.nodes())\n",
        "        edges1 = list(graph1.edges())\n",
        "        edges2 = list(graph2.edges())\n",
        "\n",
        "        label_multiset = dict()\n",
        "        node_features_1, node_features_2, edge_features_1, edge_features_2, edge_adj_1, edge_adj_2 = [], [], [], [], [], []\n",
        "\n",
        "        for i in graph1.nodes():\n",
        "            node_features_1.append([1.0 if node_info1[i] == node else 0.0 for node in self.node_type])\n",
        "        for i in graph2.nodes():\n",
        "            node_features_2.append([1.0 if node_info2[i] == node else 0.0 for node in self.node_type])\n",
        "        node_features_1, node_features_2 = torch.FloatTensor(np.array(node_features_1)), torch.FloatTensor(\n",
        "            np.array(node_features_2))\n",
        "\n",
        "        for i in edges1:\n",
        "            edge_features_1.append([1.0 if edge_info1[i] == edge else 0.0 for edge in self.edge_type])\n",
        "            adj_row = []\n",
        "            for d in edges1:\n",
        "                if (i == d):\n",
        "                    adj_row.append(0.0)\n",
        "                    continue\n",
        "                if ((i[0] in d) | (i[1] in d)):\n",
        "                    adj_row.append(1.0)\n",
        "                else:\n",
        "                    adj_row.append(0.0)\n",
        "            edge_adj_1.append(adj_row)\n",
        "        for i in edges2:\n",
        "            edge_features_2.append([1.0 if edge_info2[i] == edge else 0.0 for edge in self.edge_type])\n",
        "            adj_row = []\n",
        "            for d in edges2:\n",
        "                if (i == d):\n",
        "                    adj_row.append(0.0)\n",
        "                    continue\n",
        "                if ((i[0] in d) | (i[1] in d)):\n",
        "                    adj_row.append(1.0)\n",
        "                else:\n",
        "                    adj_row.append(0.0)\n",
        "            edge_adj_2.append(adj_row)\n",
        "        edge_features_1, edge_features_2 = torch.FloatTensor(np.array(edge_features_1)), torch.FloatTensor(\n",
        "            np.array(edge_features_2))\n",
        "        edge_adj_1, edge_adj_2 = torch.FloatTensor(np.array(edge_adj_1)), torch.FloatTensor(np.array(edge_adj_2))\n",
        "\n",
        "        label_multiset[\"node_index_1\"], label_multiset[\"node_index_2\"] = nx.adjacency_matrix(\n",
        "            graph1), nx.adjacency_matrix(graph2)\n",
        "        label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"] = node_features_1, node_features_2\n",
        "        label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"] = edge_features_1, edge_features_2\n",
        "        label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"] = edge_adj_1, edge_adj_2\n",
        "\n",
        "        #ged normalisation\n",
        "        if (type_specified):  # for training\n",
        "            avg_node_number = 0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes())\n",
        "            norm_ged = [n / avg_node_number for n in ged]\n",
        "            norm_ged = np.array(norm_ged)\n",
        "            label_multiset[\"target\"] = torch.from_numpy(np.exp(-norm_ged)).view(1, -1).float()\n",
        "\n",
        "            norm_gt_ged = (len(ged)) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "        else:  # for testing\n",
        "            norm_gt_ged = (ged) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
        "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
        "\n",
        "        return label_multiset\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = 20\n",
        "tensor_neurons = 16\n",
        "bottle_neck_neurons = 16\n",
        "batch_size = 128\n",
        "dropout = 0.0\n",
        "lr = 0.001\n",
        "weight_decay = 0.0\n",
        "\n",
        "Node_Types = ['1']\n",
        "Edge_Types = ['1']\n",
        "#collection global node label and edge label info\n",
        "\n",
        "print(\"\\n-------Model training---------.\\n\")\n",
        "\n",
        "model = TaGSim(Node_Types, Edge_Types, tensor_neurons, bottle_neck_neurons)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "iteration = 0\n",
        "\n",
        "visual_loss_train = []\n",
        "test_scores = []\n",
        "visual_loss_test = []\n",
        "train_pair = []\n",
        "test_pair = []\n",
        "epo = []\n",
        "\n",
        "#model training\n",
        "for epoch in range(epochs):\n",
        "    random.shuffle(train_pairs)\n",
        "    batches = []\n",
        "    for graph in range(0, len(train_pairs), batch_size):\n",
        "        batches.append(train_pairs[graph:graph + batch_size])\n",
        "\n",
        "    for batch in batches:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        losses = 0\n",
        "        for graph_pair in batch:\n",
        "            data = model.transform_label_multiset(graph_pair)\n",
        "            prediction = model(data)\n",
        "            losses += torch.nn.functional.mse_loss(data[\"target\"], prediction)\n",
        "\n",
        "        losses.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        loss = losses.item()\n",
        "        print('Iteration', iteration, 'loss: ', loss / len(batch))\n",
        "        iteration += 1\n",
        "\n",
        "    visual_loss_train.append(loss / len(batch))\n",
        "    # testing\n",
        "    model.eval()\n",
        "    for n in test_pairs:\n",
        "        graph1 = n['graph_pair'][0]  #updated_test\n",
        "        graph2 = n['graph_pair'][1]  #updated_test\n",
        "        ged = int(n['gt_ged'])\n",
        "        tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "        data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "        prediction = model(data)\n",
        "        prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "        current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "        test_scores.append(current_error.data.item())\n",
        "    visual_loss_test.append(sum(test_scores) / len(test_scores))\n",
        "    epo.append(epoch + 1)\n",
        "\n",
        "#visualization of traning and testing loss\n",
        "plt.plot(epo, visual_loss_train, 'g', label='Training Loss')\n",
        "plt.plot(epo, visual_loss_test, 'b', label='Validation Loss')\n",
        "plt.title('Evaluation of TaGSim Model with SUM Graph Pooling layer (' + DATASET + ')')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n-------Model testing---------.\\n\")\n",
        "\n",
        "model.eval()\n",
        "test_scores = []\n",
        "for n in test_pairs:\n",
        "    graph1 = n['graph_pair'][0]  #updated_test\n",
        "    graph2 = n['graph_pair'][1]  #updated_test\n",
        "    ged = int(n['gt_ged'])\n",
        "    tem_data = {\"graph_pair\": [graph1, graph2], \"ged\": ged}\n",
        "    data = model.transform_label_multiset(tem_data, type_specified=False)\n",
        "    prediction = model(data)\n",
        "    prediction = torch.exp(torch.sum(torch.log(prediction))).view(1, -1)\n",
        "    current_error = torch.nn.functional.mse_loss(prediction, data[\"gt_ged\"])\n",
        "    test_scores.append(current_error.data.item())\n",
        "\n",
        "model_error = sum(test_scores) / len(test_scores)\n",
        "print(\"\\nModel test error: \" + str(model_error))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dJq9glo1CWUH",
        "outputId": "94024c72-e19e-47b0-ccb2-55756fc671f0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model training---------.\n",
            "\n",
            "Iteration 0 loss:  0.09324866533279419\n",
            "Iteration 1 loss:  0.10059898346662521\n",
            "Iteration 2 loss:  0.05952055752277374\n",
            "Iteration 3 loss:  0.049609966576099396\n",
            "Iteration 4 loss:  0.04333518072962761\n",
            "Iteration 5 loss:  0.043746888637542725\n",
            "Iteration 6 loss:  0.03624604642391205\n",
            "Iteration 7 loss:  0.03472323343157768\n",
            "Iteration 8 loss:  0.0325297974050045\n",
            "Iteration 9 loss:  0.029561405380566914\n",
            "Iteration 10 loss:  0.035171616822481155\n",
            "Iteration 11 loss:  0.03098398819565773\n",
            "Iteration 12 loss:  0.028678901493549347\n",
            "Iteration 13 loss:  0.03555115684866905\n",
            "Iteration 14 loss:  0.031149905174970627\n",
            "Iteration 15 loss:  0.030152563005685806\n",
            "Iteration 16 loss:  0.029949383810162544\n",
            "Iteration 17 loss:  0.030836505815386772\n",
            "Iteration 18 loss:  0.0245953481644392\n",
            "Iteration 19 loss:  0.03387939433256785\n",
            "Iteration 20 loss:  0.02862081490457058\n",
            "Iteration 21 loss:  0.024751415476202965\n",
            "Iteration 22 loss:  0.03278009593486786\n",
            "Iteration 23 loss:  0.026215756312012672\n",
            "Iteration 24 loss:  0.02808256261050701\n",
            "Iteration 25 loss:  0.03400551900267601\n",
            "Iteration 26 loss:  0.027639493346214294\n",
            "Iteration 27 loss:  0.03253386169672012\n",
            "Iteration 28 loss:  0.03037184663116932\n",
            "Iteration 29 loss:  0.03161028027534485\n",
            "Iteration 30 loss:  0.02877877466380596\n",
            "Iteration 31 loss:  0.030216820538043976\n",
            "Iteration 32 loss:  0.02566404454410076\n",
            "Iteration 33 loss:  0.032571837306022644\n",
            "Iteration 34 loss:  0.028482263907790184\n",
            "Iteration 35 loss:  0.026608005166053772\n",
            "Iteration 36 loss:  0.027463754639029503\n",
            "Iteration 37 loss:  0.03334314376115799\n",
            "Iteration 38 loss:  0.027647025883197784\n",
            "Iteration 39 loss:  0.031488065918286644\n",
            "Iteration 40 loss:  0.03203630819916725\n",
            "Iteration 41 loss:  0.026425708085298538\n",
            "Iteration 42 loss:  0.027400828897953033\n",
            "Iteration 43 loss:  0.026054080575704575\n",
            "Iteration 44 loss:  0.030118774622678757\n",
            "Iteration 45 loss:  0.0312262624502182\n",
            "Iteration 46 loss:  0.029188571497797966\n",
            "Iteration 47 loss:  0.028877759352326393\n",
            "Iteration 48 loss:  0.02757979743182659\n",
            "Iteration 49 loss:  0.026270173490047455\n",
            "Iteration 50 loss:  0.02937953546643257\n",
            "Iteration 51 loss:  0.02788420394062996\n",
            "Iteration 52 loss:  0.02523888647556305\n",
            "Iteration 53 loss:  0.029923586174845695\n",
            "Iteration 54 loss:  0.02718293108046055\n",
            "Iteration 55 loss:  0.029088806360960007\n",
            "Iteration 56 loss:  0.024029096588492393\n",
            "Iteration 57 loss:  0.030973026528954506\n",
            "Iteration 58 loss:  0.028396261855959892\n",
            "Iteration 59 loss:  0.03531104822953542\n",
            "Iteration 60 loss:  0.029386311769485474\n",
            "Iteration 61 loss:  0.02525494247674942\n",
            "Iteration 62 loss:  0.030886797234416008\n",
            "Iteration 63 loss:  0.02670096978545189\n",
            "Iteration 64 loss:  0.028397342190146446\n",
            "Iteration 65 loss:  0.025669781491160393\n",
            "Iteration 66 loss:  0.032101958990097046\n",
            "Iteration 67 loss:  0.029211031273007393\n",
            "Iteration 68 loss:  0.02603679709136486\n",
            "Iteration 69 loss:  0.02664826810359955\n",
            "Iteration 70 loss:  0.027426183223724365\n",
            "Iteration 71 loss:  0.026064513251185417\n",
            "Iteration 72 loss:  0.03014357201755047\n",
            "Iteration 73 loss:  0.027629617601633072\n",
            "Iteration 74 loss:  0.02902263030409813\n",
            "Iteration 75 loss:  0.024750206619501114\n",
            "Iteration 76 loss:  0.02916133776307106\n",
            "Iteration 77 loss:  0.027471499517560005\n",
            "Iteration 78 loss:  0.02769164741039276\n",
            "Iteration 79 loss:  0.03267489125331243\n",
            "Iteration 80 loss:  0.02831146866083145\n",
            "Iteration 81 loss:  0.02316705696284771\n",
            "Iteration 82 loss:  0.027619482949376106\n",
            "Iteration 83 loss:  0.02658133953809738\n",
            "Iteration 84 loss:  0.029457518830895424\n",
            "Iteration 85 loss:  0.02868705242872238\n",
            "Iteration 86 loss:  0.026941383257508278\n",
            "Iteration 87 loss:  0.031644102185964584\n",
            "Iteration 88 loss:  0.026462547481060028\n",
            "Iteration 89 loss:  0.027806227405865986\n",
            "Iteration 90 loss:  0.02647038735449314\n",
            "Iteration 91 loss:  0.025946684181690216\n",
            "Iteration 92 loss:  0.027997886762022972\n",
            "Iteration 93 loss:  0.027537751942873\n",
            "Iteration 94 loss:  0.0262331310659647\n",
            "Iteration 95 loss:  0.027223465964198112\n",
            "Iteration 96 loss:  0.03174692392349243\n",
            "Iteration 97 loss:  0.028103604912757874\n",
            "Iteration 98 loss:  0.026868076995015144\n",
            "Iteration 99 loss:  0.023124322295188904\n",
            "Iteration 100 loss:  0.03106152079999447\n",
            "Iteration 101 loss:  0.02848813682794571\n",
            "Iteration 102 loss:  0.029581669718027115\n",
            "Iteration 103 loss:  0.02899809181690216\n",
            "Iteration 104 loss:  0.026106735691428185\n",
            "Iteration 105 loss:  0.02548300474882126\n",
            "Iteration 106 loss:  0.028085943311452866\n",
            "Iteration 107 loss:  0.02419852837920189\n",
            "Iteration 108 loss:  0.023826364427804947\n",
            "Iteration 109 loss:  0.02262139568726222\n",
            "Iteration 110 loss:  0.02715357206761837\n",
            "Iteration 111 loss:  0.026354843750596046\n",
            "Iteration 112 loss:  0.02644176222383976\n",
            "Iteration 113 loss:  0.024475613608956337\n",
            "Iteration 114 loss:  0.027597714215517044\n",
            "Iteration 115 loss:  0.02959703654050827\n",
            "Iteration 116 loss:  0.025028400123119354\n",
            "Iteration 117 loss:  0.028928039595484734\n",
            "Iteration 118 loss:  0.02826336771249771\n",
            "Iteration 119 loss:  0.021271852155526478\n",
            "Iteration 120 loss:  0.028288275003433228\n",
            "Iteration 121 loss:  0.025441013276576996\n",
            "Iteration 122 loss:  0.028787124902009964\n",
            "Iteration 123 loss:  0.02405416965484619\n",
            "Iteration 124 loss:  0.03040573000907898\n",
            "Iteration 125 loss:  0.027307365089654922\n",
            "Iteration 126 loss:  0.024354252964258194\n",
            "Iteration 127 loss:  0.025988604873418808\n",
            "Iteration 128 loss:  0.025632675737142563\n",
            "Iteration 129 loss:  0.02229279528061549\n",
            "Iteration 130 loss:  0.029566267505288124\n",
            "Iteration 131 loss:  0.022823208943009377\n",
            "Iteration 132 loss:  0.027232898399233818\n",
            "Iteration 133 loss:  0.024517375975847244\n",
            "Iteration 134 loss:  0.026252716779708862\n",
            "Iteration 135 loss:  0.026549579575657845\n",
            "Iteration 136 loss:  0.023885197937488556\n",
            "Iteration 137 loss:  0.02414594404399395\n",
            "Iteration 138 loss:  0.03131013736128807\n",
            "Iteration 139 loss:  0.0250301460425059\n",
            "Iteration 140 loss:  0.027441218495368958\n",
            "Iteration 141 loss:  0.025078199803829193\n",
            "Iteration 142 loss:  0.026336411014199257\n",
            "Iteration 143 loss:  0.025294223800301552\n",
            "Iteration 144 loss:  0.025202998891472816\n",
            "Iteration 145 loss:  0.024782584980130196\n",
            "Iteration 146 loss:  0.026155659928917885\n",
            "Iteration 147 loss:  0.02930058166384697\n",
            "Iteration 148 loss:  0.02481728233397007\n",
            "Iteration 149 loss:  0.023295643428961437\n",
            "Iteration 150 loss:  0.024998052045702934\n",
            "Iteration 151 loss:  0.025366224348545074\n",
            "Iteration 152 loss:  0.02574261836707592\n",
            "Iteration 153 loss:  0.025764955207705498\n",
            "Iteration 154 loss:  0.02548391930758953\n",
            "Iteration 155 loss:  0.025652335956692696\n",
            "Iteration 156 loss:  0.02729032188653946\n",
            "Iteration 157 loss:  0.02659866213798523\n",
            "Iteration 158 loss:  0.02605026215314865\n",
            "Iteration 159 loss:  0.027132754524548847\n",
            "Iteration 160 loss:  0.029934750869870186\n",
            "Iteration 161 loss:  0.02723724953830242\n",
            "Iteration 162 loss:  0.026953238993883133\n",
            "Iteration 163 loss:  0.023261381313204765\n",
            "Iteration 164 loss:  0.02231854759156704\n",
            "Iteration 165 loss:  0.024574285373091698\n",
            "Iteration 166 loss:  0.02567112445831299\n",
            "Iteration 167 loss:  0.02678319625556469\n",
            "Iteration 168 loss:  0.025811342522501945\n",
            "Iteration 169 loss:  0.031191920240720112\n",
            "Iteration 170 loss:  0.031495239585638046\n",
            "Iteration 171 loss:  0.026565710082650185\n",
            "Iteration 172 loss:  0.027184568345546722\n",
            "Iteration 173 loss:  0.024279996752738953\n",
            "Iteration 174 loss:  0.02479793317615986\n",
            "Iteration 175 loss:  0.027229251340031624\n",
            "Iteration 176 loss:  0.02164941467344761\n",
            "Iteration 177 loss:  0.025578264147043228\n",
            "Iteration 178 loss:  0.027281444519758224\n",
            "Iteration 179 loss:  0.020144267628590267\n",
            "Iteration 180 loss:  0.024369802325963974\n",
            "Iteration 181 loss:  0.026241431012749672\n",
            "Iteration 182 loss:  0.028460349887609482\n",
            "Iteration 183 loss:  0.026792556047439575\n",
            "Iteration 184 loss:  0.02538839355111122\n",
            "Iteration 185 loss:  0.02545304037630558\n",
            "Iteration 186 loss:  0.02469152770936489\n",
            "Iteration 187 loss:  0.025542810559272766\n",
            "Iteration 188 loss:  0.02502613514661789\n",
            "Iteration 189 loss:  0.027414128184318542\n",
            "Iteration 190 loss:  0.02510223723948002\n",
            "Iteration 191 loss:  0.025015585124492645\n",
            "Iteration 192 loss:  0.026524368673563004\n",
            "Iteration 193 loss:  0.027241306379437447\n",
            "Iteration 194 loss:  0.02903476357460022\n",
            "Iteration 195 loss:  0.028382251039147377\n",
            "Iteration 196 loss:  0.026937181130051613\n",
            "Iteration 197 loss:  0.0255495086312294\n",
            "Iteration 198 loss:  0.020998237654566765\n",
            "Iteration 199 loss:  0.01793361579378446\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------Model testing---------.\n",
            "\n",
            "\n",
            "Model test error: 0.1152071249075622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7GinYFvaCWIE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}