{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6277cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "import os\n",
    "import random\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import pylab\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8175b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirName = os.getcwd()+'\\\\train'\n",
    "filenames = os.listdir(dirName)\n",
    "Node_Types = []\n",
    "Edge_Types = []\n",
    "for filename in filenames:\n",
    "    if filename.endswith(\".gexf\"):\n",
    "        #print(filename)\n",
    "        temp =  nx.read_gexf(path=dirName+\"\\\\\"+filename)\n",
    "        for node in temp.nodes:\n",
    "            temp_type = temp.nodes[node]['type']\n",
    "            if temp_type not in Node_Types:\n",
    "                Node_Types.append(temp_type)\n",
    "        for edge in temp.edges:\n",
    "            temp_type = temp.edges[edge]['valence']\n",
    "            if temp_type not in Edge_Types:\n",
    "                Edge_Types.append(temp_type)\n",
    "\n",
    "print(Node_Types)\n",
    "print(Edge_Types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c6a354",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_set = []\n",
    "for i in range(0,len(Node_Types)):\n",
    "    r = lambda: random.randint(0,255)\n",
    "    color_set.append('#{:02x}{:02x}{:02x}'.format(r(), r(), r()))\n",
    "\n",
    "def draw_type(g):\n",
    "#    node_color_lst = []\n",
    "#    node_type_lst =  []\n",
    "#    for node in list(g.nodes()):\n",
    "#        temp = g.node[node]['type']\n",
    "#        if temp not in node_type_lst:\n",
    "#            index = Node_Types.index(temp)\n",
    "#            node_color_lst.append(color_set[index])\n",
    "#            node_type_lst.append(temp)\n",
    "\n",
    "    pos = nx.spring_layout(g)\n",
    "    edge_labels = dict([((n1, n2), d['valence']) for n1, n2, d in g.edges(data=True)])\n",
    "    node_labels = nx.get_node_attributes(g, 'type')\n",
    "    print(edge_labels)\n",
    "    print(node_labels)\n",
    "    #nx.draw(g, pos, labels=node_labels, edge_labels=edge_labels, node_size=500, node_color=node_color_lst)\n",
    "    nx.draw(g, pos, labels=node_labels, node_size=500)\n",
    "    nx.draw_networkx_edge_labels(g,pos,edge_labels=edge_labels)\n",
    "    pylab.show()\n",
    "\n",
    "\n",
    "\n",
    "def draw_id(g):\n",
    "    pos = nx.spring_layout(g)\n",
    "    edge_labels = dict([((n1, n2), d['valence']) for n1, n2, d in g.edges(data=True)])\n",
    "    node_labels = nx.get_node_attributes(g, 'label')\n",
    "    nx.draw(g,pos,labels=node_labels, node_size=500)\n",
    "    nx.draw_networkx_edge_labels(g,pos,edge_labels=edge_labels)\n",
    "    pylab.show()\n",
    "\n",
    "def draw(g):\n",
    "    draw_type(g)\n",
    "    draw_id(g)\n",
    "\n",
    "g = nx.read_gexf(path=\"./train/4.gexf\")\n",
    "print(str(g.number_of_nodes())+\" nodes:\\n\",list(g.nodes))\n",
    "print(str(g.number_of_edges())+\" edges:\\n\",list(g.edges))\n",
    "draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf5a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.read_gexf(path=\"./train/4.gexf\")\n",
    "\n",
    "def GPG(g, NR, NID, ER, EID):\n",
    "    Del_Edge = []\n",
    "    G = g\n",
    "    ED = random.randint(0, EID)\n",
    "    # draw(g)\n",
    "    NR = random_node_relabeling(g,NR)\n",
    "    NID = random_node_insertion(g,NID)\n",
    "    ED, Del_Edge = random_edge_deletion(g,ED)\n",
    "\n",
    "    ER = random_edge_relabeling(g,ER)\n",
    "    EI = random_edge_insertion(g,EID-ED, Del_Edge)\n",
    "    EID = EI +ED\n",
    "    print(\"Edge Deletion\",ED)\n",
    "    print(\"Edge Insertion\",EI)\n",
    "    print(\"NR,NID,ER,EI,ED: \",NR,NID,ER,EI,ED)\n",
    "    GEV = NR + NID + ER + EID\n",
    "    print(\"GEV_SUM:\", GEV)\n",
    "    gev_info = \"_NR_\"+str(NR)+\"_NID_\"+str(NID)+\"_ER_\"+str(ER)+\"_EID_\"+str(EID)\n",
    "    return gev_info\n",
    "\n",
    "\n",
    "trainDir = os.getcwd()+'\\\\train'\n",
    "filenames = os.listdir(trainDir)\n",
    "for i in range(5):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".gexf\"):\n",
    "            print(\"->\"+filename)\n",
    "            g =  nx.read_gexf(path=dirName+\"\\\\\"+filename)\n",
    "            gev_info = GPG(g, random.randint(0, 5),random.randint(0, 5),random.randint(0, 5),random.randint(0, 5))\n",
    "            nx.write_gexf(G=g, path=\"./export/\"+filename[:-5]+gev_info+\".gexf\")\n",
    "            print(\"<-\"+filename[:-5]+gev_info+\".gexf\")\n",
    "\n",
    "GPG(g, random.randint(0, 5),random.randint(0, 5),random.randint(0, 5),random.randint(0, 5))\n",
    "draw_type(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d869a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileInfo(filename):\n",
    "    g = nx.read_gexf(path=\"./export/\"+filename)\n",
    "    # draw(g)\n",
    "    reg = re.sub(\".*NR_(?P<nr>\\d+)_NID_(?P<nid>\\d+)_ER_(?P<er>\\d+)_EID_(?P<eid>\\d+).gexf\", \"\\g<eid>\", filename)\n",
    "    ori = re.sub(\"(?P<t>.+?)_.*\", \"\\g<t>\", filename)\n",
    "    nr = int(re.sub(\".*NR_(?P<t>.+?)_.*\", \"\\g<t>\", filename))\n",
    "    nid = int(re.sub(\".*NID_(?P<t>.+?)_.*\", \"\\g<t>\", filename))\n",
    "    er =  int(re.sub(\".*ER_(?P<t>.+?)_.*\", \"\\g<t>\", filename))\n",
    "    eid = int(re.sub(\".*EID_(?P<t>.+?).gexf\", \"\\g<t>\", filename))\n",
    "    gev = nr+nid+er+eid\n",
    "    return [ori+'.gexf',gev,nr,nid,er,eid]\n",
    "    # print('ori',ori, 'nr',nr, 'nid',nid, 'er',er, 'eid',eid,'gev',gev)\n",
    "getFileInfo(\"4_NR_0_NID_3_ER_2_EID_2.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653d42f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filename = \"4_NR_0_NID_3_ER_2_EID_2.gexf\"\n",
    "g = nx.read_gexf(path=\"./export/\"+filename)\n",
    "# draw(g)\n",
    "reg = re.sub(\".*NR_(?P<nr>\\d+)_NID_(?P<nid>\\d+)_ER_(?P<er>\\d+)_EID_(?P<eid>\\d+).gexf\", \"\\g<eid>\", filename)\n",
    "ori = re.sub(\"(?P<t>.+?)_.*\", \"\\g<t>\", filename)\n",
    "nr = int(re.sub(\".*NR_(?P<t>.+?)_.*\", \"\\g<t>\", filename))\n",
    "nid = int(re.sub(\".*NID_(?P<t>.+?)_.*\", \"\\g<t>\", filename))\n",
    "er =  int(re.sub(\".*ER_(?P<t>.+?)_.*\", \"\\g<t>\", filename))\n",
    "eid = int(re.sub(\".*EID_(?P<t>.+?).gexf\", \"\\g<t>\", filename))\n",
    "gev = nr+nid+er+eid\n",
    "print('ori',ori, 'nr',nr, 'nid',nid, 'er',er, 'eid',eid,'gev',gev)\n",
    "\n",
    "g_ori = nx.read_gexf(path=\"./train/\"+ori+\".gexf\")\n",
    "# draw(g_ori)\n",
    "# print(nx.adjacency_matrix(g))\n",
    "\n",
    "import json\n",
    "\n",
    "nlm0 ={}\n",
    "for node in g_ori.nodes():\n",
    "    t = g_ori.nodes[node]['type']\n",
    "    # print(t)\n",
    "    dic = {t:1}\n",
    "    str_key = json.dumps(dic)\n",
    "    if nlm0.get(str_key):\n",
    "        nlm0[str_key] = nlm0.get(str_key)+1\n",
    "    else:\n",
    "        nlm0[str_key] = 1\n",
    "\n",
    "print('nlm0',nlm0)\n",
    "\n",
    "nlm1 ={}\n",
    "for node in g_ori.nodes():\n",
    "    neighbors = [n for n in g_ori.neighbors(node)]\n",
    "    # print(neighbors)\n",
    "    dic = {}\n",
    "    for neighbor in neighbors:\n",
    "        t = g_ori.nodes[neighbor]['type']\n",
    "        # print(t)\n",
    "        if dic.get(t):\n",
    "            dic[t] = dic.get(t)+1\n",
    "        else:\n",
    "            dic[t] = 1\n",
    "\n",
    "    # print(dic)\n",
    "    # print(json.dumps(dic))\n",
    "    if nlm1.get(json.dumps(dic)):\n",
    "            nlm1[json.dumps(dic)] = nlm1.get(json.dumps(dic))+1\n",
    "    else:\n",
    "            nlm1[json.dumps(dic)] = 1\n",
    "\n",
    "    # print('----------------')\n",
    "print(\"nlm1\",nlm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46bdae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "elm0 ={}\n",
    "for edge in g_ori.edges():\n",
    "    t = g_ori.edges[edge]['valence']\n",
    "    # print(t)\n",
    "    dic = {t:1}\n",
    "    str_key = json.dumps(dic)\n",
    "    if elm0.get(str_key):\n",
    "        elm0[str_key] = elm0.get(str_key)+1\n",
    "    else:\n",
    "        elm0[str_key] = 1\n",
    "\n",
    "print('elm0',elm0)\n",
    "\n",
    "elm1 ={}\n",
    "for edge in g_ori.edges():\n",
    "    print(edge)\n",
    "    print(g_ori.nodes[edge[0]])\n",
    "\n",
    "draw(g_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e24a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TensorNetworkModule(torch.nn.Module):\n",
    "    def __init__(self, tensor_neurons, input_dim):\n",
    "        super(TensorNetworkModule, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.tensor_neurons = tensor_neurons\n",
    "        self.setup_weights()\n",
    "        self.init_parameters()\n",
    "\n",
    "    def setup_weights(self):\n",
    "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.input_dim, self.input_dim, self.tensor_neurons))\n",
    "        self.weight_matrix_block = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 2 * self.input_dim))\n",
    "        self.bias = torch.nn.Parameter(torch.Tensor(self.tensor_neurons, 1))\n",
    "\n",
    "    def init_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
    "        torch.nn.init.xavier_uniform_(self.weight_matrix_block)\n",
    "        torch.nn.init.xavier_uniform_(self.bias)\n",
    "\n",
    "    def forward(self, embedding_1, embedding_2):\n",
    "        scoring = torch.mm(torch.t(embedding_1), self.weight_matrix.view(self.input_dim, -1))\n",
    "        scoring = scoring.view(self.input_dim, self.tensor_neurons)\n",
    "        scoring = torch.mm(torch.t(scoring), embedding_2)\n",
    "        combined_representation = torch.cat((embedding_1, embedding_2))\n",
    "        block_scoring = torch.mm(self.weight_matrix_block, combined_representation)\n",
    "        scores = torch.nn.functional.relu(scoring + block_scoring + self.bias)\n",
    "        return scores\n",
    "\n",
    "\n",
    "def graph_aggregation_layer(adj, features):\n",
    "    hidden1 = torch.mm(adj, features)\n",
    "    hidden2 = torch.mm(adj, hidden1)\n",
    "    return hidden1, hidden2\n",
    "\n",
    "\n",
    "class TaGSim(torch.nn.Module):\n",
    "    def __init__(self, number_of_node_labels, number_of_edge_labels, tensor_neurons, bottle_neck_neurons):\n",
    "        super(TaGSim, self).__init__()\n",
    "        self.number_of_node_labels = len(number_of_node_labels)\n",
    "        self.number_of_edge_labels = len(number_of_edge_labels)\n",
    "        self.node_type = number_of_node_labels\n",
    "        self.edge_type = number_of_edge_labels\n",
    "        self.tensor_neurons = tensor_neurons\n",
    "        self.bottle_neck_neurons = bottle_neck_neurons\n",
    "        self.setup_layers()\n",
    "\n",
    "    def setup_layers(self):\n",
    "        self.feature_count = self.tensor_neurons\n",
    "\n",
    "        self.tensor_network_nc = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
    "        self.tensor_network_in = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
    "        self.tensor_network_ie = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_node_labels)\n",
    "        self.tensor_network_ec = TensorNetworkModule(self.tensor_neurons, 2 * self.number_of_edge_labels)\n",
    "\n",
    "        self.fully_connected_first_nc = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
    "        self.fully_connected_second_nc = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
    "        self.fully_connected_third_nc = torch.nn.Linear(8, 4)\n",
    "        self.scoring_layer_nc = torch.nn.Linear(4, 1)\n",
    "\n",
    "        self.fully_connected_first_in = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
    "        self.fully_connected_second_in = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
    "        self.fully_connected_third_in = torch.nn.Linear(8, 4)\n",
    "        self.scoring_layer_in = torch.nn.Linear(4, 1)\n",
    "\n",
    "        self.fully_connected_first_ie = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
    "        self.fully_connected_second_ie = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
    "        self.fully_connected_third_ie = torch.nn.Linear(8, 4)\n",
    "        self.scoring_layer_ie = torch.nn.Linear(4, 1)\n",
    "\n",
    "        self.fully_connected_first_ec = torch.nn.Linear(self.feature_count, self.bottle_neck_neurons)\n",
    "        self.fully_connected_second_ec = torch.nn.Linear(self.bottle_neck_neurons, 8)\n",
    "        self.fully_connected_third_ec = torch.nn.Linear(8, 4)\n",
    "        self.scoring_layer_ec = torch.nn.Linear(4, 1)\n",
    "\n",
    "    def gal_pass(self, edge_index, features):\n",
    "        hidden1 = self.gal1(features, edge_index)\n",
    "        hidden2 = self.gal2(hidden1, edge_index)\n",
    "\n",
    "        return hidden1, hidden2\n",
    "\n",
    "    def forward(self, label_multiset):\n",
    "        adj_1, adj_2 = torch.FloatTensor(np.array(label_multiset[\"node_index_1\"].todense())), torch.FloatTensor(\n",
    "            np.array(label_multiset[\"node_index_2\"].todense()))\n",
    "        edge_adj_1, edge_adj_2 = label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"]\n",
    "        node_features_1, node_features_2 = label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"]\n",
    "        edge_features_1, edge_features_2 = label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"]\n",
    "\n",
    "        #gal\n",
    "        graph1_hidden1, graph1_hidden2 = graph_aggregation_layer(adj_1, node_features_1)  #original graph node\n",
    "        graph2_hidden1, graph2_hidden2 = graph_aggregation_layer(adj_2, node_features_2)  #generated graph node\n",
    "        edge1_hidden1, edge1_hidden2 = graph_aggregation_layer(edge_adj_1, edge_features_1)  #original edge node\n",
    "        edge2_hidden1, edge2_hidden2 = graph_aggregation_layer(edge_adj_2, edge_features_2)  #generated graph edge\n",
    "        #node level embedding Concatenation\n",
    "        graph1_01concat = torch.cat([node_features_1, graph1_hidden1], dim=1)\n",
    "        graph2_01concat = torch.cat([node_features_2, graph2_hidden1], dim=1)\n",
    "        graph1_12concat = torch.cat([graph1_hidden1, graph1_hidden2], dim=1)\n",
    "        graph2_12concat = torch.cat([graph2_hidden1, graph2_hidden2], dim=1)\n",
    "        #graph pooling: node Sum\n",
    "        graph1_01pooled = torch.sum(graph1_01concat, dim=0).unsqueeze(1)\n",
    "        graph2_01pooled = torch.sum(graph2_01concat, dim=0).unsqueeze(1)\n",
    "        graph1_12pooled = torch.sum(graph1_12concat, dim=0).unsqueeze(1)\n",
    "        graph2_12pooled = torch.sum(graph2_12concat, dim=0).unsqueeze(1)\n",
    "        #edge level embedding Concatenation\n",
    "        edge1_01concat = torch.cat([edge_features_1, edge1_hidden1], dim=1)\n",
    "        edge2_01concat = torch.cat([edge_features_2, edge2_hidden1], dim=1)\n",
    "        #graph pooling: edge Sum\n",
    "        edge1_01pooled = torch.sum(edge1_01concat, dim=0).unsqueeze(1)\n",
    "        edge2_01pooled = torch.sum(edge2_01concat, dim=0).unsqueeze(1)\n",
    "\n",
    "        scores_nc = self.tensor_network_nc(graph1_01pooled, graph2_01pooled)\n",
    "        scores_nc = torch.t(scores_nc)\n",
    "\n",
    "        scores_nc = torch.nn.functional.relu(self.fully_connected_first_nc(scores_nc))\n",
    "        scores_nc = torch.nn.functional.relu(self.fully_connected_second_nc(scores_nc))\n",
    "        scores_nc = torch.nn.functional.relu(self.fully_connected_third_nc(scores_nc))\n",
    "        score_nc = torch.sigmoid(self.scoring_layer_nc(scores_nc))\n",
    "\n",
    "        scores_in = self.tensor_network_in(graph1_01pooled, graph2_01pooled)\n",
    "        scores_in = torch.t(scores_in)\n",
    "\n",
    "        scores_in = torch.nn.functional.relu(self.fully_connected_first_in(scores_in))\n",
    "        scores_in = torch.nn.functional.relu(self.fully_connected_second_in(scores_in))\n",
    "        scores_in = torch.nn.functional.relu(self.fully_connected_third_in(scores_in))\n",
    "        score_in = torch.sigmoid(self.scoring_layer_in(scores_in))\n",
    "\n",
    "        scores_ie = self.tensor_network_ie(graph1_12pooled, graph2_12pooled)\n",
    "        scores_ie = torch.t(scores_ie)\n",
    "\n",
    "        scores_ie = torch.nn.functional.relu(self.fully_connected_first_ie(scores_ie))\n",
    "        scores_ie = torch.nn.functional.relu(self.fully_connected_second_ie(scores_ie))\n",
    "        scores_ie = torch.nn.functional.relu(self.fully_connected_third_ie(scores_ie))\n",
    "        score_ie = torch.sigmoid(self.scoring_layer_ie(scores_ie))\n",
    "\n",
    "        scores_ec = self.tensor_network_ec(edge1_01pooled, edge2_01pooled)\n",
    "        scores_ec = torch.t(scores_ec)\n",
    "\n",
    "        scores_ec = torch.nn.functional.relu(self.fully_connected_first_ec(scores_ec))\n",
    "        scores_ec = torch.nn.functional.relu(self.fully_connected_second_ec(scores_ec))\n",
    "        scores_ec = torch.nn.functional.relu(self.fully_connected_third_ec(scores_ec))\n",
    "        score_ec = torch.sigmoid(self.scoring_layer_ec(scores_ec))\n",
    "\n",
    "        return torch.cat([score_nc, score_in, score_ie, score_ec], dim=1)\n",
    "\n",
    "    def transform_label_multiset(self, graph1, graph2, ged, type_specified=True):\n",
    "        #node and edge info of pair graph\n",
    "\n",
    "        node_info1 = nx.get_node_attributes(graph1, 'type')\n",
    "        node_info2 = nx.get_node_attributes(graph2, 'type')\n",
    "        edge_info1 = nx.get_edge_attributes(graph1, 'valence')\n",
    "        edge_info2 = nx.get_edge_attributes(graph2, 'valence')\n",
    "        nodes1 = list(graph1.nodes())\n",
    "        nodes2 = list(graph2.nodes())\n",
    "        edges1 = list(graph1.edges())\n",
    "        edges2 = list(graph2.edges())\n",
    "\n",
    "        label_multiset = dict()\n",
    "        node_features_1, node_features_2, edge_features_1, edge_features_2, edge_adj_1, edge_adj_2 = [], [], [], [], [], []\n",
    "\n",
    "        for i in graph1.nodes():\n",
    "            # print(i,graph1.nodes())\n",
    "            # print('info:',node_info1)\n",
    "            node_features_1.append([1.0 if node_info1[i] == node else 0.0 for node in self.node_type])\n",
    "\n",
    "        for i in graph2.nodes():\n",
    "            node_features_2.append([1.0 if node_info2[i] == node else 0.0 for node in self.node_type])\n",
    "        node_features_1, node_features_2 = torch.FloatTensor(np.array(node_features_1)), torch.FloatTensor(\n",
    "            np.array(node_features_2))\n",
    "\n",
    "        for i in edges1:\n",
    "            edge_features_1.append([1.0 if edge_info1[i] == edge else 0.0 for edge in self.edge_type])\n",
    "            adj_row = []\n",
    "            for d in edges1:\n",
    "                if (i == d):\n",
    "                    adj_row.append(0.0)\n",
    "                    continue\n",
    "                if ((i[0] in d) | (i[1] in d)):\n",
    "                    adj_row.append(1.0)\n",
    "                else:\n",
    "                    adj_row.append(0.0)\n",
    "            edge_adj_1.append(adj_row)\n",
    "        for i in edges2:\n",
    "            edge_features_2.append([1.0 if edge_info2[i] == edge else 0.0 for edge in self.edge_type])\n",
    "            adj_row = []\n",
    "            for d in edges2:\n",
    "                if (i == d):\n",
    "                    adj_row.append(0.0)\n",
    "                    continue\n",
    "                if ((i[0] in d) | (i[1] in d)):\n",
    "                    adj_row.append(1.0)\n",
    "                else:\n",
    "                    adj_row.append(0.0)\n",
    "            edge_adj_2.append(adj_row)\n",
    "\n",
    "        edge_features_1, edge_features_2 = torch.FloatTensor(np.array(edge_features_1)), torch.FloatTensor(\n",
    "            np.array(edge_features_2))\n",
    "        edge_adj_1, edge_adj_2 = torch.FloatTensor(np.array(edge_adj_1)), torch.FloatTensor(np.array(edge_adj_2))\n",
    "\n",
    "        label_multiset[\"node_index_1\"], label_multiset[\"node_index_2\"] = nx.adjacency_matrix(\n",
    "            graph1), nx.adjacency_matrix(graph2)\n",
    "        label_multiset[\"node_features_1\"], label_multiset[\"node_features_2\"] = node_features_1, node_features_2\n",
    "        label_multiset[\"edge_features_1\"], label_multiset[\"edge_features_2\"] = edge_features_1, edge_features_2\n",
    "        label_multiset[\"edge_adj_1\"], label_multiset[\"edge_adj_2\"] = edge_adj_1, edge_adj_2\n",
    "\n",
    "        #ged normalisation\n",
    "        if (type_specified):\n",
    "            # norm_ged = [ged.count(key) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes())) for key in ['1', '2', '3', '4']]\n",
    "            norm_ged = [n / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes())) for n in ged]\n",
    "            norm_ged = np.array(norm_ged)\n",
    "            label_multiset[\"target\"] = torch.from_numpy(np.exp(-norm_ged)).view(1, -1).float()\n",
    "\n",
    "            norm_gt_ged = (len(ged)) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
    "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
    "        else:\n",
    "            norm_gt_ged = (len(ged)) / (0.5 * (graph1.number_of_nodes() + graph2.number_of_nodes()))\n",
    "            label_multiset[\"gt_ged\"] = torch.from_numpy(np.exp(-norm_gt_ged).reshape(1, 1)).view(1, -1).float()\n",
    "\n",
    "        return label_multiset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e51c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileInfo(filename):\n",
    "    g = nx.read_gexf(path=\"./export/\"+filename)\n",
    "    # draw(g)\n",
    "    reg = re.sub(\".*NR_(?P<nr>\\d+)_NID_(?P<nid>\\d+)_ER_(?P<er>\\d+)_EID_(?P<eid>\\d+).gexf\", \"\\g<eid>\", filename)\n",
    "    ori = re.sub(\"(?P<t>.+?)_.*\", \"\\g<t>\", filename)\n",
    "    nr = int(re.sub(\".*NR_(?P<t>.+?)_.*\", \"\\g<t>\", filename))\n",
    "    nid = int(re.sub(\".*NID_(?P<t>.+?)_.*\", \"\\g<t>\", filename))\n",
    "    er =  int(re.sub(\".*ER_(?P<t>.+?)_.*\", \"\\g<t>\", filename))\n",
    "    eid = int(re.sub(\".*EID_(?P<t>.+?).gexf\", \"\\g<t>\", filename))\n",
    "    gev = nr+nid+er+eid\n",
    "    # return [ori+'.gexf',str(nr)+str(nid)+str(er)+str(eid)]\n",
    "    return [ori+'.gexf',[nr, nid, er,eid]]\n",
    "    # print('ori',ori, 'nr',nr, 'nid',nid, 'er',er, 'eid',eid,'gev',gev)\n",
    "getFileInfo(\"4_NR_0_NID_3_ER_2_EID_2.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1af7c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "tensor_neurons = 16\n",
    "bottle_neck_neurons = 16\n",
    "batch_size = 128\n",
    "dropout = 0.0\n",
    "lr = 0.001\n",
    "weight_decay = 0.0\n",
    "\n",
    "exportDir = os.getcwd()+'\\\\export'\n",
    "trainDir = os.getcwd()+'\\\\train'\n",
    "filenames = os.listdir(exportDir)\n",
    "\n",
    "\n",
    "print(Node_Types)\n",
    "print(Edge_Types)\n",
    "globel_node_number = len(Node_Types)\n",
    "globel_edge_number = len(Edge_Types)\n",
    "print(\"\\n-------Model training---------.\\n\")\n",
    "\n",
    "model = TaGSim(Node_Types, Edge_Types, tensor_neurons, bottle_neck_neurons)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "iteration = 0\n",
    "\n",
    "# #pick random pair\n",
    "# pair_1 = random.choice(filenames)\n",
    "# print(pair_1)\n",
    "\n",
    "# pair_2 = getFileInfo(pair_1)[0]\n",
    "# ged = getFileInfo(pair_1)[1]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batches = []\n",
    "    for graph in range(0, len(filenames), batch_size):\n",
    "        #TODO Use Sequencing Instead of Random\n",
    "        pair_1 = random.choice(filenames)\n",
    "        pair_2 = getFileInfo(pair_1)[0]\n",
    "        ged = getFileInfo(pair_1)[1]\n",
    "        # print(pair_1,pair_2,ged)\n",
    "        graph1 = nx.read_gexf(exportDir+'\\\\'+pair_1)\n",
    "        graph2 = nx.read_gexf(trainDir+'\\\\'+pair_2)\n",
    "        batches.append([graph1,graph2,ged,pair_1])\n",
    "\n",
    "    for batch in batches:\n",
    "      model.train()\n",
    "      optimizer.zero_grad()\n",
    "      losses = 0\n",
    "      graph1 = batch[0]\n",
    "      graph2 = batch[1]\n",
    "      draw(graph1)\n",
    "      draw(graph2)\n",
    "      print('filename:',batch[3],'GED: ',batch[2])\n",
    "      data = model.transform_label_multiset(graph1, graph2, batch[2])\n",
    "      prediction = model(data)\n",
    "      losses += torch.nn.functional.mse_loss(data[\"target\"], prediction)\n",
    "      losses.backward(retain_graph=True)\n",
    "      optimizer.step()\n",
    "      loss = losses.item()\n",
    "\n",
    "      print('Iteration', iteration, 'loss: ', loss/len(batch))\n",
    "\n",
    "      iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c85b765",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g_ori = nx.read_gexf(path=\"./train/8116.gexf\")\n",
    "draw(g_ori)\n",
    "print(g_ori.nodes())\n",
    "print(nx.get_node_attributes(g_ori,'type'))\n",
    "# print(g_ori.edges())\n",
    "# print(nx.get_edge_attributes(g_ori,'valence'))\n",
    "\n",
    "g = nx.read_gexf(path=\"./export/8116_NR_2_NID_2_ER_1_EID_4.gexf\")\n",
    "draw(g)\n",
    "print(g.nodes())\n",
    "print(nx.get_node_attributes(g,'type'))\n",
    "# print(g.edges())\n",
    "# print(nx.get_edge_attributes(g,'valence'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39a1439",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.read_gexf(path=\"./train/8116.gexf\")\n",
    "print(g.nodes())\n",
    "print(nx.get_node_attributes(g,'type'))\n",
    "draw(g)\n",
    "##8116_NR_2_NID_2_ER_1_EID_4.gexf\")\n",
    "GPG(g, 5, 0, 0, 5)\n",
    "print(g.nodes())\n",
    "print(nx.get_node_attributes(g,'type'))\n",
    "draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d428105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_node_relabeling(g, numbers):\n",
    "    if numbers > g.number_of_nodes():\n",
    "        numbers = g.number_of_nodes()\n",
    "\n",
    "    # draw_type(g)\n",
    "    i=1\n",
    "    lst = []\n",
    "\n",
    "    while i<=numbers:\n",
    "        # print(i,\"-th random_node_relabeling\")\n",
    "        n = random.choice(list(g.nodes))\n",
    "        assigned_type = random.choice(Node_Types)\n",
    "        # print(g.node[n], assigned_type, lst)\n",
    "        if (n in lst) or (g.nodes[n]['type'] == assigned_type):\n",
    "            continue\n",
    "        else:\n",
    "            g.nodes[n]['type'] = assigned_type\n",
    "            lst.append(n)\n",
    "            # print(g.node[n])\n",
    "            # draw_type(g)\n",
    "            i+=1\n",
    "    return numbers\n",
    "g = nx.read_gexf(path=\"./train/2821.gexf\")\n",
    "print(random_node_relabeling(g,5))\n",
    "print(g.nodes())\n",
    "print(nx.get_node_attributes(g,'type'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51483289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_edge_relabeling(g, numbers):\n",
    "    if numbers > g.number_of_edges():\n",
    "        numbers = g.number_of_edges()\n",
    "\n",
    "    # draw_type(g)\n",
    "    i=1\n",
    "    lst = []\n",
    "\n",
    "    while i<=numbers:\n",
    "        # print(i,\"-th random_edge_relabeling\")\n",
    "        n = random.choice(list(g.edges()))\n",
    "        assigned_type = random.choice(Edge_Types)\n",
    "        # print(g.edges[n], assigned_type, lst)\n",
    "        if (n in lst) or (g.edges[n]['valence'] == assigned_type):\n",
    "            continue\n",
    "        else:\n",
    "            g.edges[n]['valence'] = assigned_type\n",
    "            lst.append(n)\n",
    "            # print(g.edges[n])\n",
    "            # draw_type(g)\n",
    "            i+=1\n",
    "    return numbers\n",
    "g = nx.read_gexf(path=\"./train/4.gexf\")\n",
    "print(random_edge_relabeling(g,99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18080bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_node_insertion(g, numbers):\n",
    "    i=1\n",
    "    while i<=numbers:\n",
    "        # print(i,\"-th random_node_insertion\")\n",
    "        new_id = max(list(map(int, g.nodes)))+1\n",
    "        g.add_node(str(new_id),label=str(new_id), type=random.choice(Node_Types))\n",
    "        # draw(g)\n",
    "        i+=1\n",
    "        # print(g.nodes)\n",
    "    return numbers\n",
    "\n",
    "g = nx.read_gexf(path=\"./train/4.gexf\")\n",
    "random_node_insertion(g,5)\n",
    "draw(g)\n",
    "print(g.nodes)\n",
    "print(nx.get_node_attributes(g,'type'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bb047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_edge_deletion(g, numbers):\n",
    "    Del_Edge = []\n",
    "    if numbers >= g.number_of_edges():\n",
    "        numbers = g.number_of_edges()-1\n",
    "    i=1\n",
    "    while i<=numbers:\n",
    "        # print(i,\"-th random_edge_deletion\")\n",
    "        n = random.choice(list(g.edges()))\n",
    "        Del_Edge.append(n)\n",
    "        g.remove_edge(n[0], n[1])\n",
    "        # draw(g)\n",
    "        i+=1\n",
    "        # print(Del_Edge)\n",
    "        # print(g.edges)\n",
    "    return numbers, Del_Edge\n",
    "\n",
    "g = nx.read_gexf(path=\"./train/8116.gexf\")\n",
    "print(g.edges())\n",
    "n, arr = random_edge_deletion(g,99)\n",
    "print(n, arr)\n",
    "print(g.edges())\n",
    "print(nx.get_edge_attributes(g,'valence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77833e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_edge_insertion(g, numbers, Del_Edge):\n",
    "    pairs = set(list(g.nodes()))\n",
    "    arr = []\n",
    "    lst = list(g.nodes())\n",
    "\n",
    "    for i in range(0,len(lst)):\n",
    "        for j in range(i+1,len(lst)):\n",
    "            arr.append((lst[i],lst[j]))\n",
    "    # print(arr)\n",
    "\n",
    "    ei_arr = list(set((a,b) if a<=b else (b,a) for a,b in arr))\n",
    "\n",
    "    for i in range(0,n):\n",
    "        for j in range(i+1,n):\n",
    "            ei_arr.append((str(i),str(j)))\n",
    "    # print(\"ei_arr\",ei_arr)\n",
    "    for edge in g.edges():\n",
    "        # print(\"edge\",edge)\n",
    "        if (edge[0], edge[1]) in ei_arr:\n",
    "            ei_arr.remove((edge[0],edge[1]))\n",
    "        else:\n",
    "            ei_arr.remove((edge[1],edge[0]))\n",
    "\n",
    "    for edge in Del_Edge:\n",
    "        if (edge[0], edge[1]) in ei_arr:\n",
    "            ei_arr.remove((edge[0],edge[1]))\n",
    "        else:\n",
    "            ei_arr.remove((edge[1],edge[0]))\n",
    "    max_edge = len(ei_arr)\n",
    "    # print(max_edge)\n",
    "\n",
    "    if numbers > max_edge:\n",
    "        numbers = max_edge\n",
    "\n",
    "    i=1\n",
    "    while i<=numbers:\n",
    "        # print(i,\"-th random_edge_insertion\")\n",
    "        r = random.sample(ei_arr,1)[0]\n",
    "        # print(r)\n",
    "        g.add_edge(r[0],r[1],valence=random.choice(Edge_Types))\n",
    "        ei_arr.remove(r)\n",
    "        # draw(g)\n",
    "        i+=1\n",
    "        # print(g.edges)\n",
    "    return numbers\n",
    "\n",
    "g = nx.read_gexf(path=\"./train/2821.gexf\")\n",
    "draw(g)\n",
    "ed, Del_Edge = random_edge_deletion(g,3)\n",
    "print(ed, type(Del_Edge))\n",
    "# Del_Edge=[]\n",
    "ei = random_edge_insertion(g,2,Del_Edge)\n",
    "draw(g)\n",
    "print(g.number_of_edges())\n",
    "print(\"ei: \", ei)\n",
    "print(g.nodes())\n",
    "print(nx.get_node_attributes(g,'type'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a38c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.read_gexf(path=\"./train/4.gexf\")\n",
    "n = g.number_of_nodes()\n",
    "print(n)\n",
    "\n",
    "pairs = set(list(g.nodes()))\n",
    "arr = []\n",
    "lst = list(g.nodes())\n",
    "\n",
    "for i in range(0,len(lst)):\n",
    "    for j in range(i+1,len(lst)):\n",
    "        arr.append((lst[i],lst[j]))\n",
    "print(arr)\n",
    "\n",
    "ei_arr = list(set((a,b) if a<=b else (b,a) for a,b in arr))\n",
    "\n",
    "for i in range(0,n):\n",
    "    for j in range(i+1,n):\n",
    "        ei_arr.append((str(i),str(j)))\n",
    "\n",
    "for edge in g.edges():\n",
    "    if (edge[0], edge[1]) in ei_arr:\n",
    "        ei_arr.remove((edge[0],edge[1]))\n",
    "    else:\n",
    "        ei_arr.remove((edge[1],edge[0]))\n",
    "\n",
    "for edge in Del_Edge:\n",
    "    if (edge[0], edge[1]) in ei_arr:\n",
    "        ei_arr.remove((edge[0],edge[1]))\n",
    "    else:\n",
    "        ei_arr.remove((edge[1],edge[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(ei_arr, len(ei_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438475ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb17126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852e4e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
